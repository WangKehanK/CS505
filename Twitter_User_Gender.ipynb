{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS505-demographic-identifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WangKehanK/CS505/blob/main/Twitter_User_Gender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMAi9DPo4woR"
      },
      "source": [
        "# Prediction on age, gender with M3 inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMI4DQmejnbb"
      },
      "source": [
        "m3inference\n",
        "\n",
        "https://github.com/euagendas/m3inference#existing-json-twitter-data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frlUYrxsCjZZ",
        "outputId": "8a49a166-4ecd-4780-fb7d-c0a6024dacbe"
      },
      "source": [
        "!pip install m3inference"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting m3inference\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/88/df1f455fd29addf4efe6b6fab346b214ccab33144fa94b8efbf5d874a732/m3inference-1.1.4-py3-none-any.whl (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 14.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 15.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 30kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 40kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 51kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from m3inference) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from m3inference) (1.19.5)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from m3inference) (0.9.1+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from m3inference) (2.23.0)\n",
            "Requirement already satisfied: pandas>=0.20 in /usr/local/lib/python3.7/dist-packages (from m3inference) (1.1.5)\n",
            "Collecting rauth\n",
            "  Downloading https://files.pythonhosted.org/packages/43/aa/7c8e852275394d65ac5bf3ac9945ecaafe4d083089e09cb0a267efea389a/rauth-0.7.3.tar.gz\n",
            "Collecting pycld2>=0.31\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/d2/8b0def84a53c88d0eb27c67b05269fbd16ad68df8c78849e7b5d65e6aec3/pycld2-0.41.tar.gz (41.4MB)\n",
            "\u001b[K     |████████████████████████████████| 41.4MB 104kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from m3inference) (4.41.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from m3inference) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->m3inference) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->m3inference) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->m3inference) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->m3inference) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->m3inference) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20->m3inference) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20->m3inference) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.20->m3inference) (1.15.0)\n",
            "Building wheels for collected packages: rauth, pycld2\n",
            "  Building wheel for rauth (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rauth: filename=rauth-0.7.3-cp37-none-any.whl size=16055 sha256=1c84b55adeb002954becf3903e58516f356c2a50423afda3603620a3221c134a\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/94/5d/81afc278dd5da884a0002563dc4b0fe85f9067a5a40f76f858\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp37-cp37m-linux_x86_64.whl size=9834237 sha256=56182deeee61f44e4f0bd25bf78049dd52d00e57793be55dc16fee715aa84d36\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/8f/e9/08a1a8932a490175bd140206cd86a3dbcfc70498100de11079\n",
            "Successfully built rauth pycld2\n",
            "Installing collected packages: rauth, pycld2, m3inference\n",
            "Successfully installed m3inference-1.1.4 pycld2-0.41 rauth-0.7.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAQMq2x0k-8N"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from m3inference import M3Twitter\n",
        "import json\n",
        "import os\n",
        "import pprint"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puDcaqYNmfGP",
        "outputId": "2fff29a6-2a0b-4bac-b105-19103959053a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQS-blVlmJr7"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Twitter_user_handles_to_predict.csv\", encoding = \"utf-8\")\n",
        "df_labeled = pd.read_csv(\"/content/drive/My Drive/Twitter_users_labeled_with_age_and_gender.csv\", encoding = \"latin-1\")\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXL6fbvHd_-l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13bfdf26-2b32-454f-a620-885916fd157e"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25129 entries, 0 to 25128\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   ID        25129 non-null  int64 \n",
            " 1   Username  25128 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 392.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "JJ6gVozEmwUH",
        "outputId": "b631595d-fcba-4417-eb47-b000aa27d744"
      },
      "source": [
        "df_labeled"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>user_id</th>\n",
              "      <th>lang</th>\n",
              "      <th>name</th>\n",
              "      <th>location</th>\n",
              "      <th>description</th>\n",
              "      <th>protected</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>statuses_count</th>\n",
              "      <th>favourites_count</th>\n",
              "      <th>account_created_at</th>\n",
              "      <th>verified</th>\n",
              "      <th>profile_banner_url</th>\n",
              "      <th>profile_background_url</th>\n",
              "      <th>profile_image_url</th>\n",
              "      <th>user.name</th>\n",
              "      <th>num.tweets.used.Lexicon.prediction</th>\n",
              "      <th>Lexicon.age.prediction</th>\n",
              "      <th>Lexicon.gender.prediction..index.</th>\n",
              "      <th>lexicon.gender.prediction</th>\n",
              "      <th>human.labeled.gender</th>\n",
              "      <th>human.labeled.age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>_____zac_____</td>\n",
              "      <td>4.614412e+08</td>\n",
              "      <td>en</td>\n",
              "      <td>zac ¢</td>\n",
              "      <td>Maryland, USA</td>\n",
              "      <td>_____Û___È_Ü´Ù</td>\n",
              "      <td>False</td>\n",
              "      <td>208</td>\n",
              "      <td>178</td>\n",
              "      <td>27912</td>\n",
              "      <td>4179</td>\n",
              "      <td>1/11/12 20:19</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/46144118...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1226134911...</td>\n",
              "      <td>@_____zac_____</td>\n",
              "      <td>100.0</td>\n",
              "      <td>27.652434</td>\n",
              "      <td>-1.457167</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>___aleia</td>\n",
              "      <td>7.650000e+17</td>\n",
              "      <td>en</td>\n",
              "      <td>_æ___ dad ___æ_</td>\n",
              "      <td>Ohio, USA</td>\n",
              "      <td>BLACK. LIVES. MATTER.</td>\n",
              "      <td>False</td>\n",
              "      <td>466</td>\n",
              "      <td>388</td>\n",
              "      <td>3313</td>\n",
              "      <td>23454</td>\n",
              "      <td>8/14/16 19:45</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/76491083...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1271280679...</td>\n",
              "      <td>@___aleia</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.111464</td>\n",
              "      <td>0.985713</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>___Dals</td>\n",
              "      <td>4.361882e+08</td>\n",
              "      <td>it</td>\n",
              "      <td>_ê_ê___ê__ê_ __</td>\n",
              "      <td>NJ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>3744</td>\n",
              "      <td>1465</td>\n",
              "      <td>97563</td>\n",
              "      <td>22499</td>\n",
              "      <td>12/13/11 22:07</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/43618822...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme14/bg.gif</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1267852466...</td>\n",
              "      <td>@___Dals</td>\n",
              "      <td>100.0</td>\n",
              "      <td>30.628957</td>\n",
              "      <td>0.734656</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>___schaeffer___</td>\n",
              "      <td>1.257110e+09</td>\n",
              "      <td>en</td>\n",
              "      <td>Brenden Schaeffer</td>\n",
              "      <td>The Lou</td>\n",
              "      <td>Culver-Stockton College '20 ¢ Ô_Ô_Ô KM 1548...</td>\n",
              "      <td>False</td>\n",
              "      <td>811</td>\n",
              "      <td>660</td>\n",
              "      <td>26670</td>\n",
              "      <td>72205</td>\n",
              "      <td>3/10/13 14:07</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/12571104...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1268044218...</td>\n",
              "      <td>@___schaeffer___</td>\n",
              "      <td>59.0</td>\n",
              "      <td>35.518352</td>\n",
              "      <td>-3.591586</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>__andresiscool</td>\n",
              "      <td>1.030000e+18</td>\n",
              "      <td>en</td>\n",
              "      <td>Andres Navarro</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>245</td>\n",
              "      <td>184</td>\n",
              "      <td>8731</td>\n",
              "      <td>18574</td>\n",
              "      <td>8/27/18 5:21</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/10339476...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1272229718...</td>\n",
              "      <td>@__andresiscool</td>\n",
              "      <td>100.0</td>\n",
              "      <td>21.014222</td>\n",
              "      <td>-1.623685</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3275</th>\n",
              "      <td>3276</td>\n",
              "      <td>ZTheBest33</td>\n",
              "      <td>1.040000e+18</td>\n",
              "      <td>en</td>\n",
              "      <td>Adam. BLM.</td>\n",
              "      <td>northeast elitelism</td>\n",
              "      <td>AOC/GND/Bern supporter| IFB | very biased | \"W...</td>\n",
              "      <td>False</td>\n",
              "      <td>345</td>\n",
              "      <td>751</td>\n",
              "      <td>17495</td>\n",
              "      <td>33147</td>\n",
              "      <td>9/7/18 11:09</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/10380214...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1232111725...</td>\n",
              "      <td>@ZTheBest33</td>\n",
              "      <td>100.0</td>\n",
              "      <td>37.946711</td>\n",
              "      <td>-2.126250</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3276</th>\n",
              "      <td>3277</td>\n",
              "      <td>ztran53</td>\n",
              "      <td>3.307187e+09</td>\n",
              "      <td>en</td>\n",
              "      <td>Zachary Tranter</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>he/him/his</td>\n",
              "      <td>False</td>\n",
              "      <td>44</td>\n",
              "      <td>148</td>\n",
              "      <td>825</td>\n",
              "      <td>3129</td>\n",
              "      <td>6/3/15 16:58</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/33071871...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/6061595328...</td>\n",
              "      <td>@ztran53</td>\n",
              "      <td>100.0</td>\n",
              "      <td>34.509457</td>\n",
              "      <td>-2.469680</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3277</th>\n",
              "      <td>3278</td>\n",
              "      <td>zupercar1</td>\n",
              "      <td>4.220999e+09</td>\n",
              "      <td>en</td>\n",
              "      <td>Chris Avery _ê___êÈ</td>\n",
              "      <td>Ann Arbor, MI</td>\n",
              "      <td>Comic Book Artist/ Film Major / I like space.....</td>\n",
              "      <td>False</td>\n",
              "      <td>121</td>\n",
              "      <td>1974</td>\n",
              "      <td>31208</td>\n",
              "      <td>70426</td>\n",
              "      <td>11/18/15 20:57</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/42209994...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1145126143...</td>\n",
              "      <td>@zupercar1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>23.884346</td>\n",
              "      <td>-2.540524</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3278</th>\n",
              "      <td>3279</td>\n",
              "      <td>ZWHITE93</td>\n",
              "      <td>4.193607e+08</td>\n",
              "      <td>en</td>\n",
              "      <td>ZWH!tE</td>\n",
              "      <td>TX_´ÙPA</td>\n",
              "      <td>My life is centered around competition and cur...</td>\n",
              "      <td>False</td>\n",
              "      <td>593</td>\n",
              "      <td>528</td>\n",
              "      <td>69595</td>\n",
              "      <td>20793</td>\n",
              "      <td>11/23/11 8:06</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/41936067...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1229137769...</td>\n",
              "      <td>@ZWHITE93</td>\n",
              "      <td>100.0</td>\n",
              "      <td>32.228124</td>\n",
              "      <td>-0.860006</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3279</th>\n",
              "      <td>3280</td>\n",
              "      <td>zzzakari4</td>\n",
              "      <td>1.020000e+18</td>\n",
              "      <td>en</td>\n",
              "      <td>_«_«ê_«__«ê</td>\n",
              "      <td>Moreno Valley, CA</td>\n",
              "      <td>i hate making bios oh my godddd UCIÈ21</td>\n",
              "      <td>False</td>\n",
              "      <td>60</td>\n",
              "      <td>283</td>\n",
              "      <td>4239</td>\n",
              "      <td>27947</td>\n",
              "      <td>7/23/18 7:05</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/10212902...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1221708547...</td>\n",
              "      <td>@zzzakari4</td>\n",
              "      <td>100.0</td>\n",
              "      <td>17.257385</td>\n",
              "      <td>0.288805</td>\n",
              "      <td>F</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3280 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0      screen_name  ...  human.labeled.gender human.labeled.age\n",
              "0              1    _____zac_____  ...                   NaN              23.0\n",
              "1              2         ___aleia  ...                   NaN              19.0\n",
              "2              3          ___Dals  ...                     F               NaN\n",
              "3              4  ___schaeffer___  ...                   NaN              22.0\n",
              "4              5   __andresiscool  ...                     M               NaN\n",
              "...          ...              ...  ...                   ...               ...\n",
              "3275        3276       ZTheBest33  ...                     M               NaN\n",
              "3276        3277          ztran53  ...                     M               NaN\n",
              "3277        3278        zupercar1  ...                   NaN              21.0\n",
              "3278        3279         ZWHITE93  ...                     M               NaN\n",
              "3279        3280        zzzakari4  ...                   NaN              21.0\n",
              "\n",
              "[3280 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-q7uFgPbMcb"
      },
      "source": [
        "#convert categories to numbers for human.labeled.gender and lexicon.gender.prediction\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "df_labeled = df_labeled[df_labeled['human.labeled.gender'].notna()]\n",
        "LE = LabelEncoder()\n",
        "df_labeled['human.labeled.gender'] = LE.fit_transform(df_labeled['human.labeled.gender'])\n",
        "df_labeled['lexicon.gender.prediction'] = LE.fit_transform(df_labeled['lexicon.gender.prediction'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "i1BfdF01b0ei",
        "outputId": "c69f6fd0-e43a-4c85-cd48-0eaad55f7b80"
      },
      "source": [
        "df_labeled.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>user_id</th>\n",
              "      <th>lang</th>\n",
              "      <th>name</th>\n",
              "      <th>location</th>\n",
              "      <th>description</th>\n",
              "      <th>protected</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>statuses_count</th>\n",
              "      <th>favourites_count</th>\n",
              "      <th>account_created_at</th>\n",
              "      <th>verified</th>\n",
              "      <th>profile_banner_url</th>\n",
              "      <th>profile_background_url</th>\n",
              "      <th>profile_image_url</th>\n",
              "      <th>user.name</th>\n",
              "      <th>num.tweets.used.Lexicon.prediction</th>\n",
              "      <th>Lexicon.age.prediction</th>\n",
              "      <th>Lexicon.gender.prediction..index.</th>\n",
              "      <th>lexicon.gender.prediction</th>\n",
              "      <th>human.labeled.gender</th>\n",
              "      <th>human.labeled.age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>___Dals</td>\n",
              "      <td>4.361882e+08</td>\n",
              "      <td>it</td>\n",
              "      <td>_ê_ê___ê__ê_ __</td>\n",
              "      <td>NJ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>3744</td>\n",
              "      <td>1465</td>\n",
              "      <td>97563</td>\n",
              "      <td>22499</td>\n",
              "      <td>12/13/11 22:07</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/43618822...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme14/bg.gif</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1267852466...</td>\n",
              "      <td>@___Dals</td>\n",
              "      <td>100.0</td>\n",
              "      <td>30.628957</td>\n",
              "      <td>0.734656</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>__andresiscool</td>\n",
              "      <td>1.030000e+18</td>\n",
              "      <td>en</td>\n",
              "      <td>Andres Navarro</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>245</td>\n",
              "      <td>184</td>\n",
              "      <td>8731</td>\n",
              "      <td>18574</td>\n",
              "      <td>8/27/18 5:21</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/10339476...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1272229718...</td>\n",
              "      <td>@__andresiscool</td>\n",
              "      <td>100.0</td>\n",
              "      <td>21.014222</td>\n",
              "      <td>-1.623685</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>__blowCeeKisses</td>\n",
              "      <td>9.795642e+07</td>\n",
              "      <td>en</td>\n",
              "      <td>Soleil _´Ù_</td>\n",
              "      <td>Murda City, MI</td>\n",
              "      <td>Rihanna Stan _Ç___ locÈd queen trusting t...</td>\n",
              "      <td>False</td>\n",
              "      <td>692</td>\n",
              "      <td>754</td>\n",
              "      <td>57586</td>\n",
              "      <td>11811</td>\n",
              "      <td>12/19/09 18:43</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/97956420...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme11/bg.gif</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1274226895...</td>\n",
              "      <td>@__blowCeeKisses</td>\n",
              "      <td>100.0</td>\n",
              "      <td>26.934912</td>\n",
              "      <td>-0.024200</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>__Bone2</td>\n",
              "      <td>2.276869e+09</td>\n",
              "      <td>en</td>\n",
              "      <td>Bone Beezy_êç</td>\n",
              "      <td>Cleveland</td>\n",
              "      <td>God First! University Of Charleston Alumni HT$...</td>\n",
              "      <td>False</td>\n",
              "      <td>1491</td>\n",
              "      <td>869</td>\n",
              "      <td>16552</td>\n",
              "      <td>24584</td>\n",
              "      <td>1/5/14 0:58</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/22768692...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1267585783...</td>\n",
              "      <td>@__Bone2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>19.886660</td>\n",
              "      <td>-3.282048</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>__dennisa</td>\n",
              "      <td>3.004387e+09</td>\n",
              "      <td>en</td>\n",
              "      <td>dennise</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>143</td>\n",
              "      <td>129</td>\n",
              "      <td>21089</td>\n",
              "      <td>20282</td>\n",
              "      <td>1/29/15 21:47</td>\n",
              "      <td>False</td>\n",
              "      <td>https://pbs.twimg.com/profile_banners/30043869...</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1243741019...</td>\n",
              "      <td>@__dennisa</td>\n",
              "      <td>100.0</td>\n",
              "      <td>26.773361</td>\n",
              "      <td>0.531561</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0      screen_name  ...  human.labeled.gender human.labeled.age\n",
              "2           3          ___Dals  ...                     0               NaN\n",
              "4           5   __andresiscool  ...                     1               NaN\n",
              "5           6  __blowCeeKisses  ...                     0               NaN\n",
              "6           7          __Bone2  ...                     1               NaN\n",
              "7           8        __dennisa  ...                     0               NaN\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "9chFbjGpd8tM",
        "outputId": "421fe94e-282a-4afb-9759-a521e5e63004"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Username</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>JayHolz410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>kelechief</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>VicSpencer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>ItsAlexDodson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>xopinkvodka6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID       Username\n",
              "0   1     JayHolz410\n",
              "1   2      kelechief\n",
              "2   3     VicSpencer\n",
              "3   4  ItsAlexDodson\n",
              "4   5   xopinkvodka6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gv_uF5lDNWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e345778e-2cf7-4538-d5e8-e3786ea9435f"
      },
      "source": [
        "user_list = df_labeled['screen_name'].tolist()\n",
        "#id_list = df_labeled['user_id'].tolist()\n",
        "print(user_list)\n",
        "print(len(user_list))\n",
        "pred = pred[:264]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['___Dals', '__andresiscool', '__blowCeeKisses', '__Bone2', '__dennisa', '__greatperhaps', '__KDA_', '__shawtyx3', '_AJoseph_', '_alfiee11', '_amina_r', '_aniyagraham', '_Baaaates724', '_BattsMan_', '_briannadevaux', '_celiaaaxo', '_CoVeRtToWn_', '_dandysandi', '_DemiNeutron', '_dxVi5', '_elisamtz', '_Eric____', '_espibarrera', '_EWillB', '_Fanaticday_', '_FatThor', '_GabiBozeman', '_Gavin0304', '_gilliansummer_', '_GiuliannaTapia', '_haileyevans', '_Huey93', '_ItsLinaa', '_Jaavvii', '_jameshatfield_', '_jaydezha', '_jonstephen', '_kbatch', '_keagannn', '_Kellyann_C', '_Kingdarrion', '_knweedman', '_lexi_lopezz_', '_liamday', '_lilgremlin', '_madisonage', '_maradelgado', '_megodeck', '_moebettaa', '_mvmacita', '_nikkidaniellee', '_notblakegray', '_olisehh', '_PAULWHISKEY', '_reneejoanne', '_rorr_', '_sacredHeart', '_sebas365', '_selgo_', '_tayloralexis13', '_tayshel_2', '_xogloria', '05Panico', '10oso1996', '1DanLawson', '1grn_eyez', '24_archito', '2no_avail', '2raosanjiv', '307cork', '312dude', '3toughsons', '40zandshorties', '4vyom4', '6Fubae', 'a_garcia23', 'A6thSense', 'aabramson', 'Aamot4life', 'aaronwarnick', 'abbsoxo', 'aBigMess', 'absolutexangel', 'acvalens', 'AddaRigby', 'Adrianaa_9_', 'adriannamorriis', 'adventurecbd', 'agsair', 'ahegaoemoji_', 'ahncruz423', 'AhrenGray', 'aimeecow', 'AIMTOKILLEVAN', 'ainhoairin_', 'airmescain', 'AishaAlMuslim', 'aj_flu', 'aja72425899', 'AkechetaCatori', 'AlaaMuz', 'alainaehle', 'alanmhancock', 'aleabigail45', 'Alecjenson', 'alenajarvis324', 'aleneaaa', 'AlexArmenta36', 'alexfriesenn', 'AlexHpackMiller', 'AlexisMcKayy', 'alexolsen24', 'alexsitaaaa', 'alexx_101', 'AliciaLeeFarns1', 'AliciaStayReal', 'alienlilith', 'alisonannyoung', 'AlisonBuki', 'alisonw0nder', 'AliviaDufay', 'allen_hegener', 'allenahrhyan', 'alliebruy', 'allthepaper', 'alonxoxodra1', 'alorahjade', 'alt_Castiel', 'alterniite', 'altuzarrah', 'AlysenDonahue', 'Alysonspell5', 'alyssa_cusack2', 'alyssa_marr', 'Alyssa_Rose03', 'alyssakochy', 'alyssamurphy', 'AlyssaWeymann', 'Alysson', 'alyyykat', 'amandadowdm', 'amandakater', 'amandariveraaaa', 'AmberBenson', 'amberisthecoIor', 'amberlunaaa', 'AmberLynnGilli2', 'americafirst217', 'amy_chafee', 'AmzGrace56', 'anaevardone', 'Anahicazares02', 'ananolascoooo', 'Anashtisul', 'andishehnouraee', 'andreaclaire33', 'andreacorbito', 'andreamazing', 'AndrethaKnight', 'Andrew__Larsen', 'Andrew_Baxter23', 'andrew_carruth', 'andrewbutlerr', 'AndrewGunn_', 'andrewjfiore', 'AndyHolt4TN', 'andymagnes', 'angelagwalters', 'AngelykkaMarrie', 'angieantell', 'AngusDwyer', 'AnimeXFan2016', 'aniyahLanae04', 'anjanaaaaaa', 'annaarnoldd', 'AnnaManae', 'annayewt', 'Annie_Mac27', 'anniecox_', 'anniethefischer', 'AnnikaTuttle', 'Annotto', 'aNOLEnymous', 'anotarian', 'AntasiaAdamjee', 'Anthony_2valve', 'anthonygaetano_', 'Antonio_giron16', 'AntonioReyX360', 'anudawn_', 'anxious_maria', 'apjicot', 'ApocalypticaNow', 'aquameleon', 'Aracely21211915', 'araikaym', 'ArcadiaMikeRiz', 'arctanprime', 'ariel_erose', 'ArielRayy', 'arleneeramirez', 'arlenejuarez_', 'ArleneRyndak', 'artherio', 'Artsmah_', 'asapmari', 'aschalee', 'ashahoffmn', 'AsherRehsaa', 'Ashin_Kusher__', 'ashleighlayer', 'ashlybillings', 'AshTheBaby_', 'asntiddys', 'AstroValerie', 'Atheist_T_Girl', 'atheistemily', 'AtomicSonic', 'Atuuttt', 'AudreyS23511436', 'AudreyVerfurth', 'aurorabisig', 'austin__vance', 'AustinRatzki', 'autismepi', 'averyshaye', 'AwfulWally', 'awizzzzz', 'axelfoley12', 'AyalaDeer', 'aydin091', 'AyeChrisMendez', 'ayoitshannahh', 'AyyJacob24', 'ayyyy_tay', 'ayzhia_ayzhia', 'AzAnnabel', 'AzathTV', 'Azazel0928', 'AZcbw', 'baaaaaylee', 'babeslovegabe', 'babycay37', 'BabyTommyTorres', 'babyybeluga_', 'badmonalisas', 'bahdbambi', 'BaileyCoatoam', 'BaileyMalia', 'baileyymeredith', 'bame_keegan', 'BammerJH', 'bananasplitbrie', 'BaNenass', 'BankrollJP', 'barbabun', 'Barbara37152749', 'Barbatos25', 'BarissaBad', 'BartlettErica', 'basically_adri', 'basicllybella', 'bauhausboi', 'bayleighf97', 'BayyBruu', 'bbkwiat', 'bbumblepupp', 'bbutton2010', 'Beachlife0769', 'beauvans', 'beazyb5', 'becbecbobec__', 'Beccs_15', 'BeckAndersonID', 'beckygilley13', 'beerandnosh', 'beesbrain', 'BekahFern', 'Ben_Johnson15', 'benviagas', 'bequitaQ', 'beshevatal', 'beth40days4life', 'BethBSwartz', 'bethrosenstein', 'beulahdude51', 'Beverlyb11', 'BGHEPE', 'bianca_barraza_', 'Bianca_mata_', 'Biancaaaa_21', 'BiblioFiglio', 'Big_James123', 'bigfack', 'bigg_mike217', 'BigJJournalists', 'bigladypimpinHL', 'BigVixie', 'billclevenger', 'billheads', 'BillTooke', 'billyduprey', 'bishman316', 'Bishonenknife', 'BizzyVick', 'bjoewolf', 'bjorlax_', 'blackcat3119', 'blackmansVW', 'blackmon_ross', 'blake_ohdam', 'blakefisher_', 'blasejaise', 'blessdndeed', 'BLITZENTERPRISE', 'Blk_Intellect', 'Blonde_Bunnie', 'blondebabe46', 'Blooming_SAJ', 'bluntneeks', 'blurhill', 'bmoleary', 'BobbyBarcelo', 'BodyForWife', 'bojanamxo', 'bombshell2119', 'BondzBoy007', 'bonecrshr', 'boostkyd', 'BossRVA', 'BostonBridget', 'Boyers_10', 'BradHeat', 'Brady_McCormick', 'bramflake', 'brandishepherdd', 'brandonawilson2', 'brandonroobz', 'BrandonStepka', 'Brandt_Markie', 'BraylenNapier', 'brazeltonnn__', 'bre_garcia_', 'breannabelleee_', 'BreannaHBenoit', 'breannh8syou', 'bree__doee', 'BrendanMortimer', 'brennanccaber', 'brettdonar', 'BrettJ33', 'BrettJamesGallo', 'Brian_PriceNYC', 'brianalin99', 'BrianDeRemer', 'brianulizio', 'brianxdin', 'briiivn', 'BritnyBollinger', 'britt_mallow', 'Brittany_Lynn__', 'brittyrog', 'brivashti', 'BrizMoni', 'bro_salie', 'brock__copas', 'BroganDaphne', 'brookeeegabriel', 'brooklynmc04', 'brooklynpstory', 'BrownjulieJulie', 'Bryan_275', 'BryanaPaulino', 'BryanKolb73', 'Bryce_imai', 'BryceGirdner', 'bryceless', 'BSlimInDaCut', 'Bubba9856', 'buckyp_', 'bullcitystorm', 'Bullet546', 'BurmistrzakJ', 'ButchWal', 'buzbeebooks', 'Buzzkill59', 'byee_feliciaaaa', 'bylauragomezr', 'byLaurenTaylor', 'bynumhailey', 'byowenbenfield', 'Byron_Pineiro', 'cachetitos__', 'caileeswan', 'caitiewompus', 'Caitikinns', 'caitlinrain', 'caitonw12', 'Caitynedwards27', 'calista_kweon', 'CallaghanPeter', 'Callumgraphy', 'calnevsafety', 'camdynpauk', 'cameronrene34', 'camlee60', 'CamlynG', 'Cammeh18', 'campbe11emma1', 'CamrinPfluger', 'camronmoniz', 'candicetobin', 'CapnDesDes', 'careuhleenuh', 'carguybilly', 'carliejohnson01', 'CarlitoManchito', 'carlmb88', 'CarlParnellJr3', 'carolinemanno', 'carolroberts67', 'CarrilloWestley', 'CarsonEWallace', 'carupanero', 'casenieb', 'caseydanielg', 'cashbackid', 'cassiepurry', 'CassKyla_', 'catejanusz', 'catwarships', 'Cauble', 'CBD1129', 'cbdwaterbed', 'CBerrios62', 'ccgirl', 'cchauvet', 'cdsilva225', 'ceire_q', 'celineethebeann', 'cfhockey35', 'CG10_CESAR', 'CGang85', 'CGarrettPadilla', 'CGH_x_', 'chaneIIas', 'CharlesRandolp3', 'CharleZeus_', 'Charliesmith87', 'charnetzki3', 'chase_holstrom', 'Chase5021', 'ChavezGilci', 'chedfisher', 'ChefDee98', 'cheskittta', 'chestmedicine', 'Chey_enn_e', 'chhhloooe', 'chicagooan', 'Chickapea60', 'chiddy_O', 'childishwilson', 'ChiTownLawyer', 'chrisdanne2', 'chrisdesalvo34', 'chrisgoodmanlex', 'chrisknowlestv', 'ChrisLevinson', 'chrissth14', 'ChristianBd_', 'christianminaj1', 'ChristiansFeed2', 'Christie_Ileto', 'ChristinamEarle', 'Christo52317208', 'christy_eckels', 'chrisvxz', 'ChronicTami', 'ChyC_', 'ciiarajade', 'cilla_contreras', 'CindyMonty', 'CinthiaKMarie', 'cispt2', 'citgoman21', 'cjenmm', 'CJF_NC', 'Cjkapp', 'ClairReynaud', 'Clay_casey', 'ClayNFerno', 'clE_aaron5', 'ClintNims', 'Cloudyktae', 'ClovisMint', 'cmjohnston06', 'Cmularz_3', 'CoachMeMaria', 'cobynovak7', 'COConservataria', 'Cody_TGM', 'CoenLollis', 'Col10Huds', 'colbi_maurer', 'ColeIchida', 'Coleman_cibs', 'colin_jackson5', 'CollinStan', 'Connee_Marie', 'connolly_carrie', 'Connorlassiterr', 'continuants', 'coolhandjennie', 'corkscrew67', 'CoronaCoreanici', 'CoryPerry', 'countessofcloud', 'courtcat55', 'CourtneyLuther4', 'CourtReed', 'CPart24', 'CPfreely', 'CptxCurbStomp', 'crazyprofessor', 'Crington', 'cristian65o', 'crockpotdeath', 'Cromero5oh', 'crystallinesd', 'csmurray27', 'csurgtech', 'cute_commie', 'Cutepacabra', 'cutetiapine', 'CvilleCyber', 'CxmpWxs', 'CydTrilla', 'cymiller14', 'D_Wilcoxson', 'Dabbin_Daddy', 'dada_issues', 'dadnamedbrad', 'dafarnum', 'dafranchise_', 'dalwpal', 'dan_ilag', 'dan_tracey3', 'danielanievesss', 'danielehare', 'DanielElkin', 'DanielleDeevert', 'Daniellersss', 'danielleward', 'DanielS2000b', 'danijunebug', 'Danikawall2', 'DaniSki13', 'danni_gioia', 'dannnimorgan', 'danpincus', 'Dante_Etnad_', 'darrenrovell', 'DataDavidDeluxe', 'davedaniels', 'davegoldhahn', 'davemanuel0', 'David1904OG', 'David36191644', 'davidgsIoT', 'davidheinzmann', 'DavidRFisher17', 'dawwveeed', 'daydaay', 'dayman23', 'DBagg_', 'dcckm', 'ddias0014', 'ddouglasgoody', 'Decal_Gal', 'deeply_Zinc', 'deesbarbara', 'delaneyyschmidt', 'deliasalcido', 'Dentonite84', 'Denverdood', 'DerwinWorrell', 'DeSchlong', 'destinylafave22', 'DestinyMac1', 'dev_monet', 'Devan_Euans', 'deviantlight1', 'DevilKnotty', 'DevonAdams11', 'devonhailey31', 'deydey_14', 'diaksnkayaks', 'diamond_022', 'dianadotjean', 'dianejcarter', 'dianeri5', 'dickyjay357', 'dietsch', 'dinoLAUR99', 'DirtyGert', 'DirtyPrune', 'disco_socialist', 'ditzyspell', 'divinedierra', 'djfoxxtrott', 'DjMatchiz', 'dkbascom', 'DKR_independent', 'DLNYHO', 'DmitriyKizhikin', 'Dmpe_141', 'DOCTORHELLOW8YM', 'DohnJolsen', 'Dola_Billz_954', 'Domi_vivian15', 'dominiiique__', 'DonaldEScott1', 'DonataLueck', 'dondvjr', 'DonJonSlaughter', 'dontpanic1955', 'Dope_Desi', 'dosnostalgic', 'DougKlaaJohnson', 'dr0ss34', 'dramaticclaire', 'Dran0n', 'DRDishman', 'DrewWolsky', 'DrFredPHS', 'DrIanWeissman', 'drkwingduck', 'drnknluvv', 'DrRandyFriese', 'DrTiffTaft', 'DruncleSamm', 'drvox', 'ducksinrows', 'duenas_irving', 'DUHHCOATUGHH', 'DylanDunman', 'dylanw', 'DynastyR6S', 'DysIsMatthew', 'EastCoastBlazed', 'EBAlvarez', 'eccentric_mia_', 'eckomitchell', 'Ed_NewsJunkie', 'edgy_cacti', 'Editorspic', 'edmacidqueen', 'edumbass_', 'eebarnes1400', 'efboltz', 'eidetickinetic', 'ejayboii', 'ejw__', 'ElainaPickles', 'elenaalece', 'ElGromitio', 'elicelestecohen', 'elise__fowler', 'elizabethkuebel', 'ElizabethMAlex', 'ElJefeLimas', 'Elliegator123', 'Elliott_Sadler', 'elsafuerst', 'elyssabaird', 'embee13', 'emberrs', 'EmEllllis', 'emidesudesu', 'emillywallsh', 'emily_flaig', 'Emily_MacIntyre', 'Emily_McMinn', 'emilyliford', 'Emilymariebohn', 'Emilyrutledge01', 'Emilyy20Emilyy', 'emilyyspraker', 'emma_palmer14', 'emmadonnbledore', 'EmmaLetky', 'emmalinm5', 'Emms317', 'emricchini', 'emsbari', 'emsdan148', 'Ena_Hodzicc', 'energy_ann', 'eraserheadbabby', 'EricelleC', 'ericjschuster', 'EricSeconds', 'erin_belle_', 'erinehebert', 'erinn_ward', 'Ese_JJ7', 'eurobeatboomer', 'evaaanicoleee', 'evalporter', 'evilchrisj', 'eyeamminotu', 'eyelightter', 'ezra_elise', 'F_Hall', 'F3CousinIT', 'fairygodmary', 'faithlhall', 'falcowitz', 'FalenGillespie', 'faroffeyes', 'fatboyoso', 'fdknight', 'fedor4', 'FeehanPres', 'feelinsmall', 'felicityokay1', 'feliidaes', 'felip_aye', 'fenbrazier', 'FeralCatholic', 'ferrermd', 'ficklenuts', 'firebreather144', 'firewat4', 'FlawedDreaming', 'fledglinguistic', 'Fletchlight_', 'flipyourLYD', 'FloatingFishPoo', 'FloppyGoffer', 'Flygirl0916', 'FM_DarkerHorse', 'fmkillakid', 'FocusedCompound', 'followthatband', 'fran_elaina', 'FrankTheKoyFish', 'FranSzpylczyn', 'frazzledjazz', 'FreakingxFeb', 'freakyfriA', 'Freny101', 'Freuds_Worst_Rx', 'FriskJoshua', 'Frogofthelaw', 'Frostay_', 'fufflebutt', 'FynnBurow', 'g_medley7', 'g0rnelas', 'gab_matthews', 'gabby_reding', 'gabbyjaaay_', 'GACKSTETTERLEII', 'GageColeman0404', 'GageDinan', 'GalaxyGodMatt', 'gamewillpdx', 'garv67', 'GaryLABirge', 'gawdz0rz', 'GC_Sherman', 'gdbttw', 'gecaj_chris', 'Geeky_Jay9', 'GenAirwreck', 'genebeesknees', 'Geniviva', 'gentledragon66', 'GeograspTV', 'georgeokc', 'georgieeeeadae', 'germmy__', 'GETSETFREENOW', 'gettemchris_', 'gettinghighwith', 'ghbledsoe', 'GildedSantiago', 'gizzz23', 'glacich', 'glassashleyy', 'GlobalMediaBuzz', 'glowitter', 'gmalmatos', 'goalkeeperking1', 'GOATGabriel', 'goawayhav', 'godsandlanas', 'GodsLoveHeals1', 'GoldenDonQ', 'goldilx16', 'GoldSoulSwank', 'GonyeaBryant', 'GoodBoy10204293', 'GoodMorgenMusic', 'gopvikeen', 'gothgranny_', 'Grace__Tuttle', 'Grace3305', 'GreasyTonys', 'gregavilashah', 'gregbroadwell', 'gregorypoor', 'grevealyssa', 'GriffithJen', 'GrimAllison', 'grxpejuice', 'guerrette79', 'gummybears1300', 'gurkinboonloop', 'gutterbruja', 'GYoung3017', 'ha13yparks', 'haileybrown32', 'haileytirado', 'Hairweaveboss1', 'Haley___ellis', 'Haley_T_143', 'haleyeyeyeyey', 'haleyglaze18', 'haleynicohl', 'HaleyTadlock', 'HALFLlT', 'HaliPawz', 'Hana4House', 'Hann_333', 'HannahBasques', 'hannahcpreston', 'hannahreneee2', 'haplessromantik', 'harryburns5680', 'HarviliczTammy', 'hbk_korbo', 'heatherswifty', 'heidinoell', 'hellahellacious', 'herbertholler', 'hethrnes', 'hey_claire', 'Hey_Meghan', 'heykatiemay87', 'hglolz', 'HiDefDanceAngel', 'HipHopHeadJerry', 'HippyHill_', 'hitaylord', 'hitmekb1mortime', 'hollalalolly', 'hollertheballer', 'hollishamilton', 'hollyannahope', 'holyheckitshope', 'HooliganNY', 'HopeNoellee', 'hornypancakes', 'Hounddog8434', 'HowBoutDemOsHon', 'hrobert454', 'HRokadiaMD', 'htravis14', 'hughbartling', 'huhwhatmoo', 'Hullzyy_', 'HusbandLauri', 'hyjjus', 'HyperboleGrant', 'iamjohnnd', 'IastIivingsouls', 'IBussolotta', 'IcarusCrusader', 'IceLxrdJay', 'ight_b', 'IilShammy', 'ilianadays', 'illStefanmatic', 'ilovesparky3', 'imadamcollins', 'imDanielValdes', 'ImDeweyy', 'ImJcon', 'ImSoSarah', 'ImZefx', 'ineedmycrown', 'ineedsommilk', 'InfamousDucky', 'inlovewithweed', 'InstaLukeDuke', 'iOG_eazy', 'isaackrakowka', 'IsabellaLitchka', 'IsaiahFromThe6', 'isisnavena', 'iso__tovar', 'isrodent', 'iSwampDweller', 'ItMeansFaith', 'Its_Joshhuwa', 'its_melo2', 'its_nicollex3', 'ItsBeeBreezy', 'itsenufalready', 'ItsGracieeBaby', 'itsjustvivee', 'ItsKiddMisfit', 'itsmicchilly', 'itsyaboiKris', 'iTwon', 'IVHoop', 'iYoung1__', 'izzy_fleenor', 'j_angliss', 'J_Cuban24', 'J_Steinberger97', 'jabs611', 'Jaci101', 'Jack_Whiteman', 'JackDamn', 'JackJohnnieMac', 'jackyboy210', 'jacobbbray', 'jacobcthefirst', 'jacobrowland123', 'JaeMariex3', 'JagerX', 'jaguar_1006', 'jaidenpope_', 'jaime__lsb', 'jaime_0916', 'jaimelcabrera', 'Jaimepfloress', 'jakehc_22', 'JakeJrciv', 'jakepie97', 'JakeRegan_', 'james_koffler', 'jamesbade474', 'jamesm10983', 'jamesreyesgrant', 'jamie_mntr', 'JaneStanley64', 'jannamaee1', 'JanzielAlamo', 'JAPiacentini', 'jarad44bulpin', 'Jared_Boyce', 'JaredCutts1', 'Jasmin7230', 'JasmineYui', 'jasonneucere', 'Jass_Victoria', 'javii_sotoo', 'javon_holmes', 'JayJay_310', 'JayneeCollins_', 'JayRJordan', 'JazzyJadeHarley', 'jbro_convo', 'jbry44', 'JBullock35', 'Jcbartone', 'jchimselfbigpo2', 'Jckschrdr', 'jdeucee35718', 'jdmmxo', 'JeffCheney', 'JeffreyTowson', 'jenn_gerhard', 'JenniForsmann', 'Jenniliciousxo', 'Jennmprins', 'JennSchanzWXYZ', 'jennsters16', 'jeonspassenger', 'JEPR320', 'jericmendoski', 'jess_paigej', 'jessehe18', 'jessenaluna', 'JessicaVelle', 'jessiicaguan', 'jesus_juul', 'JesusBeDrunk', 'jesuswater666', 'JETMEDIA2', 'jeweleawnuh', 'JGucciCuh', 'Jhannigan445', 'jhaveri_komal', 'JhoelFrancis', 'ji_nkies', 'Jim_WGEM', 'JimClerkinRadio', 'JimiDevine', 'Jimminy', 'Jimmysimo_', 'jimstroud', 'jinni_mcc', 'jjtrey1', 'jkaiulanif', 'JKrew2', 'jkrew44', 'jle0na', 'jlemley_', 'jmadds0', 'jmadss13', 'jmesstuff', 'Jmurraybil', 'JNATH86287623', 'jnnyhg', 'JNobeSr', 'Joan21788838', 'JoaquinLopez85', 'jobertaro', 'Joel_Howard', 'joelmsiegel', 'JoePowerMcGarry', 'joew8302', 'JoeyGold24k', 'Joeymamunes', 'JoeyMancuso21', 'John_Harland', 'johnebel', 'johnkaiser13', 'johnxmar', 'joliegauvain_', 'JolysaMcKay', 'jonah_german', 'Jonesinfilm', 'jonny868', 'JonnyBigBlock', 'jordannnsimmons', 'josee_cruz5', 'JoseMattle15', 'JosephineShaker', 'JosephT_music', 'joshcokerrr', 'JoshReddick13', 'Josiasakakix94', 'Josie0430', 'JosieePadilla', 'JoslynHammond', 'jouradn', 'JovanaBulatovi', 'JoyJenn1', 'jp_bourget', 'jpappafotis', 'JPert13', 'Jr_Biggie_', 'Jr_Palladino', 'jr08_', 'JRMRS22', 'Jrz04Melissa', 'jsnsexton', 'jtierney6', 'JTursich', 'juanelberto', 'JuliaCoty', 'JuliaRosarioo', 'juliedianeexo', 'julieoriglio', 'JulioFranko17', 'JulisaBernal', 'Juneeee_20', 'JunkFc3', 'JussDrums', 'just_m0en', 'justamber09', 'JustinAlmighty', 'Justininoo', 'JustinWPruett', 'justjensart', 'Jxllxn', 'Jziegeldorf', 'Jzientz', 'k_moore123', 'kaelialexys', 'kafffferine', 'KaileeSullivan2', 'kaitapgar', 'kaitlinbc11', 'KaitlinXTesla', 'kalanigaddyy', 'KaLebSpEIlMan74', 'kalee_renee', 'KalishaPhaiboun', 'KamBarr55', 'KariannNicoler', 'Karl_Carr', 'Karl_Deigert_RX', 'karmensmithivey', 'kasailapaige', 'kashmoneykamri', 'kassahndra', 'kasssino', 'kateannelle', 'kategleske', 'katelyndowse', 'katevictorriaa', 'katherinecabr', 'kathleenhayden', 'KatieLemoine', 'katierosman', 'katrocada', 'katthequeen_', 'kay_benz_', 'kaykayrozay_', 'Kayla_Setti', 'kayla_wallace90', 'kaylalivyy', 'kaylawalker__', 'kayleelindd', 'kayray', 'kaytlan14', 'kbunnx3', 'kcarpenter5', 'KChatwin22', 'KDNNRS', 'KeepRuminating', 'KeithMShaffer', 'keldoller128', 'kellyh2199', 'kelsiedeanna', 'kendall_maxey', 'kenkenlicious', 'Kennaboo911', 'KennaShirer', 'KennedyHughes9', 'kenney_owen', 'kennysouthwell', 'kenzlaplace', 'kern_michael', 'kg4gwa', 'KhalaniIman', 'kharyp', 'kiara__10', 'kieahwilley', 'KienYouNot', 'KIERAsaidTHAT', 'Kikideliver_', 'KILLAEI99', 'Kimberlynngg', 'Kimberryjugo', 'kimmiecatttttt', 'kimmythatgirl', 'KindaCurvedDick', 'KingMatttt', 'kingmecvc', 'kinsey_chase', 'KirchsComet247', 'kirxstin', 'kishkedeesmom', 'KissMy_Elegance', 'Kiyanalovee', 'kjgonzo3', 'kkatelynreese', 'kkdonutslinger', 'kkqtopeka', 'KL04655767', 'KMerrit13', 'KMorsett', 'KneenaMarie', 'kobey224j', 'KolbycIsMe', 'Koolmom12Nance', 'kris_10smith', 'kristi_falbo', 'KristinTomoff', 'KristiRawlings', 'krystalxevette', 'kspringsss', 'ktazwells', 'kuladudette', 'KyanKento', 'KyleeRenaee', 'kymcfarland', 'KyraInABox', 'kz457', 'LabbieJake', 'laeldubz_', 'lakrenek', 'LamboForte', 'lanaisamonkeyy', 'langwiser', 'lanie_jns', 'LaRompeToto', 'lauraxoisabel', 'Lauren420_69', 'LaurenLindsayDj', 'laurennn140', 'lauryn_elizaa', 'lauryn_jaydee', 'lauryn_quinn', 'lauurreenna', 'lawdforgivemee', 'LaydiexSkull', 'lazaruseffect79', 'lbateman40', 'lbgoforth1978', 'lcortner09', 'LDA_writes', 'leaaves', 'LeahCapezzuto', 'LeahOliver0502', 'leealvarado101', 'LeeBrewer2NA', 'LeemanRobertF', 'lei_fle', 'leilaclaire', 'leimer', 'Len_Evans', 'LesSuggs', 'lesxmoreno', 'levichpaige', 'lexnstuff', 'lgeisheimer', 'liamschmidt15', 'libragirlfriend', 'librawithcancer', 'Lil_Kermy', 'lilaahhh', 'lilangrybaby', 'lilbaabyhan', 'Lilebboo', 'lilgrand_', 'lilmike_2013', 'liltinyhumann', 'lindsayRaeg', 'lindsey_robarge', 'lindseybr00keb', 'lindseyy090', 'lis_sux', 'LisaIOP', 'LiseyFreije', 'lissavibes', 'Lissyd0ll99', 'littlelemon_boy', 'livefastdiejohn', 'livetolove_000', 'lizb411', 'Lizeth_J97', 'lizwithcon', 'Lizzifus0606', 'lizzoot', 'LJosephGarcia', 'lolocanavan', 'lolskatherine', 'lonelybabylon', 'LongLivHevyMetl', 'LooveKaroll', 'LordJoey615', 'lorena_anyssa', 'Lori_Charlton', 'lorynveilleux', 'lotsofjoon', 'LovelylLeger', 'Lozanology', 'lptutoringco', 'lucillemilles', 'LuciSkydyme', 'lucywright00', 'LukeLaidAndThin', 'lvxtlman', 'lydiuhhh', 'lydscott1', 'Lyndsey_Warren', 'lynnchloee', 'lyricalprisoner', 'lyssannj', 'm_hoag1', 'maaddiieebby', 'mad_th_jed', 'maddi_romeo', 'maddidailyy', 'MaddieAdams02', 'maddileighhhh', 'MaddisonNell', 'Maddsue4444', 'maddyluvsdaniel', 'madi_schaefer09', 'madieebosleyy', 'madiicarterr', 'madikreilly', 'MadisonHerron18', 'MadisonMaelynn', 'madsuder4', 'madyaholt27', 'magdahalina', 'maggie_717', 'maggie_meehann', 'maggiedtrack', 'MajestyJames1', 'makena1127', 'malaylayxo', 'mamacitamuerte', 'mandavillegass', 'mandersonville', 'mando_iman', 'mandy_j_riley', 'Maralan17', 'marbauer27', 'marco95altamore', 'MarcusMySelff', 'MarcyMartin07', 'Mari_aaf', 'mari_elyse', 'mariaa_salcedo', 'mariannecoffeyy', 'MarieNoelMiller', 'MarisaSobeski', 'marissadeblasie', 'MaritsaNBCMT', 'Marlowe79419796', 'marlzzzbarkley', 'martyrsdaughter', 'MartyWilliams17', 'marxinista', 'MaryBarbaraMar1', 'MaryELosch', 'marymargaretwe', 'marysavage1957', 'mashisoyeol', 'Masonpls', 'Matt_Phillips93', 'Mattbernal916', 'MattfromBerkley', 'Matthew69835043', 'MattLabor', 'MattReedNews', 'matzar12', 'Mauriciooo_G', 'mawisa_b', 'max_xam82000', 'maxo3284', 'Mayranation', 'mayravenzor_', 'MAZIE58', 'MazurekRebecca', 'McClutherness', 'McGeek77', 'mckinziegoble', 'mckira1', 'mckmil', 'mclanoux', 'McmullenRaelynn', 'mcrae_heath', 'megan_wolfe2', 'meganbb18', 'meganeliseeeee', 'megankill_', 'megannlindstrom', 'Meghan_Nasty', 'MeghanMcNerney_', 'megnewman19', 'megpriadka', 'MegSherlock', 'melanatedliz', 'Melissacaton4', 'Mella1281', 'memedithhh', 'MemphisSanta', 'meredithnoelled', 'metallidan', 'methredandllfan', 'mewbotz', 'mexicansugarr', 'Meyer_CE1978', 'mfatah281', 'MFFNtv', 'mfraz4', 'MFrederickM', 'mgencs11', 'mheffron12', 'MiaScotttt', 'micahmartinezx1', 'michael2irwin', 'michaelfranti', 'MichaelPartida', 'michexposures', 'Mighty23405', 'mikayla_roch', 'mikaylaxdavis', 'mikepaddock', 'MikeShe16309299', 'milesjoseph3', 'miliondollathot', 'millsyfbabyyy', 'millylilyrose', 'milsgoprod', 'mimij37', 'MindlessLez', 'minhthyfreshh', 'minorthreat1978', 'MireyahWolfe', 'MishaLawless', 'MissAngSays', 'Missin_Florida', 'missMARCELA_', 'MistyAue', 'MistyN10', 'MitchOnDrums', 'mitolizard', 'mjb1284', 'mmoe69_maureen', 'mneakin', 'mochiwovesyou', 'mohillbilly', 'MollySneed', 'mommadeen2', 'mongibeddu', 'MonkeyBlood', 'Monroy__17', 'montalvaan', 'MonticelloHoe', 'MonyQ', 'morgan_goulding', 'Morgan9Ashleigh', 'morganlpitre', 'morgmorgan25', 'MoserAlexis', 'MOSHxSPICE', 'MR_Classic_', 'Mr_JWalter', 'mr_sasz', 'mreestry', 'MrForsbergLHS', 'MrGoodluckXXX', 'MrMapleShade25', 'MrMattFoss', 'mrsbumble97', 'mrschimpf', 'mrsdelagrange54', 'MrSmiLeS666', 'MrTrevorHamil', 'Ms_Cecere', 'ms909698', 'msamandapandaxo', 'msdvvv', 'msoto1210', 'mulderisgay666', 'MundellRobert', 'munky_strike', 'musa_mtk', 'Mxrlene44', 'mxrquez___', 'MxTorrieFoxx', 'myrtleinjurylaw', 'Mystar4eva', 'mystikx20', 'mziobro_', 'nabbypatty', 'nadia_jaouad', 'najabailey', 'NancyatHeart', 'nanisalinas20', 'naomyvalens', 'NaraApricots', 'naragclan', 'narissafbrokob', 'NataleHalesmbj', 'NataleyNeuman', 'nataliefournell', 'NateNashGetCash', 'naterip9', 'natewrussell', 'nath_ngo20', 'NathanRamsey3', 'nathansmart', 'natitti_', 'natsilletti', 'NealTena', 'NECR0PARTY', 'nedalai', 'nemily65', 'nepalesruben', 'neptuneelevated', 'nervoucities', 'neshhaaaaa_', 'NessaMcmains', 'NewfoundNolan', 'nickdobbins22', 'Nickin616', 'nickkwheeler', 'nicoleewagner8', 'nicolesusanne21', 'nicovetch', 'NIGHTCR37274702', 'Nightlinez', 'nightsinger1942', 'NightVIIX', 'Nikhail13', 'nikimaghzy99', 'nikkiatkinson', 'NikkiSpeech', 'NinjaEconomics', 'nityed', 'nizaddy', 'NjayColes', 'nmdomo', 'noabournexo', 'noahalex35', 'nochillciera', 'NohelyMejia3', 'nohhhemy', 'NoRAd_Alpha', 'nostalgic_leah', 'NotCody00', 'notnicolaa', 'NotNova_', 'notorious_val', 'NotoriousIanV', 'notquitespooky', 'novarose92', 'nplg98', 'NtJustAnnieBody', 'nuggette__', 'NuggleTheKelpie', 'NursesCircle', 'nutmeggles', 'NVCrittenden', 'nvmdes', 'nvro_e', 'nvthvnmville', 'nyccookies', 'ObiWanJacobi_tv', 'octalmage', 'oddfutureevee', 'officialmaurixo', 'officialxjuliaa', 'OgAckerman', 'Oh_Ivanna', 'OhColeman', 'Ohitsbrii21', 'OhVonda', 'olandgren', 'oliveratlanta', 'olivia_hickey_', 'olivia_karene', 'Olmedic', 'omar_lizardo', 'omgitscaelyn', 'onlinevalerie', 'Onlyjuanchance', 'opelikaaligator', 'orangRabb', 'orlandomicki', 'OrleansCamille', 'oscarmventura', 'Osufan_71', 'otis', 'owenwhatever', 'ox_aln', 'Ozzy_Statesman', 'P_wilson83', 'PacHS_Calabro', 'paigealage', 'paigemc911', 'paingloss', 'Pam58622393', 'PamRotella', 'PaniceAllyssa', 'papa_shmup', 'papatvans', 'park_anders', 'ParkerSchrempp', 'ParkeyJennifer', 'PatsfanToro', 'PattMiles', 'PaulCurtiscoop3', 'paulstorms', 'Paydenstrizzle', 'PaytonSherman', 'Pbrandt4369', 'peachybellss', 'PeachyVal__', 'peggyrosepr', 'peltzie', 'PenaSteele', 'penelope8226', 'Penniii21', 'PentagramPizza', 'PepeClinton', 'PepinLachance', 'peterhassett', 'pfannyyy', 'Phelps_c98', 'Photog_JohnB', 'phouch', 'piercetherose', 'Pimpcenta', 'Pinkychelle', 'pinkytatum', 'pipecityy', 'PissedOffShrimp', 'pk_scm', 'platano_shawty', 'plees13', 'pmatons', 'pok3cs', 'pompey_lucas', 'poseidonette', 'powndhownd', 'PPonsetto', 'prettyandplummp', 'PrincelyOnion', 'Princess_in_NY', 'Princessscamm_', 'princessshenk', 'Procane09', 'Prodigy_JayBee', 'Prplhaze101', 'psepi', 'ptnapoleon', 'pugz1lla', 'QuathyInTheSky', 'queenawoo', 'queenbreeen', 'QueenCece_xo', 'queendollhouse', 'queenofthesou1', 'queenxmads', 'QueerPlatypus7', 'Quiggaveli', 'QuileIsREAL', 'quinntucky2', 'qvbrs', 'RabbsterMatt', 'rach_greenspan', 'Rachel3299', 'rachellabbq', 'rachelnoel__', 'RadMadbutFab', 'raeee_kayla', 'rainb0w_hat', 'raleldil', 'ramielanude', 'ransabot', 'raquelcalvoo', 'RaShAd_HuGhsToN', 'RaulJohsua', 'raviroy23', 'raysullivann', 'rayvenmoore', 'RCxrly', 'Rdusty10', 'realaaronmounts', 'realChadJohnson', 'realKaraLynn', 'realliltush', 'realphillipsA', 'RealReala', 'realRonnieJames', 'RebeccaCarmen', 'rebeccaspence72', 'rebekkamains', 'RecoveringProf', 'Redheaded_Jenn', 'reepsrolyat', 'reevynap', 'reharmon56', 'reichert_liz', 'renz360', 'RepDrewFerguson', 'reppocs', 'ReverendJon', 'RGarcia63', 'rhawk55', 'RHBrowning', 'RhondaRYoung', 'ricee_cake', 'Richardwisler', 'Rickmil69704052', 'ricktimbs', 'rigorrmorrtis', 'Rilaniii', 'rileighgraham', 'riloskir', 'RJurgy_12', 'Rob_L_Collier', 'robbyFNblaze', 'robbyjmoore', 'robert_tedesco', 'RobertS1ngleton', 'robertthepotter', 'Robin_McCoy_', 'Robynnlea_', 'rocnhog1', 'rogeliomartian', 'Rogeromfg', 'rohan98111', 'rohry_music', 'rollergir1', 'rolyatetak', 'Romayroh', 'RonHogan', 'roocrow', 'RosanneAzarian', 'rosehoban', 'roselynnn_1', 'RoweRikW', 'rriceboii', 'RSL012548', 'RubyRanda_', 'rudehunch', 'ruizphysique', 'RUOffendedYetB', 'ruthymunoz', 'ruxbat', 'rye_bread_bi', 's_cilla_xo', 'sad_grrrrl', 'saddbino', 'sadgirlfall', 'sadieanne01', 'sadpalemami', 'saesee_steven', 'sahara_hansen', 'SaintFDW', 'saleashuh', 'Salojoelina', 'SalsaPrice', 'sam_nunes_21', 'Sambytheseaa', 'sammiesammm42', 'samonella___', 'SamStout_', 'SandraGlanton', 'saniom1', 'sapphiceevee', 'saraaleone', 'sarahapanek', 'sarahellenbell', 'saraheneedleman', 'sarahhhaddonn', 'SarahMessina_', 'SarahTStewart', 'sarajeffy', 'sassy_gramma', 'saturnrosee', 'savannahnanbell', 'savbeckwith', 'Savvyy18', 'sawitwosw', 'Sawybeans_', 'sberghuis43', 'sbjames2327', 'SBocade', 'scabbyscribe56', 'Scarlet_Kitteh', 'scbaldwin', 'SCemensky', 'sckrjoe', 'scolipoliolli', 'Scotlandfog', 'scottconso', 'sean_chris10', 'Seattlesbadboy', 'SebastinNichols', 'seho82', 'selyna408', 'SenyapRaja', 'sergadry', 'SergSayz', 'sexbot2k', 'sh_rk_tt_ck', 'shakabrawl', 'shakdadday', 'shane_prender15', 'shaniahlavacek', 'shannicholls_', 'shannondl31', 'shannontwote', 'Shanzeenah', 'sharebear817', 'sharlenemc_s', 'SharonZJewelry', 'shaungriff', 'shawnngee', 'SheHasNoName999', 'sheiladelgadog', 'shelbaerobx', 'shelby_mcadams', 'shelbymuzny', 'ShellyLonginot2', 'sherijr', 'sherrykdelaney', 'ShesSteeleLoved', 'Shikona', 'shiloh_miller70', 'shimor', 'ShitNotYouAgain', 'ShortnSassy1990', 'SHSjacketvball', 'sierrasevier', 'siiddd7', 'Sir_Mart_Ash', 'Sirenscrytoo', 'sjmarkwood', 'sjsbeats', 'skyjjj', 'SkylieMarie_', 'SlickbackB', 'slkaplanmd', 'smhboba', 'smilemorepenny', 'SmokeSeattle', 'smoresmartin', 'Smuttysquid', 'SneedFOE409', 'so_curly10', 'SoberD4D', 'SodaCola52', 'Soenda', 'sofiilroy', 'solas_na_greine', 'SoOvrTheRainbow', 'sophiebushman', 'sophiekhadija', 'sp_acevex', 'SpacedOwt01', 'spacehailey', 'SpacePatrolLyle', 'spacerose94', 'SpeakerCoughlin', 'speshul_wes', 'spicytunarolll', 'spunkiscientist', 'SquallStaffan', 'Srslyomgwtfbro', 'ssagesk', 'ssliik', 'SsoDorian', 'sssydneyhehe', 'sstorm01', 'St0rmii__', 'Stacy_B', 'stainfacemane', 'starfallgoddess', 'Starz_Wayne', 'StateRepBain', 'steamboatwillyo', 'stefisbright', 'stelladcox', 'Stepha_Nie_Vee', 'stephaniedvine', 'StephenSailsPDX', 'stephmannn', 'STEVE_BOZIC', 'stevenmurillo21', 'stevenyangxx', 'stilchy', 'stonedcoId', 'StorySlug', 'stphil', 'StreetSouls16', 'Strike_CVI', 'strwbrrymlkt', 'stubdastud', 'subatomicdoc', 'Suck_My_Sam', 'suckafreeebri', 'sunoveristambul', 'SupaDolphan', 'superpixels', 'SupraN2Omar', 'surfkujo', 'suziraeee', 'SvechinLarisa', 'svveetalexa', 'swagger372', 'swalker_43', 'swamp_surprise', 'Swanny23', 'swavey_orlando', 'sweetestthreat', 'swerve2850', 'syd_wilburn', 'Sydney_Smith99', 'sydneywsanders', 'sydsheehan5', 'syorkMI', 't_abee33', 't_kawasaki02', 'T_Radz', 'TacticalFruit', 'TagleAlexx', 'takeashortROUTT', 'Tall_Ayden', 'taniella67', 'tanisharrao', 'TannerA_Olson', 'taryn_mackennaa', 'tatersaurusrex', 'taugenthaler', 'taylor_hockey8', 'taylorrdawnnnn', 'taylorrrdeanne', 'taythewelder', 'tcapspresident', 'TchouMd', 'tealeksunthon', 'Techgnostik', 'teddy_montoya', 'TedKoppyNBC', 'Teepers1', 'teghanbartee_', 'tellithowitis24', 'tenshioskar', 'terrellckeith', 'thalyamk', 'that_madi_chica', 'thatguyaj36', 'Thathigga', 'ThatJoeHerrmann', 'thattkay', 'The_Davenporter', 'the_Naypalm', 'The_Psi_Lord', 'the_ravefairy', 'The_Real_F_A_M_', 'the23rdjoker', 'TheAnxietyBoi', 'thebeast456158', 'TheBiggestUwU', 'TheBigManJimmyT', 'thebillbuchanan', 'thebiospace', 'thecandymancant', 'thecaseygram', 'thecgist22', 'TheChadow', 'thedaniidiaries', 'TheDeaconCash', 'THEE_TOMCAT', 'thefunction13', 'Thegabegarza', 'thegreatlexini', 'TheHannahLacey', 'TheJourneymanGC', 'thelatinochild', 'TheRealATCinema', 'TheRealLaBruna', 'TheRocketRalph', 'thescorpio69', 'theTRminator01', 'TheUncannySnail', 'TheWhaler', 'theyhatetaylor', 'thezobelle', 'thornsberry44', 'threadslut', 'thrown_salad', 'thumphries06', 'tiaralo_', 'TiaraMonee', 'tice_stacy', 'tiffanyharttt', 'tiffanyparkkk', 'tim_ronquillo', 'TimConnellyMD', 'TimJMasterson', 'TinSoldier6', 'TKyzer', 'TNRLM', 'TobyBaratta', 'todayimbecca', 'toddmitchell550', 'ToExcogitate', 'toiletliner', 'tom_mcmurray', 'tommygun083', 'tonightisabel', 'TONY73922959', 'TonyPlayboi', 'Too_ManyFaces', 'TooNastieTTV', 'toothpickisgay', 'Toraad4u', 'tornadolarkin', 'totally__kyle__', 'TotoTinmanAndME', 'Towndog3', 'toygodd', 'tracey_t_m', 'tradamfool214', 'trap_soullll', 'trapcoupe', 'travelinman1966', 'TravisYoung12', 'Travy_Trav_Trav', 'TrentDwyer30', 'Trevor__brown17', 'TribeCalledSeth', 'TriciaNolfi', 'TrishQuade', 'TrixSensei', 'troutbumsteeze', 'TroyMickle', 'truewert', 'tsa_hai', 'Turd__Ferguson2', 'tvalife', 'Twan_Tucker', 'tweetingLEB', 'tweetyrealtor', 'twentyy_8', 'twistedup_Nside', 'TwitchTreehop', 'txhoneydip', 'tydollatree', 'tyler_gulledge', 'TylerHoffman7', 'TylerInTheMakin', 'TylerKing_2', 'TylerOlson1791', 'typeogregative', 'tyramjb', 'UliGG_', 'UmTAW', 'UnbreakableHate', 'UncleBob56', 'Unique_By_Angie', 'unique_lache', 'Unknown_SoNn', 'uplinkal', 'uraww', 'ursa_majors', 'uwubabi', 'v_mengden', 'valenntinarave', 'ValerieDiS', 'VanessaDenise12', 'vanilla_lovve', 'VapeLvLMidnight', 'vapes_2_much', 'veixms', 'Verbesity', 'verzachyy', 'VicCudi', 'vicemackingtink', 'VictoriaSenese', 'victorsamayoa45', 'VikkiFusco', 'VintageProblem', 'VirginiaEllis14', 'VirtualFrankie', 'VMHS_Ritchie', 'vMotiionz', 'vondishea', 'vperez180', 'vpi75wood', 'vriless', 'vyemily_', 'VzNchy', 'walkingbazketz', 'walkthesun_', 'wannabegoat', 'WarrenSuperT', 'WATITIZWATZUP', 'WaylandGuidance', 'waywardstrav', 'wdthebeast', 'WeaselWords', 'wendy_guajardo1', 'Wes_wiens16', 'whoiscrura', 'whosjoey_', 'Why_Vet38', 'Wickerpedia', 'wiggeth', 'Wildheart_Baby', 'wildkatttt', 'Williamson_SR', 'willtraube', 'Willy_Rozay', 'woahh_daee', 'wolf_ezo', 'wolfofeastside', 'wootmoot', 'wordfromamabird', 'WordsmithWyle', 'worldisstoned', 'wright_brooklin', 'wrwagner97', 'wrxcrae', 'wthangel_', 'wvnkv', 'xbeautyxtruthx', 'xembearx', 'XenoCG', 'xi__exe', 'xkikibaby', 'XLcshe', 'xm_Cassie', 'xo__sel', 'xoashyboo', 'xolaibaaa', 'xSHOGUNDo', 'xTcaffx', 'xUnicorn_Gaming', 'xxpaigelovesxx', 'xXRageXSlayerXx', 'xxwindixx', 'y2vonne', 'yam_btw', 'yburyug', 'yeha_keelo', 'yellojmas', 'yeoldemack', 'yoonminsnana', 'YorkHouseCleanr', 'YouKnowJarod', 'YoungGas6', 'youngtoering', 'Yourfavjenn', 'yung_quick', 'Yunghatedbelo', 'yvettedivadance', 'YvetteManes', 'yvngbronchus', 'zachkobayashi', 'ZACHSORAVEN', 'ZacOutLoud', 'ZaliasFGC', 'zeldabynight', 'zepy32', 'ZionDood', 'znarikia', 'ZoeBerrier', 'ZoeCalamaco', 'zoeynicodemus', 'ZTheBest33', 'ztran53', 'ZWHITE93']\n",
            "2144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtMtINoPC0gW"
      },
      "source": [
        "username = user_list[0] # try one user first, we can loop over the entire user list to get all the user detail\n",
        "m3cachedir = \"drive/MyDrive/cachedir\"\n",
        "\n",
        "if not os.path.exists(m3cachedir):\n",
        "  os.mkdir(m3cachedir)\n",
        "pred = []"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGARhLI7fHcH",
        "outputId": "e048de00-c869-4531-a411-1d76e36f06ec"
      },
      "source": [
        "# initialization\n",
        "m3twitter=M3Twitter()\n",
        "\n",
        "# remember to upload Twitter API keys, format as https://github.com/euagendas/m3inference/blob/master/scripts/auth_example.txt\n",
        "m3twitter.twitter_init_from_file(\"/content/drive/MyDrive/auth.txt\")\n",
        "\n",
        "# you can also use m3twitter.infer_id(id = \"....\")\n",
        "for i in range(1173,len(user_list)):\n",
        "  print(i)\n",
        "  user_detail = m3twitter.infer_screen_name(user_list[i],skip_cache=True)\n",
        "  prob_male = user_detail['output']['gender']['male']\n",
        "  prob_female = user_detail['output']['gender']['female']\n",
        "  if prob_male > prob_female:\n",
        "    pred.append('1')\n",
        "  else:\n",
        "    pred.append('0')"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:20:15 - INFO - m3inference.m3inference -   Version 1.1.4\n",
            "04/12/2021 06:20:15 - INFO - m3inference.m3inference -   Running on cpu.\n",
            "04/12/2021 06:20:15 - INFO - m3inference.m3inference -   Will use full M3 model.\n",
            "04/12/2021 06:20:15 - INFO - m3inference.m3inference -   Model full_model exists at /root/m3/models/full_model.mdl.\n",
            "04/12/2021 06:20:15 - INFO - m3inference.utils -   Checking MD5 for model full_model at /root/m3/models/full_model.mdl\n",
            "04/12/2021 06:20:16 - INFO - m3inference.utils -   MD5s match.\n",
            "04/12/2021 06:20:16 - INFO - m3inference.m3inference -   Loaded pretrained weight at /root/m3/models/full_model.mdl\n",
            "04/12/2021 06:20:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for kolbycisme.\n",
            "04/12/2021 06:20:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=kolbycisme\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1173\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:20:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:20:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for koolmom12nance.\n",
            "04/12/2021 06:20:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=koolmom12nance\n",
            "04/12/2021 06:20:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:20:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for kris_10smith.\n",
            "04/12/2021 06:20:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=kris_10smith\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:20:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "04/12/2021 06:20:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for kristi_falbo.\n",
            "04/12/2021 06:20:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=kristi_falbo\n",
            "04/12/2021 06:20:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:20:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for kristintomoff.\n",
            "04/12/2021 06:20:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=kristintomoff\n",
            "04/12/2021 06:20:20 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:20:20 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:20:20 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:20:20 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:20:20 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:20:20 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:20:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
            "04/12/2021 06:20:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for kristirawlings.\n",
            "04/12/2021 06:20:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=kristirawlings\n",
            "04/12/2021 06:20:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:20:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for krystalxevette.\n",
            "04/12/2021 06:20:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=krystalxevette\n",
            "04/12/2021 06:20:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1179\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:20:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for kspringsss.\n",
            "04/12/2021 06:20:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=kspringsss\n",
            "04/12/2021 06:20:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
            "04/12/2021 06:20:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ktazwells.\n",
            "04/12/2021 06:20:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ktazwells\n",
            "04/12/2021 06:20:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
            "04/12/2021 06:20:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for kuladudette.\n",
            "04/12/2021 06:20:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=kuladudette\n",
            "04/12/2021 06:20:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
            "04/12/2021 06:20:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for kyankento.\n",
            "04/12/2021 06:20:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=kyankento\n",
            "04/12/2021 06:20:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:20:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for kyleerenaee.\n",
            "04/12/2021 06:20:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=kyleerenaee\n",
            "04/12/2021 06:20:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1184\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:20:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for kymcfarland.\n",
            "04/12/2021 06:20:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=kymcfarland\n",
            "04/12/2021 06:20:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1185\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:20:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for kyrainabox.\n",
            "04/12/2021 06:20:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=kyrainabox\n",
            "04/12/2021 06:20:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
            "04/12/2021 06:20:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for kz457.\n",
            "04/12/2021 06:20:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=kz457\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:20:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
            "04/12/2021 06:20:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for labbiejake.\n",
            "04/12/2021 06:20:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=labbiejake\n",
            "04/12/2021 06:20:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1188\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:20:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for laeldubz_.\n",
            "04/12/2021 06:20:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=laeldubz_\n",
            "04/12/2021 06:20:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1189\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:20:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lakrenek.\n",
            "04/12/2021 06:20:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lakrenek\n",
            "04/12/2021 06:20:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1190\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:20:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lamboforte.\n",
            "04/12/2021 06:20:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lamboforte\n",
            "04/12/2021 06:20:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
            "04/12/2021 06:20:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lanaisamonkeyy.\n",
            "04/12/2021 06:20:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lanaisamonkeyy\n",
            "04/12/2021 06:20:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:20:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for langwiser.\n",
            "04/12/2021 06:20:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=langwiser\n",
            "04/12/2021 06:20:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
            "04/12/2021 06:20:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lanie_jns.\n",
            "04/12/2021 06:20:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lanie_jns\n",
            "04/12/2021 06:20:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1194\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
            "04/12/2021 06:20:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for larompetoto.\n",
            "04/12/2021 06:20:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=larompetoto\n",
            "04/12/2021 06:20:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:20:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lauraxoisabel.\n",
            "04/12/2021 06:20:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lauraxoisabel\n",
            "04/12/2021 06:20:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:20:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lauren420_69.\n",
            "04/12/2021 06:20:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lauren420_69\n",
            "04/12/2021 06:20:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:20:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for laurenlindsaydj.\n",
            "04/12/2021 06:20:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=laurenlindsaydj\n",
            "04/12/2021 06:20:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:20:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for laurennn140.\n",
            "04/12/2021 06:20:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=laurennn140\n",
            "04/12/2021 06:20:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1199\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:20:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lauryn_elizaa.\n",
            "04/12/2021 06:20:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lauryn_elizaa\n",
            "04/12/2021 06:20:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "04/12/2021 06:20:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lauryn_jaydee.\n",
            "04/12/2021 06:20:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lauryn_jaydee\n",
            "04/12/2021 06:20:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1201\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
            "04/12/2021 06:20:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lauryn_quinn.\n",
            "04/12/2021 06:20:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lauryn_quinn\n",
            "04/12/2021 06:20:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
            "04/12/2021 06:20:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lauurreenna.\n",
            "04/12/2021 06:20:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lauurreenna\n",
            "04/12/2021 06:20:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:20:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lawdforgivemee.\n",
            "04/12/2021 06:20:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lawdforgivemee\n",
            "04/12/2021 06:20:42 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:20:42 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:20:42 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:20:42 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:20:42 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:20:42 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:20:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "04/12/2021 06:20:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for laydiexskull.\n",
            "04/12/2021 06:20:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=laydiexskull\n",
            "04/12/2021 06:20:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:20:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lazaruseffect79.\n",
            "04/12/2021 06:20:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lazaruseffect79\n",
            "04/12/2021 06:20:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:20:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lbateman40.\n",
            "04/12/2021 06:20:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lbateman40\n",
            "04/12/2021 06:20:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:20:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lbgoforth1978.\n",
            "04/12/2021 06:20:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lbgoforth1978\n",
            "04/12/2021 06:20:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1208\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:20:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lcortner09.\n",
            "04/12/2021 06:20:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lcortner09\n",
            "04/12/2021 06:20:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
            "04/12/2021 06:20:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lda_writes.\n",
            "04/12/2021 06:20:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lda_writes\n",
            "04/12/2021 06:20:46 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:20:46 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:20:46 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:20:46 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:20:46 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:20:46 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:20:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1210\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:20:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for leaaves.\n",
            "04/12/2021 06:20:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=leaaves\n",
            "04/12/2021 06:20:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:20:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for leahcapezzuto.\n",
            "04/12/2021 06:20:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=leahcapezzuto\n",
            "04/12/2021 06:20:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:20:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for leaholiver0502.\n",
            "04/12/2021 06:20:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=leaholiver0502\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1213\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:20:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
            "04/12/2021 06:20:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for leealvarado101.\n",
            "04/12/2021 06:20:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=leealvarado101\n",
            "04/12/2021 06:20:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:20:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for leebrewer2na.\n",
            "04/12/2021 06:20:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=leebrewer2na\n",
            "04/12/2021 06:20:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:20:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for leemanrobertf.\n",
            "04/12/2021 06:20:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=leemanrobertf\n",
            "04/12/2021 06:20:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:20:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lei_fle.\n",
            "04/12/2021 06:20:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lei_fle\n",
            "04/12/2021 06:20:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
            "04/12/2021 06:20:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for leilaclaire.\n",
            "04/12/2021 06:20:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=leilaclaire\n",
            "04/12/2021 06:20:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1218\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:20:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for leimer.\n",
            "04/12/2021 06:20:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=leimer\n",
            "04/12/2021 06:20:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:20:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for len_evans.\n",
            "04/12/2021 06:20:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=len_evans\n",
            "04/12/2021 06:20:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1220\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:20:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lessuggs.\n",
            "04/12/2021 06:20:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lessuggs\n",
            "04/12/2021 06:20:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:20:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lesxmoreno.\n",
            "04/12/2021 06:20:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lesxmoreno\n",
            "04/12/2021 06:20:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:20:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for levichpaige.\n",
            "04/12/2021 06:20:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=levichpaige\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:20:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
            "04/12/2021 06:20:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lexnstuff.\n",
            "04/12/2021 06:20:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lexnstuff\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:20:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:20:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lgeisheimer.\n",
            "04/12/2021 06:20:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lgeisheimer\n",
            "04/12/2021 06:21:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
            "04/12/2021 06:21:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for liamschmidt15.\n",
            "04/12/2021 06:21:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=liamschmidt15\n",
            "04/12/2021 06:21:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1226\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "04/12/2021 06:21:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for libragirlfriend.\n",
            "04/12/2021 06:21:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=libragirlfriend\n",
            "04/12/2021 06:21:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:21:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for librawithcancer.\n",
            "04/12/2021 06:21:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=librawithcancer\n",
            "04/12/2021 06:21:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:21:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lil_kermy.\n",
            "04/12/2021 06:21:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lil_kermy\n",
            "04/12/2021 06:21:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1229\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
            "04/12/2021 06:21:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lilaahhh.\n",
            "04/12/2021 06:21:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lilaahhh\n",
            "04/12/2021 06:21:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
            "04/12/2021 06:21:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lilangrybaby.\n",
            "04/12/2021 06:21:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lilangrybaby\n",
            "04/12/2021 06:21:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:21:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lilbaabyhan.\n",
            "04/12/2021 06:21:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lilbaabyhan\n",
            "04/12/2021 06:21:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
            "04/12/2021 06:21:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lilebboo.\n",
            "04/12/2021 06:21:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lilebboo\n",
            "04/12/2021 06:21:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1233\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:21:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lilgrand_.\n",
            "04/12/2021 06:21:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lilgrand_\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:21:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:21:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lilmike_2013.\n",
            "04/12/2021 06:21:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lilmike_2013\n",
            "04/12/2021 06:21:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:21:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for liltinyhumann.\n",
            "04/12/2021 06:21:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=liltinyhumann\n",
            "04/12/2021 06:21:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:21:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lindsayraeg.\n",
            "04/12/2021 06:21:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lindsayraeg\n",
            "04/12/2021 06:21:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:21:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lindsey_robarge.\n",
            "04/12/2021 06:21:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lindsey_robarge\n",
            "04/12/2021 06:21:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1238\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:21:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lindseybr00keb.\n",
            "04/12/2021 06:21:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lindseybr00keb\n",
            "04/12/2021 06:21:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:21:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lindseyy090.\n",
            "04/12/2021 06:21:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lindseyy090\n",
            "04/12/2021 06:21:12 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:21:12 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:21:12 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:21:12 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:21:12 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:21:12 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:21:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:21:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lis_sux.\n",
            "04/12/2021 06:21:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lis_sux\n",
            "04/12/2021 06:21:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:21:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lisaiop.\n",
            "04/12/2021 06:21:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lisaiop\n",
            "04/12/2021 06:21:13 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:21:13 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:21:13 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:21:13 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:21:13 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:21:13 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:21:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:21:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for liseyfreije.\n",
            "04/12/2021 06:21:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=liseyfreije\n",
            "04/12/2021 06:21:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:21:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lissavibes.\n",
            "04/12/2021 06:21:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lissavibes\n",
            "04/12/2021 06:21:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "04/12/2021 06:21:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lissyd0ll99.\n",
            "04/12/2021 06:21:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lissyd0ll99\n",
            "04/12/2021 06:21:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1245\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:21:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for littlelemon_boy.\n",
            "04/12/2021 06:21:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=littlelemon_boy\n",
            "04/12/2021 06:21:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:21:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for livefastdiejohn.\n",
            "04/12/2021 06:21:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=livefastdiejohn\n",
            "04/12/2021 06:21:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:21:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for livetolove_000.\n",
            "04/12/2021 06:21:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=livetolove_000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:21:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:21:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lizb411.\n",
            "04/12/2021 06:21:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lizb411\n",
            "04/12/2021 06:21:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
            "04/12/2021 06:21:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lizeth_j97.\n",
            "04/12/2021 06:21:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lizeth_j97\n",
            "04/12/2021 06:21:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:21:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lizwithcon.\n",
            "04/12/2021 06:21:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lizwithcon\n",
            "04/12/2021 06:21:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:21:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lizzifus0606.\n",
            "04/12/2021 06:21:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lizzifus0606\n",
            "04/12/2021 06:21:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:21:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lizzoot.\n",
            "04/12/2021 06:21:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lizzoot\n",
            "04/12/2021 06:21:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "04/12/2021 06:21:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ljosephgarcia.\n",
            "04/12/2021 06:21:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ljosephgarcia\n",
            "04/12/2021 06:21:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:21:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lolocanavan.\n",
            "04/12/2021 06:21:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lolocanavan\n",
            "04/12/2021 06:21:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1255\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:21:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lolskatherine.\n",
            "04/12/2021 06:21:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lolskatherine\n",
            "04/12/2021 06:21:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1256\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:21:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lonelybabylon.\n",
            "04/12/2021 06:21:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lonelybabylon\n",
            "04/12/2021 06:21:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1257\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:21:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for longlivhevymetl.\n",
            "04/12/2021 06:21:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=longlivhevymetl\n",
            "04/12/2021 06:21:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1258\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "04/12/2021 06:21:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for loovekaroll.\n",
            "04/12/2021 06:21:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=loovekaroll\n",
            "04/12/2021 06:21:28 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:21:28 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:21:28 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:21:28 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:21:28 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:21:28 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:21:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:21:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lordjoey615.\n",
            "04/12/2021 06:21:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lordjoey615\n",
            "04/12/2021 06:21:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1260\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:21:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lorena_anyssa.\n",
            "04/12/2021 06:21:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lorena_anyssa\n",
            "04/12/2021 06:21:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1261\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:21:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lori_charlton.\n",
            "04/12/2021 06:21:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lori_charlton\n",
            "04/12/2021 06:21:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1262\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:21:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lorynveilleux.\n",
            "04/12/2021 06:21:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lorynveilleux\n",
            "04/12/2021 06:21:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:21:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lotsofjoon.\n",
            "04/12/2021 06:21:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lotsofjoon\n",
            "04/12/2021 06:21:32 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:21:32 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:21:32 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:21:32 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:21:32 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:21:32 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:21:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:21:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lovelylleger.\n",
            "04/12/2021 06:21:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lovelylleger\n",
            "04/12/2021 06:21:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:21:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lozanology.\n",
            "04/12/2021 06:21:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lozanology\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:21:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "04/12/2021 06:21:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lptutoringco.\n",
            "04/12/2021 06:21:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lptutoringco\n",
            "04/12/2021 06:21:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:21:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lucillemilles.\n",
            "04/12/2021 06:21:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lucillemilles\n",
            "04/12/2021 06:21:35 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:21:35 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:21:35 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:21:35 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:21:35 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:21:35 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:21:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1268\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "04/12/2021 06:21:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for luciskydyme.\n",
            "04/12/2021 06:21:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=luciskydyme\n",
            "04/12/2021 06:21:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:21:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lucywright00.\n",
            "04/12/2021 06:21:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lucywright00\n",
            "04/12/2021 06:21:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
            "04/12/2021 06:21:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lukelaidandthin.\n",
            "04/12/2021 06:21:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lukelaidandthin\n",
            "04/12/2021 06:21:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1271\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:21:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lvxtlman.\n",
            "04/12/2021 06:21:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lvxtlman\n",
            "04/12/2021 06:21:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1272\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:21:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lydiuhhh.\n",
            "04/12/2021 06:21:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lydiuhhh\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:21:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:21:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lydscott1.\n",
            "04/12/2021 06:21:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lydscott1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:21:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
            "04/12/2021 06:21:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lyndsey_warren.\n",
            "04/12/2021 06:21:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lyndsey_warren\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:21:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:21:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lynnchloee.\n",
            "04/12/2021 06:21:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lynnchloee\n",
            "04/12/2021 06:21:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
            "04/12/2021 06:21:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lyricalprisoner.\n",
            "04/12/2021 06:21:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lyricalprisoner\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:21:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "04/12/2021 06:21:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for lyssannj.\n",
            "04/12/2021 06:21:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=lyssannj\n",
            "04/12/2021 06:21:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:21:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for m_hoag1.\n",
            "04/12/2021 06:21:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=m_hoag1\n",
            "04/12/2021 06:21:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1279\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:21:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maaddiieebby.\n",
            "04/12/2021 06:21:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maaddiieebby\n",
            "04/12/2021 06:21:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "04/12/2021 06:21:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mad_th_jed.\n",
            "04/12/2021 06:21:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mad_th_jed\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:21:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "04/12/2021 06:21:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maddi_romeo.\n",
            "04/12/2021 06:21:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maddi_romeo\n",
            "04/12/2021 06:21:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:21:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maddidailyy.\n",
            "04/12/2021 06:21:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maddidailyy\n",
            "04/12/2021 06:21:48 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:21:48 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:21:48 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:21:48 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:21:48 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:21:48 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:21:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
            "04/12/2021 06:21:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maddieadams02.\n",
            "04/12/2021 06:21:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maddieadams02\n",
            "04/12/2021 06:21:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:21:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maddileighhhh.\n",
            "04/12/2021 06:21:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maddileighhhh\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:21:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:21:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maddisonnell.\n",
            "04/12/2021 06:21:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maddisonnell\n",
            "04/12/2021 06:21:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:21:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maddsue4444.\n",
            "04/12/2021 06:21:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maddsue4444\n",
            "04/12/2021 06:21:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:21:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maddyluvsdaniel.\n",
            "04/12/2021 06:21:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maddyluvsdaniel\n",
            "04/12/2021 06:21:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1288\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:21:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for madi_schaefer09.\n",
            "04/12/2021 06:21:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=madi_schaefer09\n",
            "04/12/2021 06:21:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1289\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:21:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for madieebosleyy.\n",
            "04/12/2021 06:21:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=madieebosleyy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1290\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:21:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:21:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for madiicarterr.\n",
            "04/12/2021 06:21:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=madiicarterr\n",
            "04/12/2021 06:21:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:21:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for madikreilly.\n",
            "04/12/2021 06:21:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=madikreilly\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1292\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:21:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:21:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for madisonherron18.\n",
            "04/12/2021 06:21:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=madisonherron18\n",
            "04/12/2021 06:21:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1293\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:21:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for madisonmaelynn.\n",
            "04/12/2021 06:21:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=madisonmaelynn\n",
            "04/12/2021 06:21:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "04/12/2021 06:21:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for madsuder4.\n",
            "04/12/2021 06:21:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=madsuder4\n",
            "04/12/2021 06:21:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:21:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for madyaholt27.\n",
            "04/12/2021 06:21:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=madyaholt27\n",
            "04/12/2021 06:21:59 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:21:59 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:21:59 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:21:59 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:21:59 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:21:59 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:21:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:22:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for magdahalina.\n",
            "04/12/2021 06:22:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=magdahalina\n",
            "04/12/2021 06:22:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1297\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:22:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maggie_717.\n",
            "04/12/2021 06:22:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maggie_717\n",
            "04/12/2021 06:22:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "04/12/2021 06:22:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maggie_meehann.\n",
            "04/12/2021 06:22:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maggie_meehann\n",
            "04/12/2021 06:22:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:22:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maggiedtrack.\n",
            "04/12/2021 06:22:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maggiedtrack\n",
            "04/12/2021 06:22:02 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:22:02 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:22:02 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:22:02 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:22:02 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:22:02 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:22:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:22:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for majestyjames1.\n",
            "04/12/2021 06:22:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=majestyjames1\n",
            "04/12/2021 06:22:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1301\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:22:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for makena1127.\n",
            "04/12/2021 06:22:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=makena1127\n",
            "04/12/2021 06:22:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1302\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "04/12/2021 06:22:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for malaylayxo.\n",
            "04/12/2021 06:22:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=malaylayxo\n",
            "04/12/2021 06:22:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:22:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mamacitamuerte.\n",
            "04/12/2021 06:22:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mamacitamuerte\n",
            "04/12/2021 06:22:06 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:22:06 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:22:06 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:22:06 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:22:06 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:22:06 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:22:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:22:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mandavillegass.\n",
            "04/12/2021 06:22:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mandavillegass\n",
            "04/12/2021 06:22:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:22:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mandersonville.\n",
            "04/12/2021 06:22:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mandersonville\n",
            "04/12/2021 06:22:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:22:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mando_iman.\n",
            "04/12/2021 06:22:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mando_iman\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1307\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:22:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:22:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mandy_j_riley.\n",
            "04/12/2021 06:22:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mandy_j_riley\n",
            "04/12/2021 06:22:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:22:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maralan17.\n",
            "04/12/2021 06:22:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maralan17\n",
            "04/12/2021 06:22:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:22:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marbauer27.\n",
            "04/12/2021 06:22:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marbauer27\n",
            "04/12/2021 06:22:11 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:22:11 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:22:11 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:22:11 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:22:11 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:22:11 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:22:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1310\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:22:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marco95altamore.\n",
            "04/12/2021 06:22:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marco95altamore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:22:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:22:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marcusmyselff.\n",
            "04/12/2021 06:22:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marcusmyselff\n",
            "04/12/2021 06:22:13 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:22:13 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:22:13 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:22:13 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:22:13 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:22:13 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:22:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:22:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marcymartin07.\n",
            "04/12/2021 06:22:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marcymartin07\n",
            "04/12/2021 06:22:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:22:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mari_aaf.\n",
            "04/12/2021 06:22:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mari_aaf\n",
            "04/12/2021 06:22:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:22:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mari_elyse.\n",
            "04/12/2021 06:22:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mari_elyse\n",
            "04/12/2021 06:22:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1315\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:22:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mariaa_salcedo.\n",
            "04/12/2021 06:22:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mariaa_salcedo\n",
            "04/12/2021 06:22:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:22:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mariannecoffeyy.\n",
            "04/12/2021 06:22:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mariannecoffeyy\n",
            "04/12/2021 06:22:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:22:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marienoelmiller.\n",
            "04/12/2021 06:22:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marienoelmiller\n",
            "04/12/2021 06:22:18 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:22:18 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:22:18 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:22:18 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:22:18 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:22:18 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:22:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:22:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marisasobeski.\n",
            "04/12/2021 06:22:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marisasobeski\n",
            "04/12/2021 06:22:19 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:22:19 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:22:19 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:22:19 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:22:19 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:22:19 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:22:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:22:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marissadeblasie.\n",
            "04/12/2021 06:22:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marissadeblasie\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1320\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:22:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "04/12/2021 06:22:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maritsanbcmt.\n",
            "04/12/2021 06:22:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maritsanbcmt\n",
            "04/12/2021 06:22:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1321\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:22:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marlowe79419796.\n",
            "04/12/2021 06:22:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marlowe79419796\n",
            "04/12/2021 06:22:22 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:22:22 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:22:22 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:22:22 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:22:22 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:22:22 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:22:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:22:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marlzzzbarkley.\n",
            "04/12/2021 06:22:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marlzzzbarkley\n",
            "04/12/2021 06:22:22 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:22:22 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:22:22 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:22:22 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:22:22 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:22:22 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:22:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:22:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for martyrsdaughter.\n",
            "04/12/2021 06:22:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=martyrsdaughter\n",
            "04/12/2021 06:22:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1324\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:22:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for martywilliams17.\n",
            "04/12/2021 06:22:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=martywilliams17\n",
            "04/12/2021 06:22:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:22:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marxinista.\n",
            "04/12/2021 06:22:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marxinista\n",
            "04/12/2021 06:22:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1326\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:22:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marybarbaramar1.\n",
            "04/12/2021 06:22:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marybarbaramar1\n",
            "04/12/2021 06:22:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:22:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maryelosch.\n",
            "04/12/2021 06:22:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maryelosch\n",
            "04/12/2021 06:22:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:22:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marymargaretwe.\n",
            "04/12/2021 06:22:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marymargaretwe\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:22:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:22:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for marysavage1957.\n",
            "04/12/2021 06:22:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=marysavage1957\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1330\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:22:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:22:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mashisoyeol.\n",
            "04/12/2021 06:22:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mashisoyeol\n",
            "04/12/2021 06:22:29 - INFO - m3inference.dataset -   1 data entries loaded.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1331\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:22:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for masonpls.\n",
            "04/12/2021 06:22:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=masonpls\n",
            "04/12/2021 06:22:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "04/12/2021 06:22:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for matt_phillips93.\n",
            "04/12/2021 06:22:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=matt_phillips93\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:22:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:22:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mattbernal916.\n",
            "04/12/2021 06:22:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mattbernal916\n",
            "04/12/2021 06:22:32 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:22:32 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:22:32 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:22:32 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:22:32 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:22:32 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:22:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:22:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mattfromberkley.\n",
            "04/12/2021 06:22:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mattfromberkley\n",
            "04/12/2021 06:22:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:22:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for matthew69835043.\n",
            "04/12/2021 06:22:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=matthew69835043\n",
            "04/12/2021 06:22:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1336\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:22:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mattlabor.\n",
            "04/12/2021 06:22:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mattlabor\n",
            "04/12/2021 06:22:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1337\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:22:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mattreednews.\n",
            "04/12/2021 06:22:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mattreednews\n",
            "04/12/2021 06:22:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:22:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for matzar12.\n",
            "04/12/2021 06:22:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=matzar12\n",
            "04/12/2021 06:22:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:22:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mauriciooo_g.\n",
            "04/12/2021 06:22:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mauriciooo_g\n",
            "04/12/2021 06:22:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1340\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:22:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mawisa_b.\n",
            "04/12/2021 06:22:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mawisa_b\n",
            "04/12/2021 06:22:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1341\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "04/12/2021 06:22:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for max_xam82000.\n",
            "04/12/2021 06:22:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=max_xam82000\n",
            "04/12/2021 06:22:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:22:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for maxo3284.\n",
            "04/12/2021 06:22:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=maxo3284\n",
            "04/12/2021 06:22:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "04/12/2021 06:22:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mayranation.\n",
            "04/12/2021 06:22:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mayranation\n",
            "04/12/2021 06:22:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1344\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
            "04/12/2021 06:22:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mayravenzor_.\n",
            "04/12/2021 06:22:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mayravenzor_\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:22:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:22:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mazie58.\n",
            "04/12/2021 06:22:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mazie58\n",
            "04/12/2021 06:22:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1346\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:22:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mazurekrebecca.\n",
            "04/12/2021 06:22:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mazurekrebecca\n",
            "04/12/2021 06:22:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1347\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:22:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mcclutherness.\n",
            "04/12/2021 06:22:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mcclutherness\n",
            "04/12/2021 06:22:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:22:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mcgeek77.\n",
            "04/12/2021 06:22:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mcgeek77\n",
            "04/12/2021 06:22:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1349\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:22:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mckinziegoble.\n",
            "04/12/2021 06:22:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mckinziegoble\n",
            "04/12/2021 06:22:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
            "04/12/2021 06:22:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mckira1.\n",
            "04/12/2021 06:22:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mckira1\n",
            "04/12/2021 06:22:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1351\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:22:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mckmil.\n",
            "04/12/2021 06:22:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mckmil\n",
            "04/12/2021 06:22:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1352\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:22:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mclanoux.\n",
            "04/12/2021 06:22:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mclanoux\n",
            "04/12/2021 06:22:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:22:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mcmullenraelynn.\n",
            "04/12/2021 06:22:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mcmullenraelynn\n",
            "04/12/2021 06:22:49 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:22:49 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:22:49 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:22:49 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:22:49 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:22:49 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:22:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1354\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:22:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mcrae_heath.\n",
            "04/12/2021 06:22:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mcrae_heath\n",
            "04/12/2021 06:22:50 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:22:50 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:22:50 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:22:50 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:22:50 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:22:50 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:22:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:22:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for megan_wolfe2.\n",
            "04/12/2021 06:22:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=megan_wolfe2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:22:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
            "04/12/2021 06:22:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for meganbb18.\n",
            "04/12/2021 06:22:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=meganbb18\n",
            "04/12/2021 06:22:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:22:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for meganeliseeeee.\n",
            "04/12/2021 06:22:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=meganeliseeeee\n",
            "04/12/2021 06:22:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:22:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for megankill_.\n",
            "04/12/2021 06:22:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=megankill_\n",
            "04/12/2021 06:22:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:22:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for megannlindstrom.\n",
            "04/12/2021 06:22:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=megannlindstrom\n",
            "04/12/2021 06:22:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1360\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:22:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for meghan_nasty.\n",
            "04/12/2021 06:22:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=meghan_nasty\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1361\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:22:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
            "04/12/2021 06:22:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for meghanmcnerney_.\n",
            "04/12/2021 06:22:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=meghanmcnerney_\n",
            "04/12/2021 06:22:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:22:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for megnewman19.\n",
            "04/12/2021 06:22:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=megnewman19\n",
            "04/12/2021 06:22:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:22:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for megpriadka.\n",
            "04/12/2021 06:22:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=megpriadka\n",
            "04/12/2021 06:22:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:22:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for megsherlock.\n",
            "04/12/2021 06:22:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=megsherlock\n",
            "04/12/2021 06:22:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "04/12/2021 06:22:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for melanatedliz.\n",
            "04/12/2021 06:22:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=melanatedliz\n",
            "04/12/2021 06:22:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:23:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for melissacaton4.\n",
            "04/12/2021 06:23:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=melissacaton4\n",
            "04/12/2021 06:23:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:23:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mella1281.\n",
            "04/12/2021 06:23:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mella1281\n",
            "04/12/2021 06:23:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:23:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for memedithhh.\n",
            "04/12/2021 06:23:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=memedithhh\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:23:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for memphissanta.\n",
            "04/12/2021 06:23:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=memphissanta\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1370\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:23:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for meredithnoelled.\n",
            "04/12/2021 06:23:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=meredithnoelled\n",
            "04/12/2021 06:23:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:23:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for metallidan.\n",
            "04/12/2021 06:23:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=metallidan\n",
            "04/12/2021 06:23:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1372\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:23:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for methredandllfan.\n",
            "04/12/2021 06:23:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=methredandllfan\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:23:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mewbotz.\n",
            "04/12/2021 06:23:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mewbotz\n",
            "04/12/2021 06:23:06 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:23:06 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:23:06 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:23:06 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:23:06 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:23:06 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:23:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "04/12/2021 06:23:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mexicansugarr.\n",
            "04/12/2021 06:23:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mexicansugarr\n",
            "04/12/2021 06:23:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
            "04/12/2021 06:23:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for meyer_ce1978.\n",
            "04/12/2021 06:23:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=meyer_ce1978\n",
            "04/12/2021 06:23:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1376\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:23:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mfatah281.\n",
            "04/12/2021 06:23:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mfatah281\n",
            "04/12/2021 06:23:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:23:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mffntv.\n",
            "04/12/2021 06:23:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mffntv\n",
            "04/12/2021 06:23:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:23:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mfraz4.\n",
            "04/12/2021 06:23:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mfraz4\n",
            "04/12/2021 06:23:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1379\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:23:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mfrederickm.\n",
            "04/12/2021 06:23:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mfrederickm\n",
            "04/12/2021 06:23:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1380\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:23:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mgencs11.\n",
            "04/12/2021 06:23:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mgencs11\n",
            "04/12/2021 06:23:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:23:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mheffron12.\n",
            "04/12/2021 06:23:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mheffron12\n",
            "04/12/2021 06:23:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:23:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for miascotttt.\n",
            "04/12/2021 06:23:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=miascotttt\n",
            "04/12/2021 06:23:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1383\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:23:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for micahmartinezx1.\n",
            "04/12/2021 06:23:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=micahmartinezx1\n",
            "04/12/2021 06:23:15 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:23:15 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:23:15 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:23:15 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:23:15 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:23:15 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:23:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:23:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for michael2irwin.\n",
            "04/12/2021 06:23:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=michael2irwin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:23:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for michaelfranti.\n",
            "04/12/2021 06:23:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=michaelfranti\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:23:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for michaelpartida.\n",
            "04/12/2021 06:23:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=michaelpartida\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:23:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for michexposures.\n",
            "04/12/2021 06:23:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=michexposures\n",
            "04/12/2021 06:23:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1388\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:23:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mighty23405.\n",
            "04/12/2021 06:23:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mighty23405\n",
            "04/12/2021 06:23:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:23:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mikayla_roch.\n",
            "04/12/2021 06:23:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mikayla_roch\n",
            "04/12/2021 06:23:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1390\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:23:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mikaylaxdavis.\n",
            "04/12/2021 06:23:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mikaylaxdavis\n",
            "04/12/2021 06:23:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:23:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mikepaddock.\n",
            "04/12/2021 06:23:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mikepaddock\n",
            "04/12/2021 06:23:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:23:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mikeshe16309299.\n",
            "04/12/2021 06:23:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mikeshe16309299\n",
            "04/12/2021 06:23:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1393\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:23:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for milesjoseph3.\n",
            "04/12/2021 06:23:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=milesjoseph3\n",
            "04/12/2021 06:23:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:23:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for miliondollathot.\n",
            "04/12/2021 06:23:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=miliondollathot\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:23:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for millsyfbabyyy.\n",
            "04/12/2021 06:23:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=millsyfbabyyy\n",
            "04/12/2021 06:23:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:23:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for millylilyrose.\n",
            "04/12/2021 06:23:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=millylilyrose\n",
            "04/12/2021 06:23:27 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:23:27 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:23:27 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:23:27 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:23:27 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:23:27 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:23:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
            "04/12/2021 06:23:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for milsgoprod.\n",
            "04/12/2021 06:23:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=milsgoprod\n",
            "04/12/2021 06:23:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:23:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mimij37.\n",
            "04/12/2021 06:23:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mimij37\n",
            "04/12/2021 06:23:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1399\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:23:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mindlesslez.\n",
            "04/12/2021 06:23:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mindlesslez\n",
            "04/12/2021 06:23:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:23:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for minhthyfreshh.\n",
            "04/12/2021 06:23:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=minhthyfreshh\n",
            "04/12/2021 06:23:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:23:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for minorthreat1978.\n",
            "04/12/2021 06:23:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=minorthreat1978\n",
            "04/12/2021 06:23:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:23:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mireyahwolfe.\n",
            "04/12/2021 06:23:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mireyahwolfe\n",
            "04/12/2021 06:23:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:23:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mishalawless.\n",
            "04/12/2021 06:23:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mishalawless\n",
            "04/12/2021 06:23:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1404\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:23:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for missangsays.\n",
            "04/12/2021 06:23:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=missangsays\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:23:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for missin_florida.\n",
            "04/12/2021 06:23:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=missin_florida\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:23:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for missmarcela_.\n",
            "04/12/2021 06:23:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=missmarcela_\n",
            "04/12/2021 06:23:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
            "04/12/2021 06:23:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mistyaue.\n",
            "04/12/2021 06:23:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mistyaue\n",
            "04/12/2021 06:23:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1408\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:23:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mistyn10.\n",
            "04/12/2021 06:23:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mistyn10\n",
            "04/12/2021 06:23:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1409\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:23:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mitchondrums.\n",
            "04/12/2021 06:23:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mitchondrums\n",
            "04/12/2021 06:23:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1410\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:23:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mitolizard.\n",
            "04/12/2021 06:23:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mitolizard\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:23:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mjb1284.\n",
            "04/12/2021 06:23:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mjb1284\n",
            "04/12/2021 06:23:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:23:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mmoe69_maureen.\n",
            "04/12/2021 06:23:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mmoe69_maureen\n",
            "04/12/2021 06:23:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1413\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:23:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mneakin.\n",
            "04/12/2021 06:23:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mneakin\n",
            "04/12/2021 06:23:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1414\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:23:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mochiwovesyou.\n",
            "04/12/2021 06:23:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mochiwovesyou\n",
            "04/12/2021 06:23:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1415\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:23:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mohillbilly.\n",
            "04/12/2021 06:23:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mohillbilly\n",
            "04/12/2021 06:23:44 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:23:44 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:23:44 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:23:44 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:23:44 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:23:44 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:23:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:23:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mollysneed.\n",
            "04/12/2021 06:23:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mollysneed\n",
            "04/12/2021 06:23:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:23:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mommadeen2.\n",
            "04/12/2021 06:23:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mommadeen2\n",
            "04/12/2021 06:23:45 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:23:45 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:23:45 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:23:45 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:23:45 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:23:45 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:23:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
            "04/12/2021 06:23:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mongibeddu.\n",
            "04/12/2021 06:23:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mongibeddu\n",
            "04/12/2021 06:23:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1419\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:23:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for monkeyblood.\n",
            "04/12/2021 06:23:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=monkeyblood\n",
            "04/12/2021 06:23:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1420\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:23:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for monroy__17.\n",
            "04/12/2021 06:23:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=monroy__17\n",
            "04/12/2021 06:23:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1421\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:23:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for montalvaan.\n",
            "04/12/2021 06:23:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=montalvaan\n",
            "04/12/2021 06:23:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:23:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for monticellohoe.\n",
            "04/12/2021 06:23:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=monticellohoe\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:23:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for monyq.\n",
            "04/12/2021 06:23:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=monyq\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:23:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for morgan_goulding.\n",
            "04/12/2021 06:23:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=morgan_goulding\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
            "04/12/2021 06:23:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for morgan9ashleigh.\n",
            "04/12/2021 06:23:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=morgan9ashleigh\n",
            "04/12/2021 06:23:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:23:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for morganlpitre.\n",
            "04/12/2021 06:23:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=morganlpitre\n",
            "04/12/2021 06:23:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:23:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for morgmorgan25.\n",
            "04/12/2021 06:23:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=morgmorgan25\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:23:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for moseralexis.\n",
            "04/12/2021 06:23:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=moseralexis\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:23:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for moshxspice.\n",
            "04/12/2021 06:23:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=moshxspice\n",
            "04/12/2021 06:23:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
            "04/12/2021 06:23:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mr_classic_.\n",
            "04/12/2021 06:23:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mr_classic_\n",
            "04/12/2021 06:23:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1431\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:23:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mr_jwalter.\n",
            "04/12/2021 06:23:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mr_jwalter\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1432\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:23:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:23:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mr_sasz.\n",
            "04/12/2021 06:23:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mr_sasz\n",
            "04/12/2021 06:23:59 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:23:59 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:23:59 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:23:59 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:23:59 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:23:59 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:23:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:24:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mreestry.\n",
            "04/12/2021 06:24:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mreestry\n",
            "04/12/2021 06:24:00 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:24:00 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:24:00 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:24:00 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:24:00 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:24:00 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:24:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:24:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mrforsberglhs.\n",
            "04/12/2021 06:24:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mrforsberglhs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:24:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:24:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mrgoodluckxxx.\n",
            "04/12/2021 06:24:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mrgoodluckxxx\n",
            "04/12/2021 06:24:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:24:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mrmapleshade25.\n",
            "04/12/2021 06:24:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mrmapleshade25\n",
            "04/12/2021 06:24:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:24:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mrmattfoss.\n",
            "04/12/2021 06:24:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mrmattfoss\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:24:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:24:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mrsbumble97.\n",
            "04/12/2021 06:24:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mrsbumble97\n",
            "04/12/2021 06:24:05 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:24:05 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:24:05 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:24:05 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:24:05 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:24:05 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:24:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1439\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:24:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mrschimpf.\n",
            "04/12/2021 06:24:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mrschimpf\n",
            "04/12/2021 06:24:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1440\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:24:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mrsdelagrange54.\n",
            "04/12/2021 06:24:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mrsdelagrange54\n",
            "04/12/2021 06:24:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:24:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mrsmiles666.\n",
            "04/12/2021 06:24:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mrsmiles666\n",
            "04/12/2021 06:24:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1442\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:24:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mrtrevorhamil.\n",
            "04/12/2021 06:24:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mrtrevorhamil\n",
            "04/12/2021 06:24:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1443\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:24:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ms_cecere.\n",
            "04/12/2021 06:24:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ms_cecere\n",
            "04/12/2021 06:24:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:24:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ms909698.\n",
            "04/12/2021 06:24:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ms909698\n",
            "04/12/2021 06:24:10 - INFO - m3inference.dataset -   1 data entries loaded.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:24:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for msamandapandaxo.\n",
            "04/12/2021 06:24:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=msamandapandaxo\n",
            "04/12/2021 06:24:11 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:24:11 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:24:11 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:24:11 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:24:11 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:24:11 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:24:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:24:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for msdvvv.\n",
            "04/12/2021 06:24:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=msdvvv\n",
            "04/12/2021 06:24:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:24:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for msoto1210.\n",
            "04/12/2021 06:24:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=msoto1210\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:24:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:24:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mulderisgay666.\n",
            "04/12/2021 06:24:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mulderisgay666\n",
            "04/12/2021 06:24:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:24:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mundellrobert.\n",
            "04/12/2021 06:24:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mundellrobert\n",
            "04/12/2021 06:24:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:24:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for munky_strike.\n",
            "04/12/2021 06:24:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=munky_strike\n",
            "04/12/2021 06:24:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:24:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for musa_mtk.\n",
            "04/12/2021 06:24:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=musa_mtk\n",
            "04/12/2021 06:24:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:24:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mxrlene44.\n",
            "04/12/2021 06:24:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mxrlene44\n",
            "04/12/2021 06:24:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:24:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mxrquez___.\n",
            "04/12/2021 06:24:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mxrquez___\n",
            "04/12/2021 06:24:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:24:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mxtorriefoxx.\n",
            "04/12/2021 06:24:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mxtorriefoxx\n",
            "04/12/2021 06:24:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:24:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for myrtleinjurylaw.\n",
            "04/12/2021 06:24:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=myrtleinjurylaw\n",
            "04/12/2021 06:24:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1456\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:24:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mystar4eva.\n",
            "04/12/2021 06:24:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mystar4eva\n",
            "04/12/2021 06:24:21 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:24:21 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:24:21 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:24:21 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:24:21 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:24:21 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:24:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1457\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:24:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mystikx20.\n",
            "04/12/2021 06:24:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mystikx20\n",
            "04/12/2021 06:24:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:24:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for mziobro_.\n",
            "04/12/2021 06:24:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=mziobro_\n",
            "04/12/2021 06:24:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:24:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nabbypatty.\n",
            "04/12/2021 06:24:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nabbypatty\n",
            "04/12/2021 06:24:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1460\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:24:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nadia_jaouad.\n",
            "04/12/2021 06:24:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nadia_jaouad\n",
            "04/12/2021 06:24:24 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:24:24 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:24:24 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:24:24 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:24:24 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:24:24 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:24:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:24:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for najabailey.\n",
            "04/12/2021 06:24:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=najabailey\n",
            "04/12/2021 06:24:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:24:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nancyatheart.\n",
            "04/12/2021 06:24:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nancyatheart\n",
            "04/12/2021 06:24:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:24:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nanisalinas20.\n",
            "04/12/2021 06:24:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nanisalinas20\n",
            "04/12/2021 06:24:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:24:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for naomyvalens.\n",
            "04/12/2021 06:24:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=naomyvalens\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1465\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:24:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
            "04/12/2021 06:24:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for naraapricots.\n",
            "04/12/2021 06:24:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=naraapricots\n",
            "04/12/2021 06:24:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:24:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for naragclan.\n",
            "04/12/2021 06:24:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=naragclan\n",
            "04/12/2021 06:24:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:24:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for narissafbrokob.\n",
            "04/12/2021 06:24:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=narissafbrokob\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:24:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:24:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for natalehalesmbj.\n",
            "04/12/2021 06:24:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=natalehalesmbj\n",
            "04/12/2021 06:24:31 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:24:31 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:24:31 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:24:31 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:24:31 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:24:31 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:24:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:24:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nataleyneuman.\n",
            "04/12/2021 06:24:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nataleyneuman\n",
            "04/12/2021 06:24:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:24:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nataliefournell.\n",
            "04/12/2021 06:24:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nataliefournell\n",
            "04/12/2021 06:24:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:24:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for natenashgetcash.\n",
            "04/12/2021 06:24:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=natenashgetcash\n",
            "04/12/2021 06:24:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1472\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:24:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for naterip9.\n",
            "04/12/2021 06:24:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=naterip9\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:24:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:24:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for natewrussell.\n",
            "04/12/2021 06:24:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=natewrussell\n",
            "04/12/2021 06:24:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:24:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nath_ngo20.\n",
            "04/12/2021 06:24:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nath_ngo20\n",
            "04/12/2021 06:24:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:24:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nathanramsey3.\n",
            "04/12/2021 06:24:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nathanramsey3\n",
            "04/12/2021 06:24:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:24:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nathansmart.\n",
            "04/12/2021 06:24:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nathansmart\n",
            "04/12/2021 06:24:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:24:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for natitti_.\n",
            "04/12/2021 06:24:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=natitti_\n",
            "04/12/2021 06:24:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1478\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:24:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for natsilletti.\n",
            "04/12/2021 06:24:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=natsilletti\n",
            "04/12/2021 06:24:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:24:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nealtena.\n",
            "04/12/2021 06:24:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nealtena\n",
            "04/12/2021 06:24:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1480\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:24:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for necr0party.\n",
            "04/12/2021 06:24:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=necr0party\n",
            "04/12/2021 06:24:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:24:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nedalai.\n",
            "04/12/2021 06:24:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nedalai\n",
            "04/12/2021 06:24:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:24:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nemily65.\n",
            "04/12/2021 06:24:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nemily65\n",
            "04/12/2021 06:24:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1483\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:24:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nepalesruben.\n",
            "04/12/2021 06:24:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nepalesruben\n",
            "04/12/2021 06:24:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:24:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for neptuneelevated.\n",
            "04/12/2021 06:24:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=neptuneelevated\n",
            "04/12/2021 06:24:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:24:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nervoucities.\n",
            "04/12/2021 06:24:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nervoucities\n",
            "04/12/2021 06:24:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:24:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for neshhaaaaa_.\n",
            "04/12/2021 06:24:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=neshhaaaaa_\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:24:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:24:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nessamcmains.\n",
            "04/12/2021 06:24:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nessamcmains\n",
            "04/12/2021 06:24:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:24:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for newfoundnolan.\n",
            "04/12/2021 06:24:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=newfoundnolan\n",
            "04/12/2021 06:24:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:24:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nickdobbins22.\n",
            "04/12/2021 06:24:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nickdobbins22\n",
            "04/12/2021 06:24:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1490\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:24:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nickin616.\n",
            "04/12/2021 06:24:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nickin616\n",
            "04/12/2021 06:24:51 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:24:51 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:24:51 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:24:51 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:24:51 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:24:51 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:24:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1491\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:24:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nickkwheeler.\n",
            "04/12/2021 06:24:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nickkwheeler\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:24:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:24:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nicoleewagner8.\n",
            "04/12/2021 06:24:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nicoleewagner8\n",
            "04/12/2021 06:24:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:24:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nicolesusanne21.\n",
            "04/12/2021 06:24:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nicolesusanne21\n",
            "04/12/2021 06:24:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:24:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nicovetch.\n",
            "04/12/2021 06:24:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nicovetch\n",
            "04/12/2021 06:24:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1495\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:24:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nightcr37274702.\n",
            "04/12/2021 06:24:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nightcr37274702\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:24:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:24:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nightlinez.\n",
            "04/12/2021 06:24:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nightlinez\n",
            "04/12/2021 06:24:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1497\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:24:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nightsinger1942.\n",
            "04/12/2021 06:24:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nightsinger1942\n",
            "04/12/2021 06:24:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1498\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:24:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nightviix.\n",
            "04/12/2021 06:24:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nightviix\n",
            "04/12/2021 06:24:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1499\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:24:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nikhail13.\n",
            "04/12/2021 06:24:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nikhail13\n",
            "04/12/2021 06:24:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:25:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nikimaghzy99.\n",
            "04/12/2021 06:25:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nikimaghzy99\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:25:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:25:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nikkiatkinson.\n",
            "04/12/2021 06:25:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nikkiatkinson\n",
            "04/12/2021 06:25:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:25:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nikkispeech.\n",
            "04/12/2021 06:25:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nikkispeech\n",
            "04/12/2021 06:25:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:25:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ninjaeconomics.\n",
            "04/12/2021 06:25:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ninjaeconomics\n",
            "04/12/2021 06:25:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:25:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nityed.\n",
            "04/12/2021 06:25:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nityed\n",
            "04/12/2021 06:25:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:25:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nizaddy.\n",
            "04/12/2021 06:25:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nizaddy\n",
            "04/12/2021 06:25:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:25:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for njaycoles.\n",
            "04/12/2021 06:25:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=njaycoles\n",
            "04/12/2021 06:25:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:25:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nmdomo.\n",
            "04/12/2021 06:25:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nmdomo\n",
            "04/12/2021 06:25:06 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:25:06 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:25:06 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:25:06 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:25:06 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:25:06 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:25:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:25:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for noabournexo.\n",
            "04/12/2021 06:25:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=noabournexo\n",
            "04/12/2021 06:25:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:25:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for noahalex35.\n",
            "04/12/2021 06:25:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=noahalex35\n",
            "04/12/2021 06:25:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1510\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:25:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nochillciera.\n",
            "04/12/2021 06:25:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nochillciera\n",
            "04/12/2021 06:25:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:25:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nohelymejia3.\n",
            "04/12/2021 06:25:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nohelymejia3\n",
            "04/12/2021 06:25:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:25:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nohhhemy.\n",
            "04/12/2021 06:25:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nohhhemy\n",
            "04/12/2021 06:25:10 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:25:10 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:25:10 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:25:10 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:25:10 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:25:10 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:25:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:25:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for norad_alpha.\n",
            "04/12/2021 06:25:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=norad_alpha\n",
            "04/12/2021 06:25:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:25:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nostalgic_leah.\n",
            "04/12/2021 06:25:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nostalgic_leah\n",
            "04/12/2021 06:25:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:25:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for notcody00.\n",
            "04/12/2021 06:25:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=notcody00\n",
            "04/12/2021 06:25:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:25:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for notnicolaa.\n",
            "04/12/2021 06:25:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=notnicolaa\n",
            "04/12/2021 06:25:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:25:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for notnova_.\n",
            "04/12/2021 06:25:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=notnova_\n",
            "04/12/2021 06:25:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:25:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for notorious_val.\n",
            "04/12/2021 06:25:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=notorious_val\n",
            "04/12/2021 06:25:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:25:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for notoriousianv.\n",
            "04/12/2021 06:25:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=notoriousianv\n",
            "04/12/2021 06:25:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:25:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for notquitespooky.\n",
            "04/12/2021 06:25:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=notquitespooky\n",
            "04/12/2021 06:25:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:25:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for novarose92.\n",
            "04/12/2021 06:25:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=novarose92\n",
            "04/12/2021 06:25:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:25:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nplg98.\n",
            "04/12/2021 06:25:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nplg98\n",
            "04/12/2021 06:25:19 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:25:19 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:25:19 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:25:19 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:25:19 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:25:19 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:25:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1523\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:25:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ntjustanniebody.\n",
            "04/12/2021 06:25:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ntjustanniebody\n",
            "04/12/2021 06:25:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:25:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nuggette__.\n",
            "04/12/2021 06:25:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nuggette__\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:25:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:25:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nugglethekelpie.\n",
            "04/12/2021 06:25:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nugglethekelpie\n",
            "04/12/2021 06:25:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:25:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nursescircle.\n",
            "04/12/2021 06:25:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nursescircle\n",
            "04/12/2021 06:25:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:25:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nutmeggles.\n",
            "04/12/2021 06:25:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nutmeggles\n",
            "04/12/2021 06:25:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:25:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nvcrittenden.\n",
            "04/12/2021 06:25:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nvcrittenden\n",
            "04/12/2021 06:25:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:25:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nvmdes.\n",
            "04/12/2021 06:25:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nvmdes\n",
            "04/12/2021 06:25:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:25:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nvro_e.\n",
            "04/12/2021 06:25:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nvro_e\n",
            "04/12/2021 06:25:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:25:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nvthvnmville.\n",
            "04/12/2021 06:25:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nvthvnmville\n",
            "04/12/2021 06:25:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:25:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for nyccookies.\n",
            "04/12/2021 06:25:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=nyccookies\n",
            "04/12/2021 06:25:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:25:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for obiwanjacobi_tv.\n",
            "04/12/2021 06:25:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=obiwanjacobi_tv\n",
            "04/12/2021 06:25:29 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:25:29 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:25:29 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:25:29 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:25:29 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:25:29 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:25:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1534\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:25:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for octalmage.\n",
            "04/12/2021 06:25:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=octalmage\n",
            "04/12/2021 06:25:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:25:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for oddfutureevee.\n",
            "04/12/2021 06:25:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=oddfutureevee\n",
            "04/12/2021 06:25:31 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:25:31 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:25:31 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:25:31 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:25:31 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:25:31 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:25:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:25:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for officialmaurixo.\n",
            "04/12/2021 06:25:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=officialmaurixo\n",
            "04/12/2021 06:25:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:25:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for officialxjuliaa.\n",
            "04/12/2021 06:25:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=officialxjuliaa\n",
            "04/12/2021 06:25:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:25:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ogackerman.\n",
            "04/12/2021 06:25:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ogackerman\n",
            "04/12/2021 06:25:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1539\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:25:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for oh_ivanna.\n",
            "04/12/2021 06:25:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=oh_ivanna\n",
            "04/12/2021 06:25:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1540\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:25:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ohcoleman.\n",
            "04/12/2021 06:25:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ohcoleman\n",
            "04/12/2021 06:25:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
            "04/12/2021 06:25:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ohitsbrii21.\n",
            "04/12/2021 06:25:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ohitsbrii21\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:25:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:25:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ohvonda.\n",
            "04/12/2021 06:25:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ohvonda\n",
            "04/12/2021 06:25:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:25:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for olandgren.\n",
            "04/12/2021 06:25:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=olandgren\n",
            "04/12/2021 06:25:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1544\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:25:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for oliveratlanta.\n",
            "04/12/2021 06:25:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=oliveratlanta\n",
            "04/12/2021 06:25:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:25:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for olivia_hickey_.\n",
            "04/12/2021 06:25:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=olivia_hickey_\n",
            "04/12/2021 06:25:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:25:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for olivia_karene.\n",
            "04/12/2021 06:25:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=olivia_karene\n",
            "04/12/2021 06:25:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1547\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:25:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for olmedic.\n",
            "04/12/2021 06:25:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=olmedic\n",
            "04/12/2021 06:25:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1548\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:25:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for omar_lizardo.\n",
            "04/12/2021 06:25:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=omar_lizardo\n",
            "04/12/2021 06:25:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1549\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
            "04/12/2021 06:25:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for omgitscaelyn.\n",
            "04/12/2021 06:25:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=omgitscaelyn\n",
            "04/12/2021 06:25:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1550\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:25:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for onlinevalerie.\n",
            "04/12/2021 06:25:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=onlinevalerie\n",
            "04/12/2021 06:25:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:25:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for onlyjuanchance.\n",
            "04/12/2021 06:25:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=onlyjuanchance\n",
            "04/12/2021 06:25:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1552\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:25:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for opelikaaligator.\n",
            "04/12/2021 06:25:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=opelikaaligator\n",
            "04/12/2021 06:25:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1553\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:25:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for orangrabb.\n",
            "04/12/2021 06:25:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=orangrabb\n",
            "04/12/2021 06:25:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:25:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for orlandomicki.\n",
            "04/12/2021 06:25:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=orlandomicki\n",
            "04/12/2021 06:25:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:25:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for orleanscamille.\n",
            "04/12/2021 06:25:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=orleanscamille\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:25:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:25:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for oscarmventura.\n",
            "04/12/2021 06:25:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=oscarmventura\n",
            "04/12/2021 06:25:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1557\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:25:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for osufan_71.\n",
            "04/12/2021 06:25:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=osufan_71\n",
            "04/12/2021 06:25:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:25:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for otis.\n",
            "04/12/2021 06:25:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=otis\n",
            "04/12/2021 06:25:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:25:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for owenwhatever.\n",
            "04/12/2021 06:25:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=owenwhatever\n",
            "04/12/2021 06:25:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1560\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:25:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ox_aln.\n",
            "04/12/2021 06:25:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ox_aln\n",
            "04/12/2021 06:25:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1561\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:25:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ozzy_statesman.\n",
            "04/12/2021 06:25:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ozzy_statesman\n",
            "04/12/2021 06:25:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:25:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for p_wilson83.\n",
            "04/12/2021 06:25:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=p_wilson83\n",
            "04/12/2021 06:25:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:25:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pachs_calabro.\n",
            "04/12/2021 06:25:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pachs_calabro\n",
            "04/12/2021 06:25:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1564\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:25:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for paigealage.\n",
            "04/12/2021 06:25:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=paigealage\n",
            "04/12/2021 06:25:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:25:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for paigemc911.\n",
            "04/12/2021 06:25:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=paigemc911\n",
            "04/12/2021 06:25:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:25:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for paingloss.\n",
            "04/12/2021 06:25:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=paingloss\n",
            "04/12/2021 06:25:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:25:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pam58622393.\n",
            "04/12/2021 06:25:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pam58622393\n",
            "04/12/2021 06:25:59 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:25:59 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:25:59 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:25:59 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:25:59 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:25:59 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:25:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1568\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:26:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pamrotella.\n",
            "04/12/2021 06:26:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pamrotella\n",
            "04/12/2021 06:26:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:26:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for paniceallyssa.\n",
            "04/12/2021 06:26:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=paniceallyssa\n",
            "04/12/2021 06:26:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1570\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:26:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for papa_shmup.\n",
            "04/12/2021 06:26:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=papa_shmup\n",
            "04/12/2021 06:26:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1571\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:26:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for papatvans.\n",
            "04/12/2021 06:26:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=papatvans\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:26:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:26:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for park_anders.\n",
            "04/12/2021 06:26:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=park_anders\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1573\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:26:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:26:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for parkerschrempp.\n",
            "04/12/2021 06:26:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=parkerschrempp\n",
            "04/12/2021 06:26:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:26:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for parkeyjennifer.\n",
            "04/12/2021 06:26:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=parkeyjennifer\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:26:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:26:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for patsfantoro.\n",
            "04/12/2021 06:26:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=patsfantoro\n",
            "04/12/2021 06:26:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1576\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:26:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pattmiles.\n",
            "04/12/2021 06:26:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pattmiles\n",
            "04/12/2021 06:26:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:26:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for paulcurtiscoop3.\n",
            "04/12/2021 06:26:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=paulcurtiscoop3\n",
            "04/12/2021 06:26:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1578\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:26:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for paulstorms.\n",
            "04/12/2021 06:26:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=paulstorms\n",
            "04/12/2021 06:26:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1579\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:26:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for paydenstrizzle.\n",
            "04/12/2021 06:26:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=paydenstrizzle\n",
            "04/12/2021 06:26:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1580\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:26:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for paytonsherman.\n",
            "04/12/2021 06:26:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=paytonsherman\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:26:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:26:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pbrandt4369.\n",
            "04/12/2021 06:26:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pbrandt4369\n",
            "04/12/2021 06:26:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:26:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for peachybellss.\n",
            "04/12/2021 06:26:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=peachybellss\n",
            "04/12/2021 06:26:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:26:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for peachyval__.\n",
            "04/12/2021 06:26:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=peachyval__\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:26:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:26:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for peggyrosepr.\n",
            "04/12/2021 06:26:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=peggyrosepr\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:26:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:26:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for peltzie.\n",
            "04/12/2021 06:26:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=peltzie\n",
            "04/12/2021 06:26:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:26:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for penasteele.\n",
            "04/12/2021 06:26:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=penasteele\n",
            "04/12/2021 06:26:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:26:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for penelope8226.\n",
            "04/12/2021 06:26:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=penelope8226\n",
            "04/12/2021 06:26:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1588\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:26:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for penniii21.\n",
            "04/12/2021 06:26:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=penniii21\n",
            "04/12/2021 06:26:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:26:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pentagrampizza.\n",
            "04/12/2021 06:26:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pentagrampizza\n",
            "04/12/2021 06:26:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1590\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:26:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pepeclinton.\n",
            "04/12/2021 06:26:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pepeclinton\n",
            "04/12/2021 06:26:20 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:26:20 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:26:20 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:26:20 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:26:20 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:26:20 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:26:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:26:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pepinlachance.\n",
            "04/12/2021 06:26:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pepinlachance\n",
            "04/12/2021 06:26:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
            "04/12/2021 06:26:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for peterhassett.\n",
            "04/12/2021 06:26:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=peterhassett\n",
            "04/12/2021 06:26:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:26:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pfannyyy.\n",
            "04/12/2021 06:26:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pfannyyy\n",
            "04/12/2021 06:26:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:26:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for phelps_c98.\n",
            "04/12/2021 06:26:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=phelps_c98\n",
            "04/12/2021 06:26:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1595\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:26:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for photog_johnb.\n",
            "04/12/2021 06:26:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=photog_johnb\n",
            "04/12/2021 06:26:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
            "04/12/2021 06:26:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for phouch.\n",
            "04/12/2021 06:26:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=phouch\n",
            "04/12/2021 06:26:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1597\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:26:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for piercetherose.\n",
            "04/12/2021 06:26:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=piercetherose\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1598\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:26:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:26:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pimpcenta.\n",
            "04/12/2021 06:26:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pimpcenta\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1599\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:26:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:26:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pinkychelle.\n",
            "04/12/2021 06:26:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pinkychelle\n",
            "04/12/2021 06:26:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:26:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pinkytatum.\n",
            "04/12/2021 06:26:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pinkytatum\n",
            "04/12/2021 06:26:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:26:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pipecityy.\n",
            "04/12/2021 06:26:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pipecityy\n",
            "04/12/2021 06:26:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:26:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pissedoffshrimp.\n",
            "04/12/2021 06:26:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pissedoffshrimp\n",
            "04/12/2021 06:26:31 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:26:31 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:26:31 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:26:31 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:26:31 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:26:31 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:26:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:26:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pk_scm.\n",
            "04/12/2021 06:26:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pk_scm\n",
            "04/12/2021 06:26:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
            "04/12/2021 06:26:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for platano_shawty.\n",
            "04/12/2021 06:26:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=platano_shawty\n",
            "04/12/2021 06:26:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1605\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:26:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for plees13.\n",
            "04/12/2021 06:26:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=plees13\n",
            "04/12/2021 06:26:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:26:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pmatons.\n",
            "04/12/2021 06:26:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pmatons\n",
            "04/12/2021 06:26:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:26:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pok3cs.\n",
            "04/12/2021 06:26:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pok3cs\n",
            "04/12/2021 06:26:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:26:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pompey_lucas.\n",
            "04/12/2021 06:26:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pompey_lucas\n",
            "04/12/2021 06:26:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:26:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for poseidonette.\n",
            "04/12/2021 06:26:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=poseidonette\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1610\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:26:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:26:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for powndhownd.\n",
            "04/12/2021 06:26:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=powndhownd\n",
            "04/12/2021 06:26:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:26:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pponsetto.\n",
            "04/12/2021 06:26:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pponsetto\n",
            "04/12/2021 06:26:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:26:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for prettyandplummp.\n",
            "04/12/2021 06:26:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=prettyandplummp\n",
            "04/12/2021 06:26:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:26:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for princelyonion.\n",
            "04/12/2021 06:26:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=princelyonion\n",
            "04/12/2021 06:26:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:26:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for princess_in_ny.\n",
            "04/12/2021 06:26:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=princess_in_ny\n",
            "04/12/2021 06:26:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:26:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for princessscamm_.\n",
            "04/12/2021 06:26:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=princessscamm_\n",
            "04/12/2021 06:26:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1616\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:26:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for princessshenk.\n",
            "04/12/2021 06:26:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=princessshenk\n",
            "04/12/2021 06:26:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1617\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:26:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for procane09.\n",
            "04/12/2021 06:26:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=procane09\n",
            "04/12/2021 06:26:44 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:26:44 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:26:44 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:26:44 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:26:44 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:26:44 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:26:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:26:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for prodigy_jaybee.\n",
            "04/12/2021 06:26:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=prodigy_jaybee\n",
            "04/12/2021 06:26:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1619\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:26:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for prplhaze101.\n",
            "04/12/2021 06:26:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=prplhaze101\n",
            "04/12/2021 06:26:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:26:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for psepi.\n",
            "04/12/2021 06:26:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=psepi\n",
            "04/12/2021 06:26:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:26:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ptnapoleon.\n",
            "04/12/2021 06:26:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ptnapoleon\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:26:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:26:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for pugz1lla.\n",
            "04/12/2021 06:26:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=pugz1lla\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:26:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:26:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for quathyinthesky.\n",
            "04/12/2021 06:26:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=quathyinthesky\n",
            "04/12/2021 06:26:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:26:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for queenawoo.\n",
            "04/12/2021 06:26:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=queenawoo\n",
            "04/12/2021 06:26:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
            "04/12/2021 06:26:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for queenbreeen.\n",
            "04/12/2021 06:26:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=queenbreeen\n",
            "04/12/2021 06:26:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:26:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for queencece_xo.\n",
            "04/12/2021 06:26:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=queencece_xo\n",
            "04/12/2021 06:26:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:26:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for queendollhouse.\n",
            "04/12/2021 06:26:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=queendollhouse\n",
            "04/12/2021 06:26:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:26:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for queenofthesou1.\n",
            "04/12/2021 06:26:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=queenofthesou1\n",
            "04/12/2021 06:26:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:26:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for queenxmads.\n",
            "04/12/2021 06:26:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=queenxmads\n",
            "04/12/2021 06:26:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1630\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:26:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for queerplatypus7.\n",
            "04/12/2021 06:26:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=queerplatypus7\n",
            "04/12/2021 06:26:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:26:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for quiggaveli.\n",
            "04/12/2021 06:26:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=quiggaveli\n",
            "04/12/2021 06:26:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:26:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for quileisreal.\n",
            "04/12/2021 06:26:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=quileisreal\n",
            "04/12/2021 06:26:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1633\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
            "04/12/2021 06:26:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for quinntucky2.\n",
            "04/12/2021 06:26:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=quinntucky2\n",
            "04/12/2021 06:26:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:27:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for qvbrs.\n",
            "04/12/2021 06:27:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=qvbrs\n",
            "04/12/2021 06:27:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1635\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:27:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rabbstermatt.\n",
            "04/12/2021 06:27:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rabbstermatt\n",
            "04/12/2021 06:27:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:27:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rach_greenspan.\n",
            "04/12/2021 06:27:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rach_greenspan\n",
            "04/12/2021 06:27:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:27:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rachel3299.\n",
            "04/12/2021 06:27:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rachel3299\n",
            "04/12/2021 06:27:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1638\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:27:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rachellabbq.\n",
            "04/12/2021 06:27:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rachellabbq\n",
            "04/12/2021 06:27:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:27:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rachelnoel__.\n",
            "04/12/2021 06:27:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rachelnoel__\n",
            "04/12/2021 06:27:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:27:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for radmadbutfab.\n",
            "04/12/2021 06:27:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=radmadbutfab\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:27:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:27:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for raeee_kayla.\n",
            "04/12/2021 06:27:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=raeee_kayla\n",
            "04/12/2021 06:27:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:27:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rainb0w_hat.\n",
            "04/12/2021 06:27:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rainb0w_hat\n",
            "04/12/2021 06:27:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:27:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for raleldil.\n",
            "04/12/2021 06:27:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=raleldil\n",
            "04/12/2021 06:27:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:27:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ramielanude.\n",
            "04/12/2021 06:27:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ramielanude\n",
            "04/12/2021 06:27:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:27:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ransabot.\n",
            "04/12/2021 06:27:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ransabot\n",
            "04/12/2021 06:27:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1646\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:27:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for raquelcalvoo.\n",
            "04/12/2021 06:27:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=raquelcalvoo\n",
            "04/12/2021 06:27:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:27:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rashad_hughston.\n",
            "04/12/2021 06:27:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rashad_hughston\n",
            "04/12/2021 06:27:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:27:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rauljohsua.\n",
            "04/12/2021 06:27:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rauljohsua\n",
            "04/12/2021 06:27:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:27:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for raviroy23.\n",
            "04/12/2021 06:27:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=raviroy23\n",
            "04/12/2021 06:27:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1650\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:27:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for raysullivann.\n",
            "04/12/2021 06:27:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=raysullivann\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:27:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:27:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rayvenmoore.\n",
            "04/12/2021 06:27:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rayvenmoore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1652\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:27:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:27:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rcxrly.\n",
            "04/12/2021 06:27:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rcxrly\n",
            "04/12/2021 06:27:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:27:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rdusty10.\n",
            "04/12/2021 06:27:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rdusty10\n",
            "04/12/2021 06:27:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:27:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for realaaronmounts.\n",
            "04/12/2021 06:27:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=realaaronmounts\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:27:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:27:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for realchadjohnson.\n",
            "04/12/2021 06:27:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=realchadjohnson\n",
            "04/12/2021 06:27:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
            "04/12/2021 06:27:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for realkaralynn.\n",
            "04/12/2021 06:27:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=realkaralynn\n",
            "04/12/2021 06:27:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:27:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for realliltush.\n",
            "04/12/2021 06:27:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=realliltush\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1658\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:27:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:27:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for realphillipsa.\n",
            "04/12/2021 06:27:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=realphillipsa\n",
            "04/12/2021 06:27:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:27:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for realreala.\n",
            "04/12/2021 06:27:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=realreala\n",
            "04/12/2021 06:27:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:27:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for realronniejames.\n",
            "04/12/2021 06:27:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=realronniejames\n",
            "04/12/2021 06:27:24 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:27:24 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:27:24 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:27:24 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:27:24 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:27:24 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:27:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1661\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:27:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rebeccacarmen.\n",
            "04/12/2021 06:27:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rebeccacarmen\n",
            "04/12/2021 06:27:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1662\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:27:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rebeccaspence72.\n",
            "04/12/2021 06:27:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rebeccaspence72\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1663\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:27:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:27:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rebekkamains.\n",
            "04/12/2021 06:27:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rebekkamains\n",
            "04/12/2021 06:27:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:27:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for recoveringprof.\n",
            "04/12/2021 06:27:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=recoveringprof\n",
            "04/12/2021 06:27:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
            "04/12/2021 06:27:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for redheaded_jenn.\n",
            "04/12/2021 06:27:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=redheaded_jenn\n",
            "04/12/2021 06:27:28 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:27:28 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:27:28 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:27:28 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:27:28 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:27:28 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:27:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:27:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for reepsrolyat.\n",
            "04/12/2021 06:27:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=reepsrolyat\n",
            "04/12/2021 06:27:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:27:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for reevynap.\n",
            "04/12/2021 06:27:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=reevynap\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:27:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:27:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for reharmon56.\n",
            "04/12/2021 06:27:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=reharmon56\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:27:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:27:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for reichert_liz.\n",
            "04/12/2021 06:27:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=reichert_liz\n",
            "04/12/2021 06:27:32 - INFO - m3inference.dataset -   1 data entries loaded.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1670\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:27:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for renz360.\n",
            "04/12/2021 06:27:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=renz360\n",
            "04/12/2021 06:27:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1671\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:27:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for repdrewferguson.\n",
            "04/12/2021 06:27:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=repdrewferguson\n",
            "04/12/2021 06:27:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1672\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
            "04/12/2021 06:27:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for reppocs.\n",
            "04/12/2021 06:27:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=reppocs\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1673\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:27:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:27:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for reverendjon.\n",
            "04/12/2021 06:27:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=reverendjon\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:27:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:27:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rgarcia63.\n",
            "04/12/2021 06:27:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rgarcia63\n",
            "04/12/2021 06:27:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:27:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rhawk55.\n",
            "04/12/2021 06:27:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rhawk55\n",
            "04/12/2021 06:27:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1676\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:27:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rhbrowning.\n",
            "04/12/2021 06:27:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rhbrowning\n",
            "04/12/2021 06:27:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
            "04/12/2021 06:27:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rhondaryoung.\n",
            "04/12/2021 06:27:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rhondaryoung\n",
            "04/12/2021 06:27:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
            "04/12/2021 06:27:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ricee_cake.\n",
            "04/12/2021 06:27:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ricee_cake\n",
            "04/12/2021 06:27:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:27:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for richardwisler.\n",
            "04/12/2021 06:27:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=richardwisler\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1680\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:27:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
            "04/12/2021 06:27:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rickmil69704052.\n",
            "04/12/2021 06:27:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rickmil69704052\n",
            "04/12/2021 06:27:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1681\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
            "04/12/2021 06:27:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ricktimbs.\n",
            "04/12/2021 06:27:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ricktimbs\n",
            "04/12/2021 06:27:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1682\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
            "04/12/2021 06:27:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rigorrmorrtis.\n",
            "04/12/2021 06:27:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rigorrmorrtis\n",
            "04/12/2021 06:27:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
            "04/12/2021 06:27:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rilaniii.\n",
            "04/12/2021 06:27:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rilaniii\n",
            "04/12/2021 06:27:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1684\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:27:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rileighgraham.\n",
            "04/12/2021 06:27:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rileighgraham\n",
            "04/12/2021 06:27:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:27:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for riloskir.\n",
            "04/12/2021 06:27:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=riloskir\n",
            "04/12/2021 06:27:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1686\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:27:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rjurgy_12.\n",
            "04/12/2021 06:27:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rjurgy_12\n",
            "04/12/2021 06:27:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:27:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rob_l_collier.\n",
            "04/12/2021 06:27:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rob_l_collier\n",
            "04/12/2021 06:27:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:27:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for robbyfnblaze.\n",
            "04/12/2021 06:27:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=robbyfnblaze\n",
            "04/12/2021 06:27:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1689\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:27:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for robbyjmoore.\n",
            "04/12/2021 06:27:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=robbyjmoore\n",
            "04/12/2021 06:27:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1690\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:27:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for robert_tedesco.\n",
            "04/12/2021 06:27:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=robert_tedesco\n",
            "04/12/2021 06:27:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:27:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for roberts1ngleton.\n",
            "04/12/2021 06:27:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=roberts1ngleton\n",
            "04/12/2021 06:27:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:27:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for robertthepotter.\n",
            "04/12/2021 06:27:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=robertthepotter\n",
            "04/12/2021 06:27:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:27:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for robin_mccoy_.\n",
            "04/12/2021 06:27:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=robin_mccoy_\n",
            "04/12/2021 06:27:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:27:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for robynnlea_.\n",
            "04/12/2021 06:27:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=robynnlea_\n",
            "04/12/2021 06:27:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:27:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rocnhog1.\n",
            "04/12/2021 06:27:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rocnhog1\n",
            "04/12/2021 06:27:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:27:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rogeliomartian.\n",
            "04/12/2021 06:27:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rogeliomartian\n",
            "04/12/2021 06:27:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:27:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rogeromfg.\n",
            "04/12/2021 06:27:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rogeromfg\n",
            "04/12/2021 06:27:58 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:27:58 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:27:58 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:27:58 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:27:58 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:27:58 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:27:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1698\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:27:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rohan98111.\n",
            "04/12/2021 06:27:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rohan98111\n",
            "04/12/2021 06:27:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:28:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rohry_music.\n",
            "04/12/2021 06:28:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rohry_music\n",
            "04/12/2021 06:28:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:28:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rollergir1.\n",
            "04/12/2021 06:28:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rollergir1\n",
            "04/12/2021 06:28:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:28:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rolyatetak.\n",
            "04/12/2021 06:28:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rolyatetak\n",
            "04/12/2021 06:28:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:28:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for romayroh.\n",
            "04/12/2021 06:28:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=romayroh\n",
            "04/12/2021 06:28:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:28:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ronhogan.\n",
            "04/12/2021 06:28:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ronhogan\n",
            "04/12/2021 06:28:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
            "04/12/2021 06:28:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for roocrow.\n",
            "04/12/2021 06:28:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=roocrow\n",
            "04/12/2021 06:28:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
            "04/12/2021 06:28:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rosanneazarian.\n",
            "04/12/2021 06:28:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rosanneazarian\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:28:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:28:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rosehoban.\n",
            "04/12/2021 06:28:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rosehoban\n",
            "04/12/2021 06:28:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
            "04/12/2021 06:28:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for roselynnn_1.\n",
            "04/12/2021 06:28:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=roselynnn_1\n",
            "04/12/2021 06:28:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:28:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rowerikw.\n",
            "04/12/2021 06:28:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rowerikw\n",
            "04/12/2021 06:28:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:28:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rriceboii.\n",
            "04/12/2021 06:28:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rriceboii\n",
            "04/12/2021 06:28:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1710\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:28:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rsl012548.\n",
            "04/12/2021 06:28:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rsl012548\n",
            "04/12/2021 06:28:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:28:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rubyranda_.\n",
            "04/12/2021 06:28:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rubyranda_\n",
            "04/12/2021 06:28:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1712\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:28:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rudehunch.\n",
            "04/12/2021 06:28:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rudehunch\n",
            "04/12/2021 06:28:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
            "04/12/2021 06:28:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ruizphysique.\n",
            "04/12/2021 06:28:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ruizphysique\n",
            "04/12/2021 06:28:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:28:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ruoffendedyetb.\n",
            "04/12/2021 06:28:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ruoffendedyetb\n",
            "04/12/2021 06:28:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:28:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ruthymunoz.\n",
            "04/12/2021 06:28:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ruthymunoz\n",
            "04/12/2021 06:28:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:28:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ruxbat.\n",
            "04/12/2021 06:28:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ruxbat\n",
            "04/12/2021 06:28:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:28:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for rye_bread_bi.\n",
            "04/12/2021 06:28:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=rye_bread_bi\n",
            "04/12/2021 06:28:16 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:28:16 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:28:16 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:28:16 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:28:16 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:28:16 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:28:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1718\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:28:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for s_cilla_xo.\n",
            "04/12/2021 06:28:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=s_cilla_xo\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:28:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:28:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sad_grrrrl.\n",
            "04/12/2021 06:28:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sad_grrrrl\n",
            "04/12/2021 06:28:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:28:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for saddbino.\n",
            "04/12/2021 06:28:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=saddbino\n",
            "04/12/2021 06:28:19 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:28:19 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:28:19 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:28:19 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:28:19 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:28:19 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:28:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:28:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sadgirlfall.\n",
            "04/12/2021 06:28:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sadgirlfall\n",
            "04/12/2021 06:28:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:28:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sadieanne01.\n",
            "04/12/2021 06:28:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sadieanne01\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:28:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:28:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sadpalemami.\n",
            "04/12/2021 06:28:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sadpalemami\n",
            "04/12/2021 06:28:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:28:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for saesee_steven.\n",
            "04/12/2021 06:28:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=saesee_steven\n",
            "04/12/2021 06:28:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:28:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sahara_hansen.\n",
            "04/12/2021 06:28:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sahara_hansen\n",
            "04/12/2021 06:28:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:28:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for saintfdw.\n",
            "04/12/2021 06:28:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=saintfdw\n",
            "04/12/2021 06:28:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:28:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for saleashuh.\n",
            "04/12/2021 06:28:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=saleashuh\n",
            "04/12/2021 06:28:25 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:28:25 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:28:25 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:28:25 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:28:25 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:28:25 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:28:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:28:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for salojoelina.\n",
            "04/12/2021 06:28:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=salojoelina\n",
            "04/12/2021 06:28:25 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:28:25 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:28:25 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:28:25 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:28:25 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:28:25 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:28:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:28:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for salsaprice.\n",
            "04/12/2021 06:28:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=salsaprice\n",
            "04/12/2021 06:28:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1730\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:28:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sam_nunes_21.\n",
            "04/12/2021 06:28:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sam_nunes_21\n",
            "04/12/2021 06:28:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1731\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:28:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sambytheseaa.\n",
            "04/12/2021 06:28:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sambytheseaa\n",
            "04/12/2021 06:28:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:28:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sammiesammm42.\n",
            "04/12/2021 06:28:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sammiesammm42\n",
            "04/12/2021 06:28:29 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:28:29 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:28:29 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:28:29 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:28:29 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:28:29 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:28:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:28:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for samonella___.\n",
            "04/12/2021 06:28:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=samonella___\n",
            "04/12/2021 06:28:30 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:28:30 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:28:30 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:28:30 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:28:30 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:28:30 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:28:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:28:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for samstout_.\n",
            "04/12/2021 06:28:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=samstout_\n",
            "04/12/2021 06:28:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:28:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sandraglanton.\n",
            "04/12/2021 06:28:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sandraglanton\n",
            "04/12/2021 06:28:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:28:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for saniom1.\n",
            "04/12/2021 06:28:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=saniom1\n",
            "04/12/2021 06:28:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:28:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sapphiceevee.\n",
            "04/12/2021 06:28:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sapphiceevee\n",
            "04/12/2021 06:28:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
            "04/12/2021 06:28:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for saraaleone.\n",
            "04/12/2021 06:28:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=saraaleone\n",
            "04/12/2021 06:28:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1739\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:28:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sarahapanek.\n",
            "04/12/2021 06:28:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sarahapanek\n",
            "04/12/2021 06:28:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:28:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sarahellenbell.\n",
            "04/12/2021 06:28:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sarahellenbell\n",
            "04/12/2021 06:28:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:28:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for saraheneedleman.\n",
            "04/12/2021 06:28:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=saraheneedleman\n",
            "04/12/2021 06:28:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:28:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sarahhhaddonn.\n",
            "04/12/2021 06:28:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sarahhhaddonn\n",
            "04/12/2021 06:28:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:28:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sarahmessina_.\n",
            "04/12/2021 06:28:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sarahmessina_\n",
            "04/12/2021 06:28:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:28:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sarahtstewart.\n",
            "04/12/2021 06:28:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sarahtstewart\n",
            "04/12/2021 06:28:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:28:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sarajeffy.\n",
            "04/12/2021 06:28:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sarajeffy\n",
            "04/12/2021 06:28:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:28:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sassy_gramma.\n",
            "04/12/2021 06:28:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sassy_gramma\n",
            "04/12/2021 06:28:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:28:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for saturnrosee.\n",
            "04/12/2021 06:28:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=saturnrosee\n",
            "04/12/2021 06:28:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:28:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for savannahnanbell.\n",
            "04/12/2021 06:28:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=savannahnanbell\n",
            "04/12/2021 06:28:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1749\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:28:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for savbeckwith.\n",
            "04/12/2021 06:28:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=savbeckwith\n",
            "04/12/2021 06:28:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:28:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for savvyy18.\n",
            "04/12/2021 06:28:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=savvyy18\n",
            "04/12/2021 06:28:45 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:28:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:28:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sawitwosw.\n",
            "04/12/2021 06:28:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sawitwosw\n",
            "04/12/2021 06:28:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:28:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sawybeans_.\n",
            "04/12/2021 06:28:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sawybeans_\n",
            "04/12/2021 06:28:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:28:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sberghuis43.\n",
            "04/12/2021 06:28:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sberghuis43\n",
            "04/12/2021 06:28:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:28:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sbjames2327.\n",
            "04/12/2021 06:28:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sbjames2327\n",
            "04/12/2021 06:28:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
            "04/12/2021 06:28:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sbocade.\n",
            "04/12/2021 06:28:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sbocade\n",
            "04/12/2021 06:28:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:28:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for scabbyscribe56.\n",
            "04/12/2021 06:28:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=scabbyscribe56\n",
            "04/12/2021 06:28:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:28:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for scarlet_kitteh.\n",
            "04/12/2021 06:28:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=scarlet_kitteh\n",
            "04/12/2021 06:28:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:28:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for scbaldwin.\n",
            "04/12/2021 06:28:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=scbaldwin\n",
            "04/12/2021 06:28:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:28:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for scemensky.\n",
            "04/12/2021 06:28:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=scemensky\n",
            "04/12/2021 06:28:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:28:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sckrjoe.\n",
            "04/12/2021 06:28:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sckrjoe\n",
            "04/12/2021 06:28:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:28:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for scolipoliolli.\n",
            "04/12/2021 06:28:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=scolipoliolli\n",
            "04/12/2021 06:28:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:28:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for scotlandfog.\n",
            "04/12/2021 06:28:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=scotlandfog\n",
            "04/12/2021 06:28:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1763\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:28:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for scottconso.\n",
            "04/12/2021 06:28:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=scottconso\n",
            "04/12/2021 06:28:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:28:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sean_chris10.\n",
            "04/12/2021 06:28:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sean_chris10\n",
            "04/12/2021 06:28:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:28:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for seattlesbadboy.\n",
            "04/12/2021 06:28:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=seattlesbadboy\n",
            "04/12/2021 06:28:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:28:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sebastinnichols.\n",
            "04/12/2021 06:28:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sebastinnichols\n",
            "04/12/2021 06:28:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:29:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for seho82.\n",
            "04/12/2021 06:29:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=seho82\n",
            "04/12/2021 06:29:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1768\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:29:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for selyna408.\n",
            "04/12/2021 06:29:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=selyna408\n",
            "04/12/2021 06:29:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:29:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for senyapraja.\n",
            "04/12/2021 06:29:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=senyapraja\n",
            "04/12/2021 06:29:02 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:29:02 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:29:02 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:29:02 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:29:02 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:29:02 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:29:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1770\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:29:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sergadry.\n",
            "04/12/2021 06:29:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sergadry\n",
            "04/12/2021 06:29:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:29:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sergsayz.\n",
            "04/12/2021 06:29:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sergsayz\n",
            "04/12/2021 06:29:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:29:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sexbot2k.\n",
            "04/12/2021 06:29:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sexbot2k\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:29:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:29:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sh_rk_tt_ck.\n",
            "04/12/2021 06:29:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sh_rk_tt_ck\n",
            "04/12/2021 06:29:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:29:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shakabrawl.\n",
            "04/12/2021 06:29:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shakabrawl\n",
            "04/12/2021 06:29:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:29:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shakdadday.\n",
            "04/12/2021 06:29:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shakdadday\n",
            "04/12/2021 06:29:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1776\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:29:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shane_prender15.\n",
            "04/12/2021 06:29:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shane_prender15\n",
            "04/12/2021 06:29:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1777\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:29:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shaniahlavacek.\n",
            "04/12/2021 06:29:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shaniahlavacek\n",
            "04/12/2021 06:29:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:29:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shannicholls_.\n",
            "04/12/2021 06:29:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shannicholls_\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1779\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:29:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:29:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shannondl31.\n",
            "04/12/2021 06:29:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shannondl31\n",
            "04/12/2021 06:29:10 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:29:10 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:29:10 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:29:10 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:29:10 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:29:10 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:29:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:29:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shannontwote.\n",
            "04/12/2021 06:29:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shannontwote\n",
            "04/12/2021 06:29:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:29:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shanzeenah.\n",
            "04/12/2021 06:29:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shanzeenah\n",
            "04/12/2021 06:29:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:29:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sharebear817.\n",
            "04/12/2021 06:29:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sharebear817\n",
            "04/12/2021 06:29:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:29:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sharlenemc_s.\n",
            "04/12/2021 06:29:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sharlenemc_s\n",
            "04/12/2021 06:29:14 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:29:14 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:29:14 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:29:14 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:29:14 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:29:14 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:29:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:29:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sharonzjewelry.\n",
            "04/12/2021 06:29:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sharonzjewelry\n",
            "04/12/2021 06:29:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1785\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:29:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shaungriff.\n",
            "04/12/2021 06:29:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shaungriff\n",
            "04/12/2021 06:29:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:29:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shawnngee.\n",
            "04/12/2021 06:29:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shawnngee\n",
            "04/12/2021 06:29:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:29:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shehasnoname999.\n",
            "04/12/2021 06:29:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shehasnoname999\n",
            "04/12/2021 06:29:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:29:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sheiladelgadog.\n",
            "04/12/2021 06:29:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sheiladelgadog\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:29:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:29:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shelbaerobx.\n",
            "04/12/2021 06:29:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shelbaerobx\n",
            "04/12/2021 06:29:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:29:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shelby_mcadams.\n",
            "04/12/2021 06:29:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shelby_mcadams\n",
            "04/12/2021 06:29:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:29:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shelbymuzny.\n",
            "04/12/2021 06:29:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shelbymuzny\n",
            "04/12/2021 06:29:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:29:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shellylonginot2.\n",
            "04/12/2021 06:29:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shellylonginot2\n",
            "04/12/2021 06:29:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:29:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sherijr.\n",
            "04/12/2021 06:29:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sherijr\n",
            "04/12/2021 06:29:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:29:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sherrykdelaney.\n",
            "04/12/2021 06:29:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sherrykdelaney\n",
            "04/12/2021 06:29:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:29:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shessteeleloved.\n",
            "04/12/2021 06:29:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shessteeleloved\n",
            "04/12/2021 06:29:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:29:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shikona.\n",
            "04/12/2021 06:29:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shikona\n",
            "04/12/2021 06:29:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:29:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shiloh_miller70.\n",
            "04/12/2021 06:29:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shiloh_miller70\n",
            "04/12/2021 06:29:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:29:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shimor.\n",
            "04/12/2021 06:29:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shimor\n",
            "04/12/2021 06:29:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:29:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shitnotyouagain.\n",
            "04/12/2021 06:29:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shitnotyouagain\n",
            "04/12/2021 06:29:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:29:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shortnsassy1990.\n",
            "04/12/2021 06:29:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shortnsassy1990\n",
            "04/12/2021 06:29:29 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:29:29 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:29:29 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:29:29 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:29:29 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:29:29 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:29:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:29:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for shsjacketvball.\n",
            "04/12/2021 06:29:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=shsjacketvball\n",
            "04/12/2021 06:29:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:29:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sierrasevier.\n",
            "04/12/2021 06:29:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sierrasevier\n",
            "04/12/2021 06:29:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:29:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for siiddd7.\n",
            "04/12/2021 06:29:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=siiddd7\n",
            "04/12/2021 06:29:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:29:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sir_mart_ash.\n",
            "04/12/2021 06:29:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sir_mart_ash\n",
            "04/12/2021 06:29:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:29:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sirenscrytoo.\n",
            "04/12/2021 06:29:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sirenscrytoo\n",
            "04/12/2021 06:29:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1806\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:29:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sjmarkwood.\n",
            "04/12/2021 06:29:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sjmarkwood\n",
            "04/12/2021 06:29:34 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:29:34 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:29:34 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:29:34 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:29:34 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:29:34 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:29:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:29:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sjsbeats.\n",
            "04/12/2021 06:29:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sjsbeats\n",
            "04/12/2021 06:29:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:29:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for skyjjj.\n",
            "04/12/2021 06:29:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=skyjjj\n",
            "04/12/2021 06:29:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:29:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for skyliemarie_.\n",
            "04/12/2021 06:29:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=skyliemarie_\n",
            "04/12/2021 06:29:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:29:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for slickbackb.\n",
            "04/12/2021 06:29:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=slickbackb\n",
            "04/12/2021 06:29:38 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:29:38 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:29:38 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:29:38 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:29:38 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:29:38 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:29:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:29:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for slkaplanmd.\n",
            "04/12/2021 06:29:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=slkaplanmd\n",
            "04/12/2021 06:29:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:29:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for smhboba.\n",
            "04/12/2021 06:29:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=smhboba\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:29:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:29:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for smilemorepenny.\n",
            "04/12/2021 06:29:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=smilemorepenny\n",
            "04/12/2021 06:29:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:29:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for smokeseattle.\n",
            "04/12/2021 06:29:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=smokeseattle\n",
            "04/12/2021 06:29:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:29:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for smoresmartin.\n",
            "04/12/2021 06:29:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=smoresmartin\n",
            "04/12/2021 06:29:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:29:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for smuttysquid.\n",
            "04/12/2021 06:29:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=smuttysquid\n",
            "04/12/2021 06:29:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:29:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sneedfoe409.\n",
            "04/12/2021 06:29:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sneedfoe409\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:29:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:29:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for so_curly10.\n",
            "04/12/2021 06:29:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=so_curly10\n",
            "04/12/2021 06:29:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:29:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for soberd4d.\n",
            "04/12/2021 06:29:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=soberd4d\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1820\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:29:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:29:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sodacola52.\n",
            "04/12/2021 06:29:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sodacola52\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:29:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:29:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for soenda.\n",
            "04/12/2021 06:29:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=soenda\n",
            "04/12/2021 06:29:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:29:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sofiilroy.\n",
            "04/12/2021 06:29:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sofiilroy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1823\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:29:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:29:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for solas_na_greine.\n",
            "04/12/2021 06:29:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=solas_na_greine\n",
            "04/12/2021 06:29:50 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:29:50 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:29:50 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:29:50 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:29:50 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:29:50 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:29:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:29:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for soovrtherainbow.\n",
            "04/12/2021 06:29:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=soovrtherainbow\n",
            "04/12/2021 06:29:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:29:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sophiebushman.\n",
            "04/12/2021 06:29:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sophiebushman\n",
            "04/12/2021 06:29:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:29:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sophiekhadija.\n",
            "04/12/2021 06:29:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sophiekhadija\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1827\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:29:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:29:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sp_acevex.\n",
            "04/12/2021 06:29:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sp_acevex\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:29:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:29:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for spacedowt01.\n",
            "04/12/2021 06:29:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=spacedowt01\n",
            "04/12/2021 06:29:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:29:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for spacehailey.\n",
            "04/12/2021 06:29:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=spacehailey\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:29:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:29:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for spacepatrollyle.\n",
            "04/12/2021 06:29:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=spacepatrollyle\n",
            "04/12/2021 06:29:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:29:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for spacerose94.\n",
            "04/12/2021 06:29:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=spacerose94\n",
            "04/12/2021 06:29:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:29:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for speakercoughlin.\n",
            "04/12/2021 06:29:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=speakercoughlin\n",
            "04/12/2021 06:29:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:29:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for speshul_wes.\n",
            "04/12/2021 06:29:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=speshul_wes\n",
            "04/12/2021 06:29:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:30:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for spicytunarolll.\n",
            "04/12/2021 06:30:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=spicytunarolll\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:30:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:30:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for spunkiscientist.\n",
            "04/12/2021 06:30:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=spunkiscientist\n",
            "04/12/2021 06:30:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:30:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for squallstaffan.\n",
            "04/12/2021 06:30:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=squallstaffan\n",
            "04/12/2021 06:30:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:30:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for srslyomgwtfbro.\n",
            "04/12/2021 06:30:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=srslyomgwtfbro\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:30:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:30:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ssagesk.\n",
            "04/12/2021 06:30:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ssagesk\n",
            "04/12/2021 06:30:04 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:30:04 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:30:04 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:30:04 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:30:04 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:30:04 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:30:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:30:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ssliik.\n",
            "04/12/2021 06:30:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ssliik\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:30:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:30:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ssodorian.\n",
            "04/12/2021 06:30:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ssodorian\n",
            "04/12/2021 06:30:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1841\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:30:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sssydneyhehe.\n",
            "04/12/2021 06:30:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sssydneyhehe\n",
            "04/12/2021 06:30:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:30:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sstorm01.\n",
            "04/12/2021 06:30:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sstorm01\n",
            "04/12/2021 06:30:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:30:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for st0rmii__.\n",
            "04/12/2021 06:30:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=st0rmii__\n",
            "04/12/2021 06:30:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:30:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stacy_b.\n",
            "04/12/2021 06:30:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stacy_b\n",
            "04/12/2021 06:30:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:30:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stainfacemane.\n",
            "04/12/2021 06:30:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stainfacemane\n",
            "04/12/2021 06:30:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:30:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for starfallgoddess.\n",
            "04/12/2021 06:30:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=starfallgoddess\n",
            "04/12/2021 06:30:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:30:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for starz_wayne.\n",
            "04/12/2021 06:30:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=starz_wayne\n",
            "04/12/2021 06:30:12 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:30:12 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:30:12 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:30:12 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:30:12 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:30:12 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:30:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:30:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for staterepbain.\n",
            "04/12/2021 06:30:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=staterepbain\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1849\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:30:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:30:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for steamboatwillyo.\n",
            "04/12/2021 06:30:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=steamboatwillyo\n",
            "04/12/2021 06:30:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1850\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:30:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stefisbright.\n",
            "04/12/2021 06:30:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stefisbright\n",
            "04/12/2021 06:30:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:30:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stelladcox.\n",
            "04/12/2021 06:30:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stelladcox\n",
            "04/12/2021 06:30:16 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:30:16 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:30:16 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:30:16 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:30:16 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:30:16 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:30:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1852\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:30:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stepha_nie_vee.\n",
            "04/12/2021 06:30:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stepha_nie_vee\n",
            "04/12/2021 06:30:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
            "04/12/2021 06:30:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stephaniedvine.\n",
            "04/12/2021 06:30:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stephaniedvine\n",
            "04/12/2021 06:30:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:30:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stephensailspdx.\n",
            "04/12/2021 06:30:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stephensailspdx\n",
            "04/12/2021 06:30:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
            "04/12/2021 06:30:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stephmannn.\n",
            "04/12/2021 06:30:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stephmannn\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:30:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:30:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for steve_bozic.\n",
            "04/12/2021 06:30:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=steve_bozic\n",
            "04/12/2021 06:30:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:30:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stevenmurillo21.\n",
            "04/12/2021 06:30:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stevenmurillo21\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1858\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:30:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:30:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stevenyangxx.\n",
            "04/12/2021 06:30:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stevenyangxx\n",
            "04/12/2021 06:30:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:30:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stilchy.\n",
            "04/12/2021 06:30:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stilchy\n",
            "04/12/2021 06:30:23 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:30:23 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:30:23 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:30:23 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:30:23 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:30:23 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:30:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:30:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stonedcoid.\n",
            "04/12/2021 06:30:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stonedcoid\n",
            "04/12/2021 06:30:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:30:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for storyslug.\n",
            "04/12/2021 06:30:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=storyslug\n",
            "04/12/2021 06:30:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:30:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stphil.\n",
            "04/12/2021 06:30:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stphil\n",
            "04/12/2021 06:30:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1863\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:30:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for streetsouls16.\n",
            "04/12/2021 06:30:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=streetsouls16\n",
            "04/12/2021 06:30:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:30:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for strike_cvi.\n",
            "04/12/2021 06:30:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=strike_cvi\n",
            "04/12/2021 06:30:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1865\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:30:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for strwbrrymlkt.\n",
            "04/12/2021 06:30:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=strwbrrymlkt\n",
            "04/12/2021 06:30:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:30:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for stubdastud.\n",
            "04/12/2021 06:30:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=stubdastud\n",
            "04/12/2021 06:30:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:30:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for subatomicdoc.\n",
            "04/12/2021 06:30:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=subatomicdoc\n",
            "04/12/2021 06:30:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:30:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for suck_my_sam.\n",
            "04/12/2021 06:30:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=suck_my_sam\n",
            "04/12/2021 06:30:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:30:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for suckafreeebri.\n",
            "04/12/2021 06:30:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=suckafreeebri\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1870\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:30:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:30:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sunoveristambul.\n",
            "04/12/2021 06:30:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sunoveristambul\n",
            "04/12/2021 06:30:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:30:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for supadolphan.\n",
            "04/12/2021 06:30:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=supadolphan\n",
            "04/12/2021 06:30:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:30:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for superpixels.\n",
            "04/12/2021 06:30:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=superpixels\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:30:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
            "04/12/2021 06:30:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for supran2omar.\n",
            "04/12/2021 06:30:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=supran2omar\n",
            "04/12/2021 06:30:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:30:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for surfkujo.\n",
            "04/12/2021 06:30:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=surfkujo\n",
            "04/12/2021 06:30:37 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:30:37 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:30:37 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:30:37 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:30:37 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:30:37 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:30:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:30:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for suziraeee.\n",
            "04/12/2021 06:30:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=suziraeee\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:30:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:30:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for svechinlarisa.\n",
            "04/12/2021 06:30:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=svechinlarisa\n",
            "04/12/2021 06:30:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:30:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for svveetalexa.\n",
            "04/12/2021 06:30:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=svveetalexa\n",
            "04/12/2021 06:30:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:30:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for swagger372.\n",
            "04/12/2021 06:30:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=swagger372\n",
            "04/12/2021 06:30:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:30:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for swalker_43.\n",
            "04/12/2021 06:30:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=swalker_43\n",
            "04/12/2021 06:30:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:30:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for swamp_surprise.\n",
            "04/12/2021 06:30:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=swamp_surprise\n",
            "04/12/2021 06:30:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1881\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:30:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for swanny23.\n",
            "04/12/2021 06:30:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=swanny23\n",
            "04/12/2021 06:30:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1882\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:30:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for swavey_orlando.\n",
            "04/12/2021 06:30:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=swavey_orlando\n",
            "04/12/2021 06:30:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1883\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:30:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sweetestthreat.\n",
            "04/12/2021 06:30:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sweetestthreat\n",
            "04/12/2021 06:30:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:30:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for swerve2850.\n",
            "04/12/2021 06:30:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=swerve2850\n",
            "04/12/2021 06:30:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:30:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for syd_wilburn.\n",
            "04/12/2021 06:30:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=syd_wilburn\n",
            "04/12/2021 06:30:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:30:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sydney_smith99.\n",
            "04/12/2021 06:30:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sydney_smith99\n",
            "04/12/2021 06:30:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:30:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sydneywsanders.\n",
            "04/12/2021 06:30:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sydneywsanders\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:30:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:30:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for sydsheehan5.\n",
            "04/12/2021 06:30:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=sydsheehan5\n",
            "04/12/2021 06:30:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:30:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for syorkmi.\n",
            "04/12/2021 06:30:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=syorkmi\n",
            "04/12/2021 06:30:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:30:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for t_abee33.\n",
            "04/12/2021 06:30:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=t_abee33\n",
            "04/12/2021 06:30:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:30:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for t_kawasaki02.\n",
            "04/12/2021 06:30:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=t_kawasaki02\n",
            "04/12/2021 06:30:52 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:30:52 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:30:52 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:30:52 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:30:52 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:30:52 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:30:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:30:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for t_radz.\n",
            "04/12/2021 06:30:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=t_radz\n",
            "04/12/2021 06:30:53 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:30:53 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:30:53 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:30:53 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:30:53 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:30:53 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:30:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:30:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tacticalfruit.\n",
            "04/12/2021 06:30:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tacticalfruit\n",
            "04/12/2021 06:30:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:30:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for taglealexx.\n",
            "04/12/2021 06:30:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=taglealexx\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:30:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:30:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for takeashortroutt.\n",
            "04/12/2021 06:30:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=takeashortroutt\n",
            "04/12/2021 06:30:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:30:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tall_ayden.\n",
            "04/12/2021 06:30:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tall_ayden\n",
            "04/12/2021 06:30:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:30:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for taniella67.\n",
            "04/12/2021 06:30:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=taniella67\n",
            "04/12/2021 06:30:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:30:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tanisharrao.\n",
            "04/12/2021 06:30:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tanisharrao\n",
            "04/12/2021 06:30:58 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:30:58 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:30:58 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:30:58 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:30:58 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:30:58 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:30:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
            "04/12/2021 06:30:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tannera_olson.\n",
            "04/12/2021 06:30:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tannera_olson\n",
            "04/12/2021 06:30:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:31:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for taryn_mackennaa.\n",
            "04/12/2021 06:31:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=taryn_mackennaa\n",
            "04/12/2021 06:31:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1901\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:31:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tatersaurusrex.\n",
            "04/12/2021 06:31:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tatersaurusrex\n",
            "04/12/2021 06:31:01 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:31:01 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:31:01 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:31:01 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:31:01 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:31:01 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:31:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1902\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:31:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for taugenthaler.\n",
            "04/12/2021 06:31:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=taugenthaler\n",
            "04/12/2021 06:31:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:31:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for taylor_hockey8.\n",
            "04/12/2021 06:31:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=taylor_hockey8\n",
            "04/12/2021 06:31:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:31:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for taylorrdawnnnn.\n",
            "04/12/2021 06:31:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=taylorrdawnnnn\n",
            "04/12/2021 06:31:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1905\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:31:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for taylorrrdeanne.\n",
            "04/12/2021 06:31:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=taylorrrdeanne\n",
            "04/12/2021 06:31:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:31:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for taythewelder.\n",
            "04/12/2021 06:31:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=taythewelder\n",
            "04/12/2021 06:31:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:31:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tcapspresident.\n",
            "04/12/2021 06:31:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tcapspresident\n",
            "04/12/2021 06:31:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:31:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tchoumd.\n",
            "04/12/2021 06:31:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tchoumd\n",
            "04/12/2021 06:31:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:31:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tealeksunthon.\n",
            "04/12/2021 06:31:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tealeksunthon\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1910\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:31:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for techgnostik.\n",
            "04/12/2021 06:31:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=techgnostik\n",
            "04/12/2021 06:31:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:31:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for teddy_montoya.\n",
            "04/12/2021 06:31:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=teddy_montoya\n",
            "04/12/2021 06:31:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:31:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tedkoppynbc.\n",
            "04/12/2021 06:31:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tedkoppynbc\n",
            "04/12/2021 06:31:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:31:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for teepers1.\n",
            "04/12/2021 06:31:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=teepers1\n",
            "04/12/2021 06:31:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:31:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for teghanbartee_.\n",
            "04/12/2021 06:31:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=teghanbartee_\n",
            "04/12/2021 06:31:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:31:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tellithowitis24.\n",
            "04/12/2021 06:31:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tellithowitis24\n",
            "04/12/2021 06:31:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:31:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tenshioskar.\n",
            "04/12/2021 06:31:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tenshioskar\n",
            "04/12/2021 06:31:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:31:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for terrellckeith.\n",
            "04/12/2021 06:31:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=terrellckeith\n",
            "04/12/2021 06:31:15 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:31:15 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:31:15 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:31:15 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:31:15 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:31:15 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:31:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:31:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thalyamk.\n",
            "04/12/2021 06:31:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thalyamk\n",
            "04/12/2021 06:31:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:31:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for that_madi_chica.\n",
            "04/12/2021 06:31:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=that_madi_chica\n",
            "04/12/2021 06:31:17 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:31:17 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:31:17 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:31:17 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:31:17 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:31:17 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:31:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:31:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thatguyaj36.\n",
            "04/12/2021 06:31:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thatguyaj36\n",
            "04/12/2021 06:31:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:31:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thathigga.\n",
            "04/12/2021 06:31:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thathigga\n",
            "04/12/2021 06:31:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1922\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:31:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thatjoeherrmann.\n",
            "04/12/2021 06:31:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thatjoeherrmann\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:31:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thattkay.\n",
            "04/12/2021 06:31:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thattkay\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:31:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for the_davenporter.\n",
            "04/12/2021 06:31:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=the_davenporter\n",
            "04/12/2021 06:31:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1925\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:31:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for the_naypalm.\n",
            "04/12/2021 06:31:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=the_naypalm\n",
            "04/12/2021 06:31:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:31:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for the_psi_lord.\n",
            "04/12/2021 06:31:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=the_psi_lord\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:31:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for the_ravefairy.\n",
            "04/12/2021 06:31:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=the_ravefairy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:31:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for the_real_f_a_m_.\n",
            "04/12/2021 06:31:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=the_real_f_a_m_\n",
            "04/12/2021 06:31:26 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:31:26 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:31:26 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:31:26 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:31:26 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:31:26 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:31:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:31:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for the23rdjoker.\n",
            "04/12/2021 06:31:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=the23rdjoker\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:31:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for theanxietyboi.\n",
            "04/12/2021 06:31:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=theanxietyboi\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:31:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thebeast456158.\n",
            "04/12/2021 06:31:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thebeast456158\n",
            "04/12/2021 06:31:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:31:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thebiggestuwu.\n",
            "04/12/2021 06:31:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thebiggestuwu\n",
            "04/12/2021 06:31:30 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:31:30 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:31:30 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:31:30 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:31:30 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:31:30 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:31:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:31:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thebigmanjimmyt.\n",
            "04/12/2021 06:31:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thebigmanjimmyt\n",
            "04/12/2021 06:31:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:31:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thebillbuchanan.\n",
            "04/12/2021 06:31:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thebillbuchanan\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:31:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thebiospace.\n",
            "04/12/2021 06:31:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thebiospace\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:31:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thecandymancant.\n",
            "04/12/2021 06:31:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thecandymancant\n",
            "04/12/2021 06:31:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:31:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thecaseygram.\n",
            "04/12/2021 06:31:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thecaseygram\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:31:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thecgist22.\n",
            "04/12/2021 06:31:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thecgist22\n",
            "04/12/2021 06:31:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:31:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thechadow.\n",
            "04/12/2021 06:31:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thechadow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:31:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thedaniidiaries.\n",
            "04/12/2021 06:31:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thedaniidiaries\n",
            "04/12/2021 06:31:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:31:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thedeaconcash.\n",
            "04/12/2021 06:31:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thedeaconcash\n",
            "04/12/2021 06:31:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:31:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thee_tomcat.\n",
            "04/12/2021 06:31:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thee_tomcat\n",
            "04/12/2021 06:31:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:31:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thefunction13.\n",
            "04/12/2021 06:31:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thefunction13\n",
            "04/12/2021 06:31:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:31:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thegabegarza.\n",
            "04/12/2021 06:31:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thegabegarza\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:31:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thegreatlexini.\n",
            "04/12/2021 06:31:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thegreatlexini\n",
            "04/12/2021 06:31:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:31:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thehannahlacey.\n",
            "04/12/2021 06:31:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thehannahlacey\n",
            "04/12/2021 06:31:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:31:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thejourneymangc.\n",
            "04/12/2021 06:31:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thejourneymangc\n",
            "04/12/2021 06:31:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:31:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thelatinochild.\n",
            "04/12/2021 06:31:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thelatinochild\n",
            "04/12/2021 06:31:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:31:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for therealatcinema.\n",
            "04/12/2021 06:31:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=therealatcinema\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:31:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:31:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thereallabruna.\n",
            "04/12/2021 06:31:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thereallabruna\n",
            "04/12/2021 06:31:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:31:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for therocketralph.\n",
            "04/12/2021 06:31:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=therocketralph\n",
            "04/12/2021 06:31:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:31:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thescorpio69.\n",
            "04/12/2021 06:31:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thescorpio69\n",
            "04/12/2021 06:31:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
            "04/12/2021 06:31:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thetrminator01.\n",
            "04/12/2021 06:31:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thetrminator01\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:32:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:32:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for theuncannysnail.\n",
            "04/12/2021 06:32:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=theuncannysnail\n",
            "04/12/2021 06:32:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:32:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thewhaler.\n",
            "04/12/2021 06:32:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thewhaler\n",
            "04/12/2021 06:32:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:32:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for theyhatetaylor.\n",
            "04/12/2021 06:32:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=theyhatetaylor\n",
            "04/12/2021 06:32:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:32:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thezobelle.\n",
            "04/12/2021 06:32:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thezobelle\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:32:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:32:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thornsberry44.\n",
            "04/12/2021 06:32:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thornsberry44\n",
            "04/12/2021 06:32:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:32:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for threadslut.\n",
            "04/12/2021 06:32:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=threadslut\n",
            "04/12/2021 06:32:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:32:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thrown_salad.\n",
            "04/12/2021 06:32:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thrown_salad\n",
            "04/12/2021 06:32:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:32:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for thumphries06.\n",
            "04/12/2021 06:32:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=thumphries06\n",
            "04/12/2021 06:32:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:32:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tiaralo_.\n",
            "04/12/2021 06:32:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tiaralo_\n",
            "04/12/2021 06:32:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:32:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tiaramonee.\n",
            "04/12/2021 06:32:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tiaramonee\n",
            "04/12/2021 06:32:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:32:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tice_stacy.\n",
            "04/12/2021 06:32:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tice_stacy\n",
            "04/12/2021 06:32:15 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:32:15 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:32:15 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:32:15 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:32:15 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:32:15 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:32:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:32:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tiffanyharttt.\n",
            "04/12/2021 06:32:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tiffanyharttt\n",
            "04/12/2021 06:32:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:32:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tiffanyparkkk.\n",
            "04/12/2021 06:32:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tiffanyparkkk\n",
            "04/12/2021 06:32:16 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:32:16 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:32:16 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:32:16 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:32:16 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:32:16 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:32:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:32:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tim_ronquillo.\n",
            "04/12/2021 06:32:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tim_ronquillo\n",
            "04/12/2021 06:32:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:32:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for timconnellymd.\n",
            "04/12/2021 06:32:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=timconnellymd\n",
            "04/12/2021 06:32:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:32:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for timjmasterson.\n",
            "04/12/2021 06:32:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=timjmasterson\n",
            "04/12/2021 06:32:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:32:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tinsoldier6.\n",
            "04/12/2021 06:32:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tinsoldier6\n",
            "04/12/2021 06:32:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:32:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tkyzer.\n",
            "04/12/2021 06:32:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tkyzer\n",
            "04/12/2021 06:32:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:32:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tnrlm.\n",
            "04/12/2021 06:32:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tnrlm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:32:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:32:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tobybaratta.\n",
            "04/12/2021 06:32:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tobybaratta\n",
            "04/12/2021 06:32:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:32:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for todayimbecca.\n",
            "04/12/2021 06:32:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=todayimbecca\n",
            "04/12/2021 06:32:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:32:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for toddmitchell550.\n",
            "04/12/2021 06:32:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=toddmitchell550\n",
            "04/12/2021 06:32:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:32:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for toexcogitate.\n",
            "04/12/2021 06:32:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=toexcogitate\n",
            "04/12/2021 06:32:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:32:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for toiletliner.\n",
            "04/12/2021 06:32:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=toiletliner\n",
            "04/12/2021 06:32:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:32:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tom_mcmurray.\n",
            "04/12/2021 06:32:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tom_mcmurray\n",
            "04/12/2021 06:32:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:32:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tommygun083.\n",
            "04/12/2021 06:32:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tommygun083\n",
            "04/12/2021 06:32:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1980\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:32:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tonightisabel.\n",
            "04/12/2021 06:32:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tonightisabel\n",
            "04/12/2021 06:32:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:32:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tony73922959.\n",
            "04/12/2021 06:32:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tony73922959\n",
            "04/12/2021 06:32:30 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:32:30 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:32:30 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:32:30 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:32:30 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:32:30 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:32:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:32:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tonyplayboi.\n",
            "04/12/2021 06:32:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tonyplayboi\n",
            "04/12/2021 06:32:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:32:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for too_manyfaces.\n",
            "04/12/2021 06:32:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=too_manyfaces\n",
            "04/12/2021 06:32:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:32:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for toonastiettv.\n",
            "04/12/2021 06:32:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=toonastiettv\n",
            "04/12/2021 06:32:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:32:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for toothpickisgay.\n",
            "04/12/2021 06:32:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=toothpickisgay\n",
            "04/12/2021 06:32:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:32:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for toraad4u.\n",
            "04/12/2021 06:32:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=toraad4u\n",
            "04/12/2021 06:32:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:32:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tornadolarkin.\n",
            "04/12/2021 06:32:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tornadolarkin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:32:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:32:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for totally__kyle__.\n",
            "04/12/2021 06:32:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=totally__kyle__\n",
            "04/12/2021 06:32:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1989\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:32:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tototinmanandme.\n",
            "04/12/2021 06:32:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tototinmanandme\n",
            "04/12/2021 06:32:37 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:32:37 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:32:37 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:32:37 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:32:37 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:32:37 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:32:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:32:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for towndog3.\n",
            "04/12/2021 06:32:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=towndog3\n",
            "04/12/2021 06:32:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:32:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for toygodd.\n",
            "04/12/2021 06:32:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=toygodd\n",
            "04/12/2021 06:32:39 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:32:39 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:32:39 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:32:39 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:32:39 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:32:39 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:32:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:32:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tracey_t_m.\n",
            "04/12/2021 06:32:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tracey_t_m\n",
            "04/12/2021 06:32:39 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:32:39 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:32:39 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:32:39 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:32:39 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:32:39 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:32:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:32:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tradamfool214.\n",
            "04/12/2021 06:32:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tradamfool214\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:32:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:32:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for trap_soullll.\n",
            "04/12/2021 06:32:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=trap_soullll\n",
            "04/12/2021 06:32:41 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:32:41 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:32:41 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:32:41 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:32:41 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:32:41 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:32:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:32:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for trapcoupe.\n",
            "04/12/2021 06:32:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=trapcoupe\n",
            "04/12/2021 06:32:42 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:32:42 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:32:42 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:32:42 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:32:42 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:32:42 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:32:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:32:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for travelinman1966.\n",
            "04/12/2021 06:32:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=travelinman1966\n",
            "04/12/2021 06:32:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:32:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for travisyoung12.\n",
            "04/12/2021 06:32:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=travisyoung12\n",
            "04/12/2021 06:32:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:32:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for travy_trav_trav.\n",
            "04/12/2021 06:32:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=travy_trav_trav\n",
            "04/12/2021 06:32:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:32:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for trentdwyer30.\n",
            "04/12/2021 06:32:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=trentdwyer30\n",
            "04/12/2021 06:32:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:32:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for trevor__brown17.\n",
            "04/12/2021 06:32:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=trevor__brown17\n",
            "04/12/2021 06:32:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:32:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tribecalledseth.\n",
            "04/12/2021 06:32:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tribecalledseth\n",
            "04/12/2021 06:32:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:32:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tricianolfi.\n",
            "04/12/2021 06:32:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tricianolfi\n",
            "04/12/2021 06:32:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:32:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for trishquade.\n",
            "04/12/2021 06:32:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=trishquade\n",
            "04/12/2021 06:32:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2004\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:32:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for trixsensei.\n",
            "04/12/2021 06:32:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=trixsensei\n",
            "04/12/2021 06:32:50 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:32:50 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:32:50 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:32:50 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:32:50 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:32:50 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:32:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:32:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for troutbumsteeze.\n",
            "04/12/2021 06:32:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=troutbumsteeze\n",
            "04/12/2021 06:32:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:32:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for troymickle.\n",
            "04/12/2021 06:32:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=troymickle\n",
            "04/12/2021 06:32:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:32:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for truewert.\n",
            "04/12/2021 06:32:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=truewert\n",
            "04/12/2021 06:32:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:32:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tsa_hai.\n",
            "04/12/2021 06:32:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tsa_hai\n",
            "04/12/2021 06:32:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:32:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for turd__ferguson2.\n",
            "04/12/2021 06:32:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=turd__ferguson2\n",
            "04/12/2021 06:32:55 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:32:55 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:32:55 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:32:55 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:32:55 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:32:55 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:32:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:32:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tvalife.\n",
            "04/12/2021 06:32:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tvalife\n",
            "04/12/2021 06:32:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2011\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:32:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for twan_tucker.\n",
            "04/12/2021 06:32:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=twan_tucker\n",
            "04/12/2021 06:32:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:32:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tweetingleb.\n",
            "04/12/2021 06:32:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tweetingleb\n",
            "04/12/2021 06:32:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:32:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tweetyrealtor.\n",
            "04/12/2021 06:32:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tweetyrealtor\n",
            "04/12/2021 06:32:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:32:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for twentyy_8.\n",
            "04/12/2021 06:32:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=twentyy_8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:32:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:33:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for twistedup_nside.\n",
            "04/12/2021 06:33:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=twistedup_nside\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:33:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:33:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for twitchtreehop.\n",
            "04/12/2021 06:33:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=twitchtreehop\n",
            "04/12/2021 06:33:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:33:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for txhoneydip.\n",
            "04/12/2021 06:33:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=txhoneydip\n",
            "04/12/2021 06:33:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:33:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tydollatree.\n",
            "04/12/2021 06:33:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tydollatree\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:33:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:33:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tyler_gulledge.\n",
            "04/12/2021 06:33:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tyler_gulledge\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:33:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:33:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tylerhoffman7.\n",
            "04/12/2021 06:33:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tylerhoffman7\n",
            "04/12/2021 06:33:05 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:33:05 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:33:05 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:33:05 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:33:05 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:33:05 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:33:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:33:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tylerinthemakin.\n",
            "04/12/2021 06:33:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tylerinthemakin\n",
            "04/12/2021 06:33:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:33:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tylerking_2.\n",
            "04/12/2021 06:33:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tylerking_2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:33:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:33:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tylerolson1791.\n",
            "04/12/2021 06:33:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tylerolson1791\n",
            "04/12/2021 06:33:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:33:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for typeogregative.\n",
            "04/12/2021 06:33:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=typeogregative\n",
            "04/12/2021 06:33:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:33:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for tyramjb.\n",
            "04/12/2021 06:33:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=tyramjb\n",
            "04/12/2021 06:33:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:33:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for uligg_.\n",
            "04/12/2021 06:33:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=uligg_\n",
            "04/12/2021 06:33:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:33:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for umtaw.\n",
            "04/12/2021 06:33:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=umtaw\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:33:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:33:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for unbreakablehate.\n",
            "04/12/2021 06:33:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=unbreakablehate\n",
            "04/12/2021 06:33:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:33:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for unclebob56.\n",
            "04/12/2021 06:33:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=unclebob56\n",
            "04/12/2021 06:33:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:33:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for unique_by_angie.\n",
            "04/12/2021 06:33:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=unique_by_angie\n",
            "04/12/2021 06:33:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:33:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for unique_lache.\n",
            "04/12/2021 06:33:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=unique_lache\n",
            "04/12/2021 06:33:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:33:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for unknown_sonn.\n",
            "04/12/2021 06:33:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=unknown_sonn\n",
            "04/12/2021 06:33:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:33:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for uplinkal.\n",
            "04/12/2021 06:33:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=uplinkal\n",
            "04/12/2021 06:33:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2034\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:33:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for uraww.\n",
            "04/12/2021 06:33:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=uraww\n",
            "04/12/2021 06:33:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:33:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ursa_majors.\n",
            "04/12/2021 06:33:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ursa_majors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:33:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:33:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for uwubabi.\n",
            "04/12/2021 06:33:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=uwubabi\n",
            "04/12/2021 06:33:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2037\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:33:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for v_mengden.\n",
            "04/12/2021 06:33:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=v_mengden\n",
            "04/12/2021 06:33:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:33:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for valenntinarave.\n",
            "04/12/2021 06:33:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=valenntinarave\n",
            "04/12/2021 06:33:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2039\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:33:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for valeriedis.\n",
            "04/12/2021 06:33:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=valeriedis\n",
            "04/12/2021 06:33:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:33:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vanessadenise12.\n",
            "04/12/2021 06:33:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vanessadenise12\n",
            "04/12/2021 06:33:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:33:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vanilla_lovve.\n",
            "04/12/2021 06:33:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vanilla_lovve\n",
            "04/12/2021 06:33:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2042\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:33:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vapelvlmidnight.\n",
            "04/12/2021 06:33:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vapelvlmidnight\n",
            "04/12/2021 06:33:24 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:33:24 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:33:24 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:33:24 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:33:24 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:33:24 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:33:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2043\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:33:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vapes_2_much.\n",
            "04/12/2021 06:33:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vapes_2_much\n",
            "04/12/2021 06:33:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:33:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for veixms.\n",
            "04/12/2021 06:33:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=veixms\n",
            "04/12/2021 06:33:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:33:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for verbesity.\n",
            "04/12/2021 06:33:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=verbesity\n",
            "04/12/2021 06:33:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:33:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for verzachyy.\n",
            "04/12/2021 06:33:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=verzachyy\n",
            "04/12/2021 06:33:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:33:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for viccudi.\n",
            "04/12/2021 06:33:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=viccudi\n",
            "04/12/2021 06:33:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:33:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vicemackingtink.\n",
            "04/12/2021 06:33:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vicemackingtink\n",
            "04/12/2021 06:33:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:33:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for victoriasenese.\n",
            "04/12/2021 06:33:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=victoriasenese\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:33:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:33:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for victorsamayoa45.\n",
            "04/12/2021 06:33:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=victorsamayoa45\n",
            "04/12/2021 06:33:31 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2051\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:33:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vikkifusco.\n",
            "04/12/2021 06:33:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vikkifusco\n",
            "04/12/2021 06:33:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2052\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:33:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vintageproblem.\n",
            "04/12/2021 06:33:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vintageproblem\n",
            "04/12/2021 06:33:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2053\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:33:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for virginiaellis14.\n",
            "04/12/2021 06:33:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=virginiaellis14\n",
            "04/12/2021 06:33:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:33:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for virtualfrankie.\n",
            "04/12/2021 06:33:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=virtualfrankie\n",
            "04/12/2021 06:33:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2055\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:33:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vmhs_ritchie.\n",
            "04/12/2021 06:33:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vmhs_ritchie\n",
            "04/12/2021 06:33:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2056\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:33:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vmotiionz.\n",
            "04/12/2021 06:33:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vmotiionz\n",
            "04/12/2021 06:33:37 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:33:37 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:33:37 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:33:37 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:33:37 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:33:37 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:33:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:33:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vondishea.\n",
            "04/12/2021 06:33:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vondishea\n",
            "04/12/2021 06:33:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:33:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vperez180.\n",
            "04/12/2021 06:33:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vperez180\n",
            "04/12/2021 06:33:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2059\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:33:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vpi75wood.\n",
            "04/12/2021 06:33:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vpi75wood\n",
            "04/12/2021 06:33:39 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:33:39 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:33:39 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:33:39 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:33:39 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:33:39 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:33:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2060\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:33:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vriless.\n",
            "04/12/2021 06:33:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vriless\n",
            "04/12/2021 06:33:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2061\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:33:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vyemily_.\n",
            "04/12/2021 06:33:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vyemily_\n",
            "04/12/2021 06:33:41 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:33:41 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:33:41 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:33:41 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:33:41 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:33:41 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:33:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:33:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for vznchy.\n",
            "04/12/2021 06:33:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=vznchy\n",
            "04/12/2021 06:33:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:33:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for walkingbazketz.\n",
            "04/12/2021 06:33:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=walkingbazketz\n",
            "04/12/2021 06:33:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2064\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:33:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for walkthesun_.\n",
            "04/12/2021 06:33:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=walkthesun_\n",
            "04/12/2021 06:33:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2065\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:33:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wannabegoat.\n",
            "04/12/2021 06:33:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wannabegoat\n",
            "04/12/2021 06:33:44 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:33:44 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:33:44 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:33:44 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:33:44 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:33:44 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:33:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:33:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for warrensupert.\n",
            "04/12/2021 06:33:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=warrensupert\n",
            "04/12/2021 06:33:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:33:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for watitizwatzup.\n",
            "04/12/2021 06:33:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=watitizwatzup\n",
            "04/12/2021 06:33:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2068\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:33:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for waylandguidance.\n",
            "04/12/2021 06:33:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=waylandguidance\n",
            "04/12/2021 06:33:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2069\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:33:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for waywardstrav.\n",
            "04/12/2021 06:33:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=waywardstrav\n",
            "04/12/2021 06:33:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:33:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wdthebeast.\n",
            "04/12/2021 06:33:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wdthebeast\n",
            "04/12/2021 06:33:49 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:33:49 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:33:49 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:33:49 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:33:49 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:33:49 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:33:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:33:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for weaselwords.\n",
            "04/12/2021 06:33:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=weaselwords\n",
            "04/12/2021 06:33:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:33:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wendy_guajardo1.\n",
            "04/12/2021 06:33:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wendy_guajardo1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2073\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:33:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:33:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wes_wiens16.\n",
            "04/12/2021 06:33:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wes_wiens16\n",
            "04/12/2021 06:33:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:33:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for whoiscrura.\n",
            "04/12/2021 06:33:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=whoiscrura\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:33:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:33:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for whosjoey_.\n",
            "04/12/2021 06:33:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=whosjoey_\n",
            "04/12/2021 06:33:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2076\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:33:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for why_vet38.\n",
            "04/12/2021 06:33:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=why_vet38\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:33:55 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:33:55 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wickerpedia.\n",
            "04/12/2021 06:33:55 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wickerpedia\n",
            "04/12/2021 06:33:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:33:56 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wiggeth.\n",
            "04/12/2021 06:33:56 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wiggeth\n",
            "04/12/2021 06:33:56 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:33:57 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wildheart_baby.\n",
            "04/12/2021 06:33:57 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wildheart_baby\n",
            "04/12/2021 06:33:57 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2080\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:33:58 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wildkatttt.\n",
            "04/12/2021 06:33:58 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wildkatttt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:33:58 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:33:59 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for williamson_sr.\n",
            "04/12/2021 06:33:59 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=williamson_sr\n",
            "04/12/2021 06:33:59 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:34:00 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for willtraube.\n",
            "04/12/2021 06:34:00 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=willtraube\n",
            "04/12/2021 06:34:00 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:34:01 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for willy_rozay.\n",
            "04/12/2021 06:34:01 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=willy_rozay\n",
            "04/12/2021 06:34:01 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2084\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:34:02 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for woahh_daee.\n",
            "04/12/2021 06:34:02 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=woahh_daee\n",
            "04/12/2021 06:34:02 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:34:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wolf_ezo.\n",
            "04/12/2021 06:34:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wolf_ezo\n",
            "04/12/2021 06:34:03 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:34:03 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wolfofeastside.\n",
            "04/12/2021 06:34:03 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wolfofeastside\n",
            "04/12/2021 06:34:04 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2087\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:34:04 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wootmoot.\n",
            "04/12/2021 06:34:04 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wootmoot\n",
            "04/12/2021 06:34:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:34:05 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wordfromamabird.\n",
            "04/12/2021 06:34:05 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wordfromamabird\n",
            "04/12/2021 06:34:05 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:34:06 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wordsmithwyle.\n",
            "04/12/2021 06:34:06 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wordsmithwyle\n",
            "04/12/2021 06:34:06 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2090\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
            "04/12/2021 06:34:07 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for worldisstoned.\n",
            "04/12/2021 06:34:07 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=worldisstoned\n",
            "04/12/2021 06:34:07 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:34:08 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wright_brooklin.\n",
            "04/12/2021 06:34:08 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wright_brooklin\n",
            "04/12/2021 06:34:08 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:34:09 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wrwagner97.\n",
            "04/12/2021 06:34:09 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wrwagner97\n",
            "04/12/2021 06:34:09 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:34:10 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wrxcrae.\n",
            "04/12/2021 06:34:10 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wrxcrae\n",
            "04/12/2021 06:34:10 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:34:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wthangel_.\n",
            "04/12/2021 06:34:11 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wthangel_\n",
            "04/12/2021 06:34:11 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:34:11 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:34:11 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:34:11 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:34:11 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:34:11 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:34:11 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:34:11 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for wvnkv.\n",
            "04/12/2021 06:34:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=wvnkv\n",
            "04/12/2021 06:34:12 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:34:12 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xbeautyxtruthx.\n",
            "04/12/2021 06:34:12 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xbeautyxtruthx\n",
            "04/12/2021 06:34:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:34:13 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xembearx.\n",
            "04/12/2021 06:34:13 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xembearx\n",
            "04/12/2021 06:34:13 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:34:14 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xenocg.\n",
            "04/12/2021 06:34:14 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xenocg\n",
            "04/12/2021 06:34:14 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2099\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:34:15 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xi__exe.\n",
            "04/12/2021 06:34:15 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xi__exe\n",
            "04/12/2021 06:34:15 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:34:16 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xkikibaby.\n",
            "04/12/2021 06:34:16 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xkikibaby\n",
            "04/12/2021 06:34:16 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:34:17 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xlcshe.\n",
            "04/12/2021 06:34:17 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xlcshe\n",
            "04/12/2021 06:34:17 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:34:18 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xm_cassie.\n",
            "04/12/2021 06:34:18 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xm_cassie\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2103\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:34:18 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:34:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xo__sel.\n",
            "04/12/2021 06:34:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xo__sel\n",
            "04/12/2021 06:34:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:34:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xoashyboo.\n",
            "04/12/2021 06:34:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xoashyboo\n",
            "04/12/2021 06:34:20 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:34:20 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xolaibaaa.\n",
            "04/12/2021 06:34:20 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xolaibaaa\n",
            "04/12/2021 06:34:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:34:21 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xshogundo.\n",
            "04/12/2021 06:34:21 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xshogundo\n",
            "04/12/2021 06:34:21 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:34:22 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xtcaffx.\n",
            "04/12/2021 06:34:22 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xtcaffx\n",
            "04/12/2021 06:34:22 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:34:22 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:34:22 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:34:22 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:34:22 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:34:22 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:34:22 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:34:23 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xunicorn_gaming.\n",
            "04/12/2021 06:34:23 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xunicorn_gaming\n",
            "04/12/2021 06:34:23 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:34:24 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xxpaigelovesxx.\n",
            "04/12/2021 06:34:24 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xxpaigelovesxx\n",
            "04/12/2021 06:34:24 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:34:25 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xxragexslayerxx.\n",
            "04/12/2021 06:34:25 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xxragexslayerxx\n",
            "04/12/2021 06:34:25 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:34:26 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for xxwindixx.\n",
            "04/12/2021 06:34:26 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=xxwindixx\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:34:26 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
            "04/12/2021 06:34:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for y2vonne.\n",
            "04/12/2021 06:34:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=y2vonne\n",
            "04/12/2021 06:34:27 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:34:27 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yam_btw.\n",
            "04/12/2021 06:34:27 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yam_btw\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:34:28 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:34:28 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yburyug.\n",
            "04/12/2021 06:34:28 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yburyug\n",
            "04/12/2021 06:34:29 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2115\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:34:29 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yeha_keelo.\n",
            "04/12/2021 06:34:29 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yeha_keelo\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:34:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:34:30 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yellojmas.\n",
            "04/12/2021 06:34:30 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yellojmas\n",
            "04/12/2021 06:34:30 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:34:31 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yeoldemack.\n",
            "04/12/2021 06:34:31 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yeoldemack\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:34:32 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
            "04/12/2021 06:34:32 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yoonminsnana.\n",
            "04/12/2021 06:34:32 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yoonminsnana\n",
            "04/12/2021 06:34:33 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
            "04/12/2021 06:34:33 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yorkhousecleanr.\n",
            "04/12/2021 06:34:33 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yorkhousecleanr\n",
            "04/12/2021 06:34:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:34:34 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for youknowjarod.\n",
            "04/12/2021 06:34:34 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=youknowjarod\n",
            "04/12/2021 06:34:34 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2121\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
            "04/12/2021 06:34:35 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for younggas6.\n",
            "04/12/2021 06:34:35 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=younggas6\n",
            "04/12/2021 06:34:35 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:34:36 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for youngtoering.\n",
            "04/12/2021 06:34:36 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=youngtoering\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:34:36 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
            "04/12/2021 06:34:37 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yourfavjenn.\n",
            "04/12/2021 06:34:37 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yourfavjenn\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:34:37 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:34:38 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yung_quick.\n",
            "04/12/2021 06:34:38 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yung_quick\n",
            "04/12/2021 06:34:38 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:34:39 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yunghatedbelo.\n",
            "04/12/2021 06:34:39 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yunghatedbelo\n",
            "04/12/2021 06:34:39 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2126\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
            "04/12/2021 06:34:40 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yvettedivadance.\n",
            "04/12/2021 06:34:40 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yvettedivadance\n",
            "04/12/2021 06:34:40 - WARNING - m3inference.m3twitter -   Could not retreive screen_name\n",
            "04/12/2021 06:34:40 - WARNING - m3inference.m3twitter -   Could not retreive id_str\n",
            "04/12/2021 06:34:40 - WARNING - m3inference.m3twitter -   Could not retreive description\n",
            "04/12/2021 06:34:40 - WARNING - m3inference.m3twitter -   Could not retreive name\n",
            "04/12/2021 06:34:40 - WARNING - m3inference.m3twitter -   Could not retreive profile_image_url\n",
            "04/12/2021 06:34:40 - WARNING - m3inference.m3twitter -   Unable to extract image from Twitter. Using default image.\n",
            "04/12/2021 06:34:40 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
            "04/12/2021 06:34:41 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yvettemanes.\n",
            "04/12/2021 06:34:41 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yvettemanes\n",
            "04/12/2021 06:34:41 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:34:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for yvngbronchus.\n",
            "04/12/2021 06:34:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=yvngbronchus\n",
            "04/12/2021 06:34:42 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2129\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
            "04/12/2021 06:34:42 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for zachkobayashi.\n",
            "04/12/2021 06:34:42 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=zachkobayashi\n",
            "04/12/2021 06:34:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2130\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
            "04/12/2021 06:34:43 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for zachsoraven.\n",
            "04/12/2021 06:34:43 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=zachsoraven\n",
            "04/12/2021 06:34:43 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
            "04/12/2021 06:34:44 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for zacoutloud.\n",
            "04/12/2021 06:34:44 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=zacoutloud\n",
            "04/12/2021 06:34:44 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
            "04/12/2021 06:34:45 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for zaliasfgc.\n",
            "04/12/2021 06:34:45 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=zaliasfgc\n",
            "04/12/2021 06:34:45 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
            "04/12/2021 06:34:46 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for zeldabynight.\n",
            "04/12/2021 06:34:46 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=zeldabynight\n",
            "04/12/2021 06:34:46 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2134\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:34:47 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for zepy32.\n",
            "04/12/2021 06:34:47 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=zepy32\n",
            "04/12/2021 06:34:47 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
            "04/12/2021 06:34:48 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ziondood.\n",
            "04/12/2021 06:34:48 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ziondood\n",
            "04/12/2021 06:34:48 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
            "04/12/2021 06:34:49 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for znarikia.\n",
            "04/12/2021 06:34:49 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=znarikia\n",
            "04/12/2021 06:34:49 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:34:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for zoeberrier.\n",
            "04/12/2021 06:34:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=zoeberrier\n",
            "04/12/2021 06:34:50 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2138\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
            "04/12/2021 06:34:50 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for zoecalamaco.\n",
            "04/12/2021 06:34:50 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=zoecalamaco\n",
            "04/12/2021 06:34:51 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
            "04/12/2021 06:34:51 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for zoeynicodemus.\n",
            "04/12/2021 06:34:51 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=zoeynicodemus\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 06:34:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
            "04/12/2021 06:34:52 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for zthebest33.\n",
            "04/12/2021 06:34:52 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=zthebest33\n",
            "04/12/2021 06:34:52 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
            "04/12/2021 06:34:53 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ztran53.\n",
            "04/12/2021 06:34:53 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ztran53\n",
            "04/12/2021 06:34:53 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
            "04/12/2021 06:34:54 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for zwhite93.\n",
            "04/12/2021 06:34:54 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=zwhite93\n",
            "04/12/2021 06:34:54 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS_5GNlvoNbl",
        "outputId": "bc8db87a-634b-42f3-9215-ebd254c733b1"
      },
      "source": [
        "count = 0\n",
        "label = df_labeled['human.labeled.gender'].tolist()\n",
        "for i in range(len(pred)):\n",
        "  if int(pred[i]) == label[i]:\n",
        "    count +=1\n",
        "print('The accuracy for gender prediction using m3inference is', count/len(pred))"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy for gender prediction using m3inference is 0.8964552238805971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr6K9koGz11L",
        "outputId": "f4f3de35-afb4-4343-e351-91cb763a78e4"
      },
      "source": [
        "count2 = 0\n",
        "label1 = df_labeled['lexicon.gender.prediction'].tolist()\n",
        "for i in range(len(label1)):\n",
        "  if label1[i] == label[i]:\n",
        "    count2 +=1\n",
        "print('The accuracy for lexicon.gender.prediction is', count2/len(label1))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy for lexicon.gender.prediction is 0.7798507462686567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8057Y8opzCH",
        "outputId": "309f2f26-2148-4c9a-fb7a-d64f01d80d36"
      },
      "source": [
        "print(len(pred))\n",
        "print(pred[-1])\n",
        "print(count)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2144\n",
            "1\n",
            "1922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU6NbQney07n",
        "outputId": "1d752bb4-98d5-4c77-a47e-24783b46ef48"
      },
      "source": [
        "user_list2 = df['Username'].tolist()\n",
        "print(len(user_list2))\n",
        "pred2 = []"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1JoEYSpehuk",
        "outputId": "7ac07b10-22b3-40b7-ca59-32d427316fa2"
      },
      "source": [
        "# initialization\n",
        "m3twitter=M3Twitter()\n",
        "\n",
        "# remember to upload Twitter API keys, format as https://github.com/euagendas/m3inference/blob/master/scripts/auth_example.txt\n",
        "m3twitter.twitter_init_from_file(\"/content/drive/MyDrive/auth.txt\")\n",
        "\n",
        "# you can also use m3twitter.infer_id(id = \"....\")\n",
        "for i in range(len(user_list2)):\n",
        "  print(i)\n",
        "  user_detail = m3twitter.infer_screen_name(user_list2[i],skip_cache=True)\n",
        "  prob_male = user_detail['output']['gender']['male']\n",
        "  prob_female = user_detail['output']['gender']['female']\n",
        "  if prob_male > prob_female:\n",
        "    pred2.append('1')\n",
        "  else:\n",
        "    pred2.append('0')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/12/2021 05:50:17 - INFO - m3inference.m3inference -   Version 1.1.4\n",
            "04/12/2021 05:50:17 - INFO - m3inference.m3inference -   Running on cpu.\n",
            "04/12/2021 05:50:17 - INFO - m3inference.m3inference -   Will use full M3 model.\n",
            "04/12/2021 05:50:18 - INFO - m3inference.m3inference -   Model full_model exists at /root/m3/models/full_model.mdl.\n",
            "04/12/2021 05:50:18 - INFO - m3inference.utils -   Checking MD5 for model full_model at /root/m3/models/full_model.mdl\n",
            "04/12/2021 05:50:18 - INFO - m3inference.utils -   MD5s match.\n",
            "04/12/2021 05:50:19 - INFO - m3inference.m3inference -   Loaded pretrained weight at /root/m3/models/full_model.mdl\n",
            "04/12/2021 05:50:19 - INFO - m3inference.m3twitter -   skip_cache is True. Fetching data from Twitter for ayyyy_tay.\n",
            "04/12/2021 05:50:19 - INFO - m3inference.m3twitter -   GET /users/show.json?screen_name=ayyyy_tay\n",
            "04/12/2021 05:50:19 - INFO - m3inference.dataset -   1 data entries loaded.\n",
            "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'male': 0.0404, 'female': 0.9596}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTG4PyZWgUic"
      },
      "source": [
        "# Create new column to save the predicted value\n",
        "df[\"gender\"] = \"male\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nue5_c5-EFkU"
      },
      "source": [
        "# Loop over each row to assign the predict value, should be used with M3\n",
        "for index, row in df.iterrows():\n",
        "    # TODO: modify value here\n",
        "    df.at[index, 'gender'] = pred2[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgURxU3ly7tK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}