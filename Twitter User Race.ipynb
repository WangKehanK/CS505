{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CS505.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/WangKehanK/CS505/blob/main/CS505.ipynb",
      "authorship_tag": "ABX9TyPbGTAbsLHYhf80xnxnthuj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WangKehanK/CS505/blob/main/Twitter%20User%20Race.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asTqpH8Z5Agu"
      },
      "source": [
        "# Prediction on Race\n",
        "https://github.com/appeler/ethnicolr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtqHODFY4_YJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74258ffa-3e70-426b-d364-3cb164566552"
      },
      "source": [
        "!pip install ethnicolr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ethnicolr\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/23/4ef1ca0c00f10362c3e2262b04c54cf7c7c28069a20dd842313dfaa5c553/ethnicolr-0.5.0-py2.py3-none-any.whl (39.1MB)\n",
            "\u001b[K     |████████████████████████████████| 39.1MB 99kB/s \n",
            "\u001b[?25hCollecting h5py==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/fd/2ca5c4f4ed33ac4178f9c4d551e3946ab480866e3cd67a65a67a4bb35367/h5py-2.9.0-cp37-cp37m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 41.2MB/s \n",
            "\u001b[?25hCollecting pandas==0.24.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/e6/2d47835f91eb010036be207581fa113fb4e3822ec1b4bafb0d3d105fede6/pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 40.0MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/51/99abd43185d94adaaaddf8f44a80c418a91977924a7bc39b8dacd0c495b0/tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 46kB/s \n",
            "\u001b[?25hCollecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/d1/45be1144b03b6b1e24f9a924f23f66b4ad030d834ad31fb9e5581bd328af/numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 257kB/s \n",
            "\u001b[?25hCollecting Keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.9.0->ethnicolr) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/dist-packages (from pandas==0.24.2->ethnicolr) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from pandas==0.24.2->ethnicolr) (2.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->ethnicolr) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->ethnicolr) (1.1.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 41.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->ethnicolr) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->ethnicolr) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->ethnicolr) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->ethnicolr) (1.1.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 55.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->ethnicolr) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->ethnicolr) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->ethnicolr) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->ethnicolr) (0.12.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4->ethnicolr) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4->ethnicolr) (1.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5->ethnicolr) (54.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5->ethnicolr) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5->ethnicolr) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5->ethnicolr) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5->ethnicolr) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5->ethnicolr) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=b3e8fc10d82f5fe9e35b8d2a99c6ed16c5da283b156f94ad00ed47d6a6fc3e05\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement pandas>=0.25, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 3.0.0 has requirement numpy>=1.16.6, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: mizani 0.6.0 has requirement pandas>=0.25.0, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.2 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, h5py, pandas, tensorboard, keras-applications, tensorflow-estimator, gast, tensorflow, Keras, ethnicolr\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed Keras-2.2.4 ethnicolr-0.5.0 gast-0.2.2 h5py-2.9.0 keras-applications-1.0.8 numpy-1.16.4 pandas-0.24.2 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAQMq2x0k-8N"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ethnicolr import census_ln, pred_census_ln"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3-SHoESmbEr"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Twitter_user_handles_to_predict.csv\", encoding = \"utf-8\")\n",
        "df_labeled = pd.read_csv(\"/content/drive/My Drive/Twitter_users_labeled_with_age_and_gender.csv\", encoding = \"latin-1\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj2oD0Cr5xuY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmGyhGkD5zJ0"
      },
      "source": [
        "del df[\"ID\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEpC97ZQ6BxQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "328447ff-85a1-4dcd-ea7d-265ab1256ae9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Username</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>JayHolz410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kelechief</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VicSpencer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ItsAlexDodson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xopinkvodka6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Username\n",
              "0     JayHolz410\n",
              "1      kelechief\n",
              "2     VicSpencer\n",
              "3  ItsAlexDodson\n",
              "4   xopinkvodka6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytzG8Z-K50zT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e169e2ed-97f8-45d0-9c57-dcdfa079e6a5"
      },
      "source": [
        "pred_census_ln(df, 'Username')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Username</th>\n",
              "      <th>race</th>\n",
              "      <th>api</th>\n",
              "      <th>black</th>\n",
              "      <th>hispanic</th>\n",
              "      <th>white</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>JayHolz410</td>\n",
              "      <td>white</td>\n",
              "      <td>0.003172</td>\n",
              "      <td>0.084731</td>\n",
              "      <td>0.019339</td>\n",
              "      <td>0.892758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kelechief</td>\n",
              "      <td>white</td>\n",
              "      <td>0.033157</td>\n",
              "      <td>0.027121</td>\n",
              "      <td>0.011495</td>\n",
              "      <td>0.928227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VicSpencer</td>\n",
              "      <td>white</td>\n",
              "      <td>0.049370</td>\n",
              "      <td>0.045059</td>\n",
              "      <td>0.230932</td>\n",
              "      <td>0.674640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ItsAlexDodson</td>\n",
              "      <td>white</td>\n",
              "      <td>0.020399</td>\n",
              "      <td>0.036895</td>\n",
              "      <td>0.010584</td>\n",
              "      <td>0.932122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xopinkvodka6</td>\n",
              "      <td>white</td>\n",
              "      <td>0.004104</td>\n",
              "      <td>0.008679</td>\n",
              "      <td>0.018387</td>\n",
              "      <td>0.968830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>larryislegend</td>\n",
              "      <td>white</td>\n",
              "      <td>0.001985</td>\n",
              "      <td>0.020910</td>\n",
              "      <td>0.016177</td>\n",
              "      <td>0.960928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>gucci1017</td>\n",
              "      <td>white</td>\n",
              "      <td>0.003321</td>\n",
              "      <td>0.040318</td>\n",
              "      <td>0.017125</td>\n",
              "      <td>0.939236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>charles270</td>\n",
              "      <td>white</td>\n",
              "      <td>0.007749</td>\n",
              "      <td>0.058597</td>\n",
              "      <td>0.026910</td>\n",
              "      <td>0.906745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>dirtbaglife</td>\n",
              "      <td>white</td>\n",
              "      <td>0.002927</td>\n",
              "      <td>0.044491</td>\n",
              "      <td>0.009565</td>\n",
              "      <td>0.943017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TaylorJTakeover</td>\n",
              "      <td>white</td>\n",
              "      <td>0.005520</td>\n",
              "      <td>0.012015</td>\n",
              "      <td>0.013033</td>\n",
              "      <td>0.969431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>TheDailyOoze</td>\n",
              "      <td>white</td>\n",
              "      <td>0.002763</td>\n",
              "      <td>0.061077</td>\n",
              "      <td>0.024159</td>\n",
              "      <td>0.912001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>masonflynt</td>\n",
              "      <td>white</td>\n",
              "      <td>0.004089</td>\n",
              "      <td>0.018419</td>\n",
              "      <td>0.018879</td>\n",
              "      <td>0.958613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Reallilmartin</td>\n",
              "      <td>white</td>\n",
              "      <td>0.006607</td>\n",
              "      <td>0.132908</td>\n",
              "      <td>0.093782</td>\n",
              "      <td>0.766703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Kiswan93</td>\n",
              "      <td>white</td>\n",
              "      <td>0.036423</td>\n",
              "      <td>0.020969</td>\n",
              "      <td>0.017105</td>\n",
              "      <td>0.925503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sack216</td>\n",
              "      <td>white</td>\n",
              "      <td>0.008360</td>\n",
              "      <td>0.150008</td>\n",
              "      <td>0.022263</td>\n",
              "      <td>0.819369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>KylahGuion</td>\n",
              "      <td>white</td>\n",
              "      <td>0.020075</td>\n",
              "      <td>0.094883</td>\n",
              "      <td>0.022539</td>\n",
              "      <td>0.862503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>KarlousM</td>\n",
              "      <td>white</td>\n",
              "      <td>0.009441</td>\n",
              "      <td>0.041288</td>\n",
              "      <td>0.012611</td>\n",
              "      <td>0.936660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>StAndrewsHall</td>\n",
              "      <td>white</td>\n",
              "      <td>0.002534</td>\n",
              "      <td>0.171896</td>\n",
              "      <td>0.015725</td>\n",
              "      <td>0.809845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>DaRellCafe</td>\n",
              "      <td>white</td>\n",
              "      <td>0.004441</td>\n",
              "      <td>0.076052</td>\n",
              "      <td>0.019792</td>\n",
              "      <td>0.899714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>mineifiwildout</td>\n",
              "      <td>white</td>\n",
              "      <td>0.001432</td>\n",
              "      <td>0.119786</td>\n",
              "      <td>0.014522</td>\n",
              "      <td>0.864260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>OfficialJSoulja</td>\n",
              "      <td>white</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.003259</td>\n",
              "      <td>0.013863</td>\n",
              "      <td>0.981105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>DGDtheband</td>\n",
              "      <td>white</td>\n",
              "      <td>0.002613</td>\n",
              "      <td>0.019337</td>\n",
              "      <td>0.013788</td>\n",
              "      <td>0.964262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>therealmikedean</td>\n",
              "      <td>white</td>\n",
              "      <td>0.001823</td>\n",
              "      <td>0.031705</td>\n",
              "      <td>0.012315</td>\n",
              "      <td>0.954157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5hunnidPheebz</td>\n",
              "      <td>white</td>\n",
              "      <td>0.006156</td>\n",
              "      <td>0.046423</td>\n",
              "      <td>0.017200</td>\n",
              "      <td>0.930221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>shirju</td>\n",
              "      <td>api</td>\n",
              "      <td>0.958702</td>\n",
              "      <td>0.001874</td>\n",
              "      <td>0.001759</td>\n",
              "      <td>0.037665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>queen_phire</td>\n",
              "      <td>white</td>\n",
              "      <td>0.074841</td>\n",
              "      <td>0.123539</td>\n",
              "      <td>0.037397</td>\n",
              "      <td>0.764223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>RichDame1</td>\n",
              "      <td>white</td>\n",
              "      <td>0.003839</td>\n",
              "      <td>0.067009</td>\n",
              "      <td>0.018244</td>\n",
              "      <td>0.910908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>JustinaMusic</td>\n",
              "      <td>white</td>\n",
              "      <td>0.006559</td>\n",
              "      <td>0.066974</td>\n",
              "      <td>0.013837</td>\n",
              "      <td>0.912630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>SaintSmith_</td>\n",
              "      <td>white</td>\n",
              "      <td>0.011831</td>\n",
              "      <td>0.163531</td>\n",
              "      <td>0.023745</td>\n",
              "      <td>0.800893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>MoneyMan</td>\n",
              "      <td>white</td>\n",
              "      <td>0.006422</td>\n",
              "      <td>0.026050</td>\n",
              "      <td>0.032278</td>\n",
              "      <td>0.935250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25099</th>\n",
              "      <td>CANNiBUS_CRAiG</td>\n",
              "      <td>white</td>\n",
              "      <td>0.001063</td>\n",
              "      <td>0.024115</td>\n",
              "      <td>0.009054</td>\n",
              "      <td>0.965768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25100</th>\n",
              "      <td>_2lite</td>\n",
              "      <td>white</td>\n",
              "      <td>0.005947</td>\n",
              "      <td>0.078404</td>\n",
              "      <td>0.019187</td>\n",
              "      <td>0.896462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25101</th>\n",
              "      <td>Shaveshacksha</td>\n",
              "      <td>white</td>\n",
              "      <td>0.067506</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>0.008618</td>\n",
              "      <td>0.894756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25102</th>\n",
              "      <td>xSPEKTAx</td>\n",
              "      <td>white</td>\n",
              "      <td>0.112471</td>\n",
              "      <td>0.210321</td>\n",
              "      <td>0.011310</td>\n",
              "      <td>0.665898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25103</th>\n",
              "      <td>Nosa_Jefe</td>\n",
              "      <td>white</td>\n",
              "      <td>0.003355</td>\n",
              "      <td>0.052560</td>\n",
              "      <td>0.016549</td>\n",
              "      <td>0.927536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25104</th>\n",
              "      <td>challxxn</td>\n",
              "      <td>white</td>\n",
              "      <td>0.002315</td>\n",
              "      <td>0.006924</td>\n",
              "      <td>0.013015</td>\n",
              "      <td>0.977745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25105</th>\n",
              "      <td>Big___Esco</td>\n",
              "      <td>white</td>\n",
              "      <td>0.012281</td>\n",
              "      <td>0.022354</td>\n",
              "      <td>0.008249</td>\n",
              "      <td>0.957116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25106</th>\n",
              "      <td>StephGotti</td>\n",
              "      <td>white</td>\n",
              "      <td>0.004034</td>\n",
              "      <td>0.003025</td>\n",
              "      <td>0.028275</td>\n",
              "      <td>0.964666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25107</th>\n",
              "      <td>superstargucci</td>\n",
              "      <td>white</td>\n",
              "      <td>0.001574</td>\n",
              "      <td>0.002396</td>\n",
              "      <td>0.014225</td>\n",
              "      <td>0.981804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25108</th>\n",
              "      <td>sidc0mbs10x</td>\n",
              "      <td>white</td>\n",
              "      <td>0.011710</td>\n",
              "      <td>0.002308</td>\n",
              "      <td>0.019421</td>\n",
              "      <td>0.966560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25109</th>\n",
              "      <td>AlmightyyOtto</td>\n",
              "      <td>white</td>\n",
              "      <td>0.012457</td>\n",
              "      <td>0.003946</td>\n",
              "      <td>0.012950</td>\n",
              "      <td>0.970647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25110</th>\n",
              "      <td>notatreesh</td>\n",
              "      <td>white</td>\n",
              "      <td>0.032008</td>\n",
              "      <td>0.172762</td>\n",
              "      <td>0.021946</td>\n",
              "      <td>0.773284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25111</th>\n",
              "      <td>hellondascale7</td>\n",
              "      <td>hispanic</td>\n",
              "      <td>0.077035</td>\n",
              "      <td>0.044136</td>\n",
              "      <td>0.530725</td>\n",
              "      <td>0.348104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25112</th>\n",
              "      <td>MaxxWavy</td>\n",
              "      <td>white</td>\n",
              "      <td>0.003344</td>\n",
              "      <td>0.051695</td>\n",
              "      <td>0.012623</td>\n",
              "      <td>0.932338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25113</th>\n",
              "      <td>ASIANSOTATTED</td>\n",
              "      <td>white</td>\n",
              "      <td>0.385599</td>\n",
              "      <td>0.107580</td>\n",
              "      <td>0.020848</td>\n",
              "      <td>0.485974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25114</th>\n",
              "      <td>BNONews</td>\n",
              "      <td>white</td>\n",
              "      <td>0.015088</td>\n",
              "      <td>0.109523</td>\n",
              "      <td>0.016878</td>\n",
              "      <td>0.858511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25115</th>\n",
              "      <td>spikefleefor3</td>\n",
              "      <td>white</td>\n",
              "      <td>0.004294</td>\n",
              "      <td>0.107927</td>\n",
              "      <td>0.016967</td>\n",
              "      <td>0.870813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25116</th>\n",
              "      <td>Bbyg_Kaayy</td>\n",
              "      <td>white</td>\n",
              "      <td>0.003683</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>0.012867</td>\n",
              "      <td>0.977265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25117</th>\n",
              "      <td>Wreckless_Pain</td>\n",
              "      <td>white</td>\n",
              "      <td>0.003946</td>\n",
              "      <td>0.093911</td>\n",
              "      <td>0.016848</td>\n",
              "      <td>0.885296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25118</th>\n",
              "      <td>catchkeyz</td>\n",
              "      <td>white</td>\n",
              "      <td>0.003896</td>\n",
              "      <td>0.005680</td>\n",
              "      <td>0.021183</td>\n",
              "      <td>0.969241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25119</th>\n",
              "      <td>ricchustle</td>\n",
              "      <td>white</td>\n",
              "      <td>0.004185</td>\n",
              "      <td>0.037986</td>\n",
              "      <td>0.011789</td>\n",
              "      <td>0.946040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25120</th>\n",
              "      <td>Robss95_</td>\n",
              "      <td>white</td>\n",
              "      <td>0.004543</td>\n",
              "      <td>0.039913</td>\n",
              "      <td>0.019187</td>\n",
              "      <td>0.936356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25121</th>\n",
              "      <td>BarbersChairNet</td>\n",
              "      <td>white</td>\n",
              "      <td>0.009575</td>\n",
              "      <td>0.007438</td>\n",
              "      <td>0.019306</td>\n",
              "      <td>0.963680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25122</th>\n",
              "      <td>notgzuspiece</td>\n",
              "      <td>white</td>\n",
              "      <td>0.010649</td>\n",
              "      <td>0.022896</td>\n",
              "      <td>0.038511</td>\n",
              "      <td>0.927944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25123</th>\n",
              "      <td>xxlalarosexx</td>\n",
              "      <td>white</td>\n",
              "      <td>0.013601</td>\n",
              "      <td>0.119409</td>\n",
              "      <td>0.020339</td>\n",
              "      <td>0.846652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25124</th>\n",
              "      <td>13luvr</td>\n",
              "      <td>white</td>\n",
              "      <td>0.014299</td>\n",
              "      <td>0.066831</td>\n",
              "      <td>0.004748</td>\n",
              "      <td>0.914122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25125</th>\n",
              "      <td>Racetac</td>\n",
              "      <td>white</td>\n",
              "      <td>0.054234</td>\n",
              "      <td>0.066791</td>\n",
              "      <td>0.093998</td>\n",
              "      <td>0.784978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25126</th>\n",
              "      <td>MrNoFilter_100</td>\n",
              "      <td>white</td>\n",
              "      <td>0.004615</td>\n",
              "      <td>0.017838</td>\n",
              "      <td>0.016188</td>\n",
              "      <td>0.961360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25127</th>\n",
              "      <td>OgheneNerojr</td>\n",
              "      <td>hispanic</td>\n",
              "      <td>0.064934</td>\n",
              "      <td>0.016160</td>\n",
              "      <td>0.554323</td>\n",
              "      <td>0.364584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25128</th>\n",
              "      <td>earlxsweat</td>\n",
              "      <td>white</td>\n",
              "      <td>0.018063</td>\n",
              "      <td>0.089648</td>\n",
              "      <td>0.013548</td>\n",
              "      <td>0.878742</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25129 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Username      race       api     black  hispanic     white\n",
              "0           JayHolz410     white  0.003172  0.084731  0.019339  0.892758\n",
              "1            kelechief     white  0.033157  0.027121  0.011495  0.928227\n",
              "2           VicSpencer     white  0.049370  0.045059  0.230932  0.674640\n",
              "3        ItsAlexDodson     white  0.020399  0.036895  0.010584  0.932122\n",
              "4         xopinkvodka6     white  0.004104  0.008679  0.018387  0.968830\n",
              "5        larryislegend     white  0.001985  0.020910  0.016177  0.960928\n",
              "6            gucci1017     white  0.003321  0.040318  0.017125  0.939236\n",
              "7           charles270     white  0.007749  0.058597  0.026910  0.906745\n",
              "8          dirtbaglife     white  0.002927  0.044491  0.009565  0.943017\n",
              "9      TaylorJTakeover     white  0.005520  0.012015  0.013033  0.969431\n",
              "10        TheDailyOoze     white  0.002763  0.061077  0.024159  0.912001\n",
              "11          masonflynt     white  0.004089  0.018419  0.018879  0.958613\n",
              "12       Reallilmartin     white  0.006607  0.132908  0.093782  0.766703\n",
              "13            Kiswan93     white  0.036423  0.020969  0.017105  0.925503\n",
              "14             sack216     white  0.008360  0.150008  0.022263  0.819369\n",
              "15          KylahGuion     white  0.020075  0.094883  0.022539  0.862503\n",
              "16            KarlousM     white  0.009441  0.041288  0.012611  0.936660\n",
              "17       StAndrewsHall     white  0.002534  0.171896  0.015725  0.809845\n",
              "18          DaRellCafe     white  0.004441  0.076052  0.019792  0.899714\n",
              "19      mineifiwildout     white  0.001432  0.119786  0.014522  0.864260\n",
              "20     OfficialJSoulja     white  0.001773  0.003259  0.013863  0.981105\n",
              "21          DGDtheband     white  0.002613  0.019337  0.013788  0.964262\n",
              "22     therealmikedean     white  0.001823  0.031705  0.012315  0.954157\n",
              "23       5hunnidPheebz     white  0.006156  0.046423  0.017200  0.930221\n",
              "24              shirju       api  0.958702  0.001874  0.001759  0.037665\n",
              "25         queen_phire     white  0.074841  0.123539  0.037397  0.764223\n",
              "26           RichDame1     white  0.003839  0.067009  0.018244  0.910908\n",
              "27        JustinaMusic     white  0.006559  0.066974  0.013837  0.912630\n",
              "28         SaintSmith_     white  0.011831  0.163531  0.023745  0.800893\n",
              "29            MoneyMan     white  0.006422  0.026050  0.032278  0.935250\n",
              "...                ...       ...       ...       ...       ...       ...\n",
              "25099   CANNiBUS_CRAiG     white  0.001063  0.024115  0.009054  0.965768\n",
              "25100           _2lite     white  0.005947  0.078404  0.019187  0.896462\n",
              "25101    Shaveshacksha     white  0.067506  0.029120  0.008618  0.894756\n",
              "25102         xSPEKTAx     white  0.112471  0.210321  0.011310  0.665898\n",
              "25103        Nosa_Jefe     white  0.003355  0.052560  0.016549  0.927536\n",
              "25104         challxxn     white  0.002315  0.006924  0.013015  0.977745\n",
              "25105       Big___Esco     white  0.012281  0.022354  0.008249  0.957116\n",
              "25106       StephGotti     white  0.004034  0.003025  0.028275  0.964666\n",
              "25107   superstargucci     white  0.001574  0.002396  0.014225  0.981804\n",
              "25108      sidc0mbs10x     white  0.011710  0.002308  0.019421  0.966560\n",
              "25109    AlmightyyOtto     white  0.012457  0.003946  0.012950  0.970647\n",
              "25110       notatreesh     white  0.032008  0.172762  0.021946  0.773284\n",
              "25111   hellondascale7  hispanic  0.077035  0.044136  0.530725  0.348104\n",
              "25112         MaxxWavy     white  0.003344  0.051695  0.012623  0.932338\n",
              "25113    ASIANSOTATTED     white  0.385599  0.107580  0.020848  0.485974\n",
              "25114          BNONews     white  0.015088  0.109523  0.016878  0.858511\n",
              "25115    spikefleefor3     white  0.004294  0.107927  0.016967  0.870813\n",
              "25116       Bbyg_Kaayy     white  0.003683  0.006185  0.012867  0.977265\n",
              "25117   Wreckless_Pain     white  0.003946  0.093911  0.016848  0.885296\n",
              "25118        catchkeyz     white  0.003896  0.005680  0.021183  0.969241\n",
              "25119       ricchustle     white  0.004185  0.037986  0.011789  0.946040\n",
              "25120         Robss95_     white  0.004543  0.039913  0.019187  0.936356\n",
              "25121  BarbersChairNet     white  0.009575  0.007438  0.019306  0.963680\n",
              "25122     notgzuspiece     white  0.010649  0.022896  0.038511  0.927944\n",
              "25123     xxlalarosexx     white  0.013601  0.119409  0.020339  0.846652\n",
              "25124           13luvr     white  0.014299  0.066831  0.004748  0.914122\n",
              "25125          Racetac     white  0.054234  0.066791  0.093998  0.784978\n",
              "25126   MrNoFilter_100     white  0.004615  0.017838  0.016188  0.961360\n",
              "25127     OgheneNerojr  hispanic  0.064934  0.016160  0.554323  0.364584\n",
              "25128       earlxsweat     white  0.018063  0.089648  0.013548  0.878742\n",
              "\n",
              "[25129 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9A1IyKD56jp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}